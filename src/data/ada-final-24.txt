Q: Dado el siguiente programa recursivo:
```cpp
int f(int n) {
  // Se asume que n >= 0
  if (n == 0)
    return 1;
  return f(n - 1) + f(n - 2);
}
```
si quisiéramos mejorarlo haciendo uso de la técnica de programación dinámica, ¿cuáles serían las complejidades temporal y espacial más ajustadas del algoritmo resultante?
O: Respectivamente, $O(n)$ y $O(1)$
O: Ambas complejidades serían $O(1)$
O: Ambas complejidades serían $O(n)$
A: 0
C: Julio 2024

Q: Una de estas tres afirmaciones es falsa. ¿Cuál?
O: Un algoritmo voraz puede no encontrar la solución óptima de un problema de selección discreta.
O: El esquema de ramificación y poda no garantiza que la complejidad temporal de resolución de un problema de selección discreta no sea exponencial.
O: Los algoritmos voraces no sirven para resolver problemas de selección discreta.
A: 2
C: Julio 2024

Q: ¿Qué tienen en común el algoritmo que obtiene el k-ésimo elemento más pequeño de un vector (estudiado en clase) y el algoritmo de ordenación Quicksort?
O: El número de llamadas recursivas que se hacen.
O: La combinación de las soluciones a los subproblemas.
O: La división del problema en subproblemas.
A: 2
C: Julio 2024

Q: Una de estas tres situaciones no es posible. ¿Cuál es?
O: $f(n) \in O(n)$ y $f(n) \in \Omega(1)$
O: $f(n) \in \Omega(n^2)$ y $f(n) \in O(n)$
O: $f(n) \in O(n)$ y $f(n) \in O(n^2)$
A: 1
C: Julio 2024

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? 
$f(n) = \begin{cases} 1 + f(n/b) & \text{si } n > 1 \\ 1 & \text{si } n = 1 \end{cases}$, con $b \in \mathbb{N}$, $b > 1$
A: 1
C: Junio 2024
O: Depende del valor de $b$
O: $f(n) \in \Theta(\log n)$
O: $f(n) \in \Theta(n)$

Q: El uso de funciones de cota en ramificación y poda...
A: 1
C: Junio 2024;Julio 2024
O: ...transforma en polinómicas complejidades que antes eran exponenciales
O: ...puede reducir el número de instancias del problema que pertenecen al caso peor
O: ...garantiza que el algoritmo va a ser más eficiente ante cualquier instancia del problema

Q: Si un problema de optimización lo es para una función que toma valores continuos...
A: 0
C: Junio 2024
O: Divide y vencerás puede resultar más eficiente que la programación dinámica iterativa en cuanto al uso de memoria
O: La programación dinámica iterativa siempre es mucho más eficiente que divide y vencerás en cuanto al uso de memoria
O: El uso de memoria de la programación dinámica iterativa y de divide y vencerás es el mismo independientemente de si el dominio es discreto o continuo

Q: La solución voraz al problema de la mochila con objetos no fraccionables:
A: 2
C: Junio 2024;Julio 2024
O: Siempre encuentra la solución óptima al problema
O: No siempre encuentra la solución óptima al problema, pero sí una muy buena aproximación, a partir de la cual se puede obtener el óptimo en tiempo constante
O: No siempre encuentra la solución óptima al problema, pero puede emplearse como cota pesimista en algoritmos de búsqueda y enumeración

Q: El algoritmo de ordenación Quicksort divide el problema en dos subproblemas. ¿Cuál es la complejidad temporal asintótica de realizar esa división?
A: 1
C: Junio 2024
O: $O(\log n)$
O: $O(n)$
O: $O(n \log n)$

Q: ¿Cuál es la complejidad temporal asintótica de la función $f$? (en la primera llamada, el parámetro $i$ toma valor $n-1$; el tamaño de los vectores $w$ y $v$ es $n$)
```cpp
float f(vector<float> &w, vector<unsigned> &v, unsigned P, int i) {
  float S1 = 0, S2;
  if (i >= 0) {
    if (w[i] <= P)
      S1 = v[i] + f(w, v, P - w[i], i - 1);
    S2 = f(w, v, P, i - 1);
    return max(S1, S2);
  }
  return 0;
}
```
A: 1
C: Junio 2024
O: $\Omega(n)$ y $O(n^2)$
O: $\Omega(n)$ y $O(2^n)$
O: $\Theta(2^n)$

Q: Dada la siguiente función:
```cpp
void f(vector<int> &v) {
  int i = 1, n = v.size();
  bool swaped = true;
  while (swaped) {
    swaped = false;
    for (int j = n - 1; j >= i; j--)
      if (v[j] < v[j - 1]) {
        swap(v[j], v[j - 1]);
        swaped = true;
      }
    i++;
  }
}
```
De las siguientes afirmaciones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A: 2
C: Junio 2024
O: El peor de los casos ocurre cuando el primer elemento del vector es estrictamente mayor que los restantes sin importar el orden de los demás
O: La complejidad temporal en el peor de los casos viene dada por la expresión $\sum_{i=1}^{n}(n-i)$
O: La complejidad temporal en el mejor de los casos ocurre cuando el vector está vacío

Q: Disponemos de dos algoritmos que queremos comparar. Hemos calculado la función de complejidad del algoritmo A contando operaciones elementales, y del algoritmo B contando pasos de programa. ¿Podemos comparar ambas funciones para decidir qué algoritmo es mejor?
A: 1
C: Junio 2024
O: No, porque al contar operaciones elementales, podríamos obtener una complejidad asintótica mayor que si contamos pasos de programa.
O: Sí, pero solo podremos comparar sus clases de notación asintótica
O: Sí, ambos métodos son totalmente equivalentes. El mejor algoritmo será aquel con la menor función

Q: Tenemos un vector ordenado y queremos comprobar si contiene un elemento dado. ¿Cuál sería la complejidad temporal más ajustada para hacerlo?
A: 1
C: Junio 2024
O: El tamaño del vector
O: El logaritmo del tamaño del vector
O: Constante con el tamaño del vector

Q: En la resolución mediante ramificación y poda del problema del camino de coste mínimo, obtenemos para un nodo determinado, una cota pesimista parcial estrictamente menor que su cota optimista. ¿Qué quiere decir esto?
A: 2
C: Junio 2024
O: Que el nodo debe expandirse
O: Que el nodo no debe expandirse
O: Que hay un error en alguna de las dos cotas

Q: ¿Qué expresión refleja mejor la complejidad asintótica respecto a $n$ del siguiente fragmento de código?
```cpp
int k = 0;
for (int a = 1; a < n; a *= 2)
  for (int b = 0; b < a; b += 1)
    k++;
```
A: 0
C: Junio 2024;Julio 2024
O: $\sum_{a=1}^{\log n} 2^a$
O: $\sum_{a=1}^{n-1} \sum_{b=0}^{a-1} 1$
O: $\sum_{a=1}^{n-1} \frac{n}{2}$

Q: ¿Se puede reducir el coste temporal de un algoritmo recursivo almacenando los resultados devueltos por las llamadas recursivas?
A: 2
C: Junio 2024
O: No, ello no reduce el coste temporal ya que las llamadas recursivas se deben realizar de cualquier manera
O: No, solo se puede reducir el coste convirtiendo el algoritmo recursivo en iterativo
O: Sí, si se repiten llamadas a la función con los mismos argumentos

Q: Resolviendo el problema de la composición de funciones mediante Ramificación y Poda, declaramos el nodo y la cola de prioridad como sigue:
```cpp
using Node = tuple<short, int>;
priority_queue<Node> pq;
```
Cada nodo contiene, en este orden, el número de veces que se ha aplicado una función y el resultado obtenido. ¿Qué se puede afirmar sobre el orden en el que se extraen los nodos de la cola de prioridad?
A: 2
C: Junio 2024;Julio 2024
O: No podemos afirmar nada, pues no hemos definido ningún criterio para la ordenación de la cola
O: Que se extraerán en un orden que permite encontrar pronto la solución óptima
O: Que se extraerán en un orden que dificulta encontrar pronto la solución óptima

Q: Dada la versión general del problema del camino de coste mínimo, ¿cuál de las estrategias siguientes proveería de una cota optimista para ramificación y poda?
A: 1
C: Junio 2024
O: Suponer que solo nos vamos a mover en tres direcciones (como en el caso restringido).
O: Suponer que ya no se van a realizar más movimientos.
O: Las otras dos estrategias son ambas válidas.

Q: Queremos utilizar el algoritmo heapsort para ordenar un vector de manera descendente (de mayor a menor). ¿Cómo serían las complejidades temporales asintóticas de construir el heap en estos dos supuestos: (1) el vector que recibe está ordenado ascendente; (2) el vector que recibe está ordenado descendente?
A: 0
C: Junio 2024
O: Iguales
O: La del primer supuesto mayor que la del segundo
O: La del segundo supuesto mayor que la del primero

Q: Queremos resolver el problema general del camino de coste mínimo. Supón que estamos usando una función $f$ como cota optimista y funciona correctamente. ¿Qué pasaría si, en el fuente, multiplicamos esta función por $1,1$. Marca la falsa.
A: 2
C: Junio 2024
O: Podría perderse la solución óptima pero la que obtendríamos no se alejaría mucho de ella
O: El programa terminaría más rápido
O: Seguiría funcionando bien pero sería más lento

Q: Si $f \in \Omega(g_1)$ y $f \in \Omega(g_2)$ entonces siempre se cumplirá: de las siguientes conclusiones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A: 1
C: Junio 2024
O: $f \in \Omega(\min(g_1, g_2))$
O: $f \in \Omega(g_1 \cdot g_2)$
O: $f \in \Omega(g_1 + g_2)$

Q: ¿Qué estructura de datos se suele utilizar para almacenar el árbol de búsqueda completo en un algoritmo de ramificación y poda?
A: 1
C: Junio 2024
O: Una cola de prioridad
O: Ninguna, no se almacena
O: Un árbol cuya aridad depende del problema

Q: En clase vimos una demostración que justificaba que el esquema voraz es adecuado para resolver el problema de la mochila continua (con fraccionamiento). Entre otros posibles motivos ¿Por qué esa misma demostración no sirve para el problema de la mochila discreta seleccionando objetos de la misma manera?
A: 0
C: Junio 2024
O: Las otras dos opciones son ambas ciertas.
O: Porque no hay garantía de que la solución esté formada por una secuencia compuesta únicamente de unos y, a continuación, otra secuencia compuesta únicamente de ceros
O: Porque no hay garantía de que la mochila se llene

Q: Dada la solución por programación dinámica recursiva de la versión restringida del problema del camino de coste mínimo, en general, ¿cuántas veces se llega al caso base de la recursión (la casilla inicial)?
A: 0
C: Junio 2024
O: Solo una
O: Un valor que es $O(2^n)$, donde $n$ es el tamaño del mapa
O: Un valor que es $O(n)$, donde $n$ es el tamaño del mapa

Q: ¿Garantiza la estrategia de divide y vencerás una solución de complejidad temporal polinómica a cualquier problema?
A: 0
C: Junio 2024;Julio 2024
O: No, la complejidad temporal puede ser incluso peor que cualquier función polinómica
O: Sí, en cualquier caso
O: Sí, pero siempre que la complejidad temporal conjunta de las operaciones de descomposición del problema y la combinación de las soluciones sea polinómica

Q: ¿Cuál de estas estrategias para calcular el $n$-ésimo elemento de la serie de Fibonacci ($f(n) = f(n-1) + f(n-2)$, $f(1) = f(2) = 1$) es más eficiente?
A: 2
C: Junio 2024
O: La estrategia divide y vencerás
O: Para este problema, las dos estrategias citadas serían similares en cuanto a eficiencia
O: Programación dinámica

Q: Queremos resolver la versión general del problema del camino de coste mínimo por ramificación y poda. Para ello se usa una estrategia que consiste en priorizar las expansiones de los nodos que contienen un camino explorado de menor coste. ¿Qué podemos decir del algoritmo resultante?
A: 0
C: Junio 2024;Julio 2024
O: Que la primera hoja a la que se llegue es la solución del problema y por lo tanto ya no será necesario explorar más nodos de la lista de nodos vivos, aunque no esté vacía.
O: Que el recorrido en el árbol de búsqueda será equivalente a un recorrido por niveles, por lo que no es necesario utilizar una cola de prioridad.
O: Las otras dos opciones son ambas ciertas.

Q: Si comparamos la cota pesimista y la optimista de un mismo nodo. ¿Qué podríamos saber?
A: 1
C: Junio 2024
O: Si el nodo debe ser descartado
O: El intervalo en el que se encuentra la mejor solución que se puede obtener con ese nodo
O: Si el nodo es prometedor

Q: Cuando se usa un algoritmo voraz para abordar la resolución de un problema de optimización por selección discreta (es decir, un problema para el cual la solución consiste en encontrar un subconjunto del conjunto de elementos que optimiza una determinada función), ¿cuál de estas tres cosas es imposible que ocurra?
A: 0
C: Junio 2024
O: Que se reconsidere la decisión ya tomada anteriormente respecto a la selección de un elemento a la vista de la decisión que se debe tomar en un instante
O: Que el algoritmo no encuentre ninguna solución
O: Que la solución no sea la óptima

Q: ¿Qué tienen en común el algoritmo que obtiene el $k$-ésimo elemento más pequeño de un vector (estudiado en clase) y el algoritmo de ordenación Quicksort?
A: 1
C: Junio 2024
O: La combinación de las soluciones a los subproblemas
O: La división del problema en subproblemas
O: El número de llamadas recursivas que se hacen

Q: Cuando se resuelve el problema de la mochila discreta usando la estrategia de vuelta atrás, ¿puede ocurrir que se tarde menos en encontrar la solución óptima si se prueba primero a meter cada objeto antes de no meterlo?
A: 0
C: Junio 2024;Julio 2024
O: Sí, pero solo si se usan cotas optimistas para podar el árbol de búsqueda
O: Sí, tanto si se usan cotas optimistas para podar el árbol de búsqueda como si no
O: No, ya que en cualquier caso se deben explorar todas las soluciones factibles

Q: ¿Cuál es la relación de recurrencia asociada a la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
  if (n == 0)
    return 1;
  return 2 * f(n - 1);
}
```
A: 2
C: Junio 2024
O: $T(n) = 1 + 2 \cdot T(n-1)$; $T(0) = 1$
O: $T(n) = 2 \cdot T(n-1)$; $T(0) = 1$
O: $T(n) = 1 + T(n-1)$; $T(0) = 1$

Q: El siguiente programa resuelve el problema de cortar un tubo de longitud $n$ en segmentos de longitud entera entre 1 y $n$ de manera que se maximice el precio de acuerdo con una tabla $p$ que da el precio para cada longitud, pero falta un trozo. ¿Qué debería ir en lugar de XXXXXXX?
```cpp
int tube_cut(const vector<int> &p, const int n) {
  if (n == 0)
    return 0;
  int q = numeric_limits<int>::lowest();
  for (int i = 1; i <= n; i++)
    q = max(q, p[i] + tube_cut(XXXXXXX));
  return q;
}
```
A: 1
C: Junio 2024
O: p,n-1
O: p,n-i
O: p,i

Q: Usando la técnica de programación dinámica con ahorro de memoria ¿podría acelerarse el programa usando tres vectores en vez de dos?
A: 2
C: Junio 2024
O: Sí, pero sería a expensas de usar más memoria
O: Sí, pero la complejidad temporal seguiría siendo la misma
O: No

Q: En un problema de minimización mediante Vuelta Atrás, empleamos una cota optimista que es mucho mayor que la mejor solución que podría alcanzarse desde un nodo determinado. Como consecuencia:
A: 0
C: Junio 2024
O: Es posible que no encontremos el óptimo
O: El programa será más lento que con otra cota optimista
O: Dicha decisión tendrá un impacto mínimo en el tiempo de ejecución del programa, puesto que es más importante elegir una buena cota pesimista inicial

Q: Un problema tiene subestructura óptima cuando...
A: 0
C: Junio 2024
O: ...su solución se puede construir eficientemente a partir de soluciones de subproblemas suyos
O: ...es posible escribir una solución voraz para el problema
O: ...es posible dividir su tamaño de forma equitativa para construir cada uno de los subproblemas

Q: En el esquema de vuelta atrás, el orden en el que se van asignando los distintos valores a las componentes del vector que contendrá la solución...
A: 2
C: Junio 2024;Julio 2024
O: ...es irrelevante si no se utilizan mecanismos de poda basados en la mejor solución hasta el momento
O: ...puede ser relevante si se utilizan mecanismos de poda basados en estimaciones optimistas
O: Las otras dos opciones son ambas ciertas

Q: En la solución de ramificación y poda del problema del camino de coste mínimo, ¿para qué puede resultar útil la técnica de poda con memoria?
A: 1
C: Junio 2024;Julio 2024
O: Para obtener cotas pesimistas
O: Para evitar la formación de ciclos
O: Para ambas cosas

Q: En un algoritmo de ramificación y poda se puede usar una cota optimista para estimar el coste restante desde el nodo actual hasta el objetivo. ¿Qué propiedad debe cumplir esta cota para asegurar que siempre se encontrará la solución óptima?
A: 0
C: Junio 2024
O: Nunca sobreestimar el coste real
O: Debe disminuir a medida que se acerca al objetivo
O: Las dos anteriores son ciertas

Q: ¿Cuál es la mejor complejidad temporal y espacial, en función de $n$, que se puede obtener en la solución de programación dinámica para el problema (visto en clase) de cortar un tubo de longitud $n$ en segmentos de longitud entera entre 1 y $n$ de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud?
A: 0
C: Junio 2024;Julio 2024
O: Temporal $\Theta(n^2)$ y espacial $\Theta(n)$
O: Temporal y espacial $\Theta(n)$
O: Temporal y espacial $\Theta(n^2)$

Q: En un algoritmo de ramificación y poda, el orden escogido para priorizar los nodos en la lista de nodos vivos...
A: 2
C: Junio 2024;Julio 2024
O: ...nunca afecta al tiempo necesario para encontrar la solución óptima
O: ...determina la complejidad temporal en el peor de los casos del algoritmo
O: ...puede influir en el número de nodos que se descartan sin llegar a expandirlos

Q: Queremos resolver la versión general del problema del camino de coste mínimo mediante ramificación y poda. Para obtener la cota optimista de un nodo cualquiera procedemos así: calculamos el número de casillas que quedan, por la diagonal derecha–abajo, hasta llegar a una pared del mapa. A ese valor le sumamos el número de casillas que podrían quedar desde esa pared hasta la salida utilizando únicamente movimientos del tipo abajo o derecha, según corresponda (distancia de Chebishev). ¿Qué podemos decir acerca de la cota optimista que se obtendría?
A: 0
C: Junio 2024
O: Que solo será una cota optimista válida si se asegura que todas las casillas tengan un coste mínimo de 1.
O: Que solo será una cota optimista válida si se asegura que todas las casillas tengan un coste mínimo de 0.
O: Que solo será una cota optimista válida si las casillas contienen valores reales mayores que 0.0.

Q: ¿Cuál de los siguientes algoritmos de ordenación funciona más rápido para ordenar vectores muy grandes que ya están casi ordenados?
A: 0
C: Junio 2024
O: Quicksort empleando el primer elemento como pivote
O: Heapsort
O: Ambos por igual

Q: ¿A qué esquema de entre los estudiados pertenece la siguiente función?
```cpp
void g(vector<unsigned> &v, unsigned j) {
  if (j == v.size())
    return;
  for (unsigned i = j; i < v.size(); i++) {
    swap(v[j], v[i]);
    g(v, j + 1);
    swap(v[j], v[i]);
  }
}
```
A: 2
C: Junio 2024
O: Programación dinámica
O: Ramificación y poda
O: Vuelta atrás

Q: En general ¿cuál de los siguientes problemas tiene solución eficiente utilizando alguno de los esquemas algorítmicos estudiados durante el curso?
A: 1
C: Julio 2024
O: La mochila discreta (0/1) sin restricciones adicionales
O: La mochila discreta (0/1) con pesos discretos
O: La mochila discreta (0/1) con valores discretos

Q: Si $f(n) \in \Theta(2^n)$, ¿podemos decir siempre que $f(n) \in O(n!)$?
A: 0
C: Julio 2024
O: Sí, ya que $2^n \in O(n!)$
O: Sí, ya que $2^n \in \Omega(n!)$
O: No, ya que $2^n \notin O(n!)$

Q: Dada la versión general del problema del camino de coste mínimo, ¿cuál de las estrategias siguientes proveería de una cota optimista para ramificación y poda?
A: 2
C: Julio 2024
O: Tomar la dificultad del camino parcial (hasta el nodo en cuestión) y sumarle la dificultad del camino que, desde el nodo en cuestión, se completa siguiendo un algoritmo voraz que solo toma los movimientos de la versión restringida
O: Tomar la dificultad del camino parcial (hasta el nodo en cuestión) y nada más
O: Las otras dos estrategias son ambas válidas.

Q: En cuanto al cálculo de la complejidad temporal en función de $n$ de la siguiente función:
```cpp
void f(unsigned n) {
  if (n > 1) {
    for (unsigned i = 0; i < 4; i++)
      f(n / 2);
  }
}
```
De las siguientes afirmaciones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A: 0
C: Julio 2024
O: El tamaño del problema viene dado por el valor que toma $n$
O: El mejor de los casos ocurre cuando $n = 0$ y su complejidad temporal está en $\Omega(1)$
O: La complejidad temporal asintótica está en $\Theta(n^2)$

Q: Dada la versión general del problema mcp, en cuanto al valor de una cota pesimista de un nodo cualquiera... de las siguientes afirmaciones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A: 0
C: Julio 2024
O: ...debe corresponder con la dificultad de un camino completado, es decir, que comienza en $(0,0)$ y termina en $(n-1,m-1)$
O: ...debe ser inferior al de una cota optimista de cualquier otro nodo
O: ...debe ser superior al de una cota optimista de cualquier otro nodo

Q: Sobre estas dos alternativas para la programación dinámica: recursiva con memoización, e iterativa, podemos afirmar lo siguiente:
A: 2
C: Julio 2024
O: Ambas calculan siempre todos los valores del almacén
O: Según el problema, la iterativa puede calcular menos valores del almacén que la recursiva
O: Según el problema, la recursiva puede calcular menos valores del almacén que la iterativa

Q: De las siguientes tres afirmaciones, una es cierta y dos falsas, o bien una es falsa y dos son ciertas. Marca la que en ese sentido es diferente a las otras dos.
A: 1
C: Julio 2024
O: El problema de la mochila continua no se puede resolver de forma análoga a como se resuelve el problema de la mochila discreta
O: El problema de la mochila continua no se puede resolver mediante la técnica de ramificación y poda pues se podría producir un número infinito de ramas
O: El problema de la mochila discreta no se puede resolver mediante la técnica de divide y vencerás

Q: ¿Cuál de las siguiente técnicas NO resuelve la versión general del problema del camino de coste mínimo? (según lo visto en clase)
A: 2
C: Julio 2024
O: Ramificación y poda
O: Programación dinámica
O: Vuelta atrás

Q: Dados dos vectores ordenados de $n$ elementos, ¿cuál es el coste del mejor algoritmo que se puede escribir para obtener un vector ordenado que contenga todos los elementos de los dos vectores?
A: 1
C: Julio 2024
O: $\Theta(\log n)$
O: $\Theta(n)$
O: $\Theta(n^2)$

Q: Queremos resolver un problema parecido la versión restringida del problema del camino de coste mínimo pero ahora permitimos (además) movimientos de dos pasos en las mismas direcciones. ¿Cómo se podría resolver este problema?
A: 0
C: Julio 2024
O: Usando programación dinámica, de una forma muy parecida al original
O: Ya no se podría resolver usando programación dinámica y habría que recurrir a la vuelta atrás
O: No se puede resolver ni usando programación dinámica ni vuelta atrás

Q: Entre dos algoritmos para solucionar el mismo problema, siempre debemos elegir:
A: 2
C: Julio 2024
O: Aquel con menor complejidad asintótica en el mejor caso
O: Aquel con menor complejidad asintótica en el peor caso
O: Si conocemos la talla máxima del problema que pretendemos resolver, es posible que un algoritmo con mayor complejidad asintótica se comporte mejor para nuestro problema

Q: El algoritmo de ordenación Mergesort divide el problema en dos subproblemas. ¿Cuál es la complejidad temporal asintótica de realizar esa división?
A: 2
C: Julio 2024
O: $O(\log n)$
O: $O(n)$
O: $O(1)$

Q: Dada la versión restringida del problema mcp resuelto mediante programación dinámica iterativa, ¿cuál es la complejidad temporal del fragmento de código que cumplimenta únicamente las celdas del almacén que corresponden a su contorno (caso base)? (suponiendo que el caso base corresponde a los casos $n = 0$ o $m = 0$)
A: 1
C: Julio 2024
O: $\Theta(m)$
O: $\Theta(\max\{n, m\})$
O: $\Theta(\min\{n, m\})$

Q: Queremos resolver la versión restringida del problema del camino de coste mínimo usando una técnica de vuelta atrás.
A: 2
C: Julio 2024
O: Eso no se puede hacer, ese problema no se puede resolver usando vuelta atrás
O: La técnica de vuelta atrás se podría aplicar, pero siempre sería más lento que si usamos programación dinámica
O: La técnica de vuelta atrás se podría aplicar, incluso en algunos raros casos podría ir más rápido que usando programación dinámica

Q: Dada la versión restringida del problema mcp, queremos listar todos los caminos posibles (sean o no los óptimos). ¿qué técnica deberíamos utilizar?
A: 1
C: Julio 2024
O: Memoización
O: Divide y vencerás
O: Programación dinámica iterativa

Q: Dada la versión general del problema mcp ¿cuál es la mejor complejidad temporal (de entre las indicadas) con la que podría obtenerse una cota pesimista para el nodo inicial del árbol de búsqueda?
A: 2
C: Julio 2024
O: $\Omega(n + m)$
O: $\Omega(nm)$
O: $\Omega(1)$

Q: Decid cuál de estas tres es la cota pesimista más ajustada al valor óptimo de la mochila discreta:
A: 1
C: Julio 2024
O: El valor de la mochila continua correspondiente
O: El valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor específico de los objetos
O: El valor de una mochila que contiene todos los objetos restantes aunque se pase del peso máximo permitido

Q: Si en el problema del camino de coste mínimo, estudiado en prácticas, permitiéramos casillas con coste 0, ¿cuál de las siguientes distancias sería una cota optimista válida si se la sumamos al coste del camino actual? $(i,j)$ es la posición actual y $(n,m)$ el número de filas y columnas, respectivamente, del mapa.
A: 2
C: Julio 2024
O: $\max(n-1-i, m-1-j)$
O: $(n-1-i) + (m-1-j)$
O: Ninguna de las anteriores

Q: Si el coste espacial de un algoritmo viene dado por la recurrencia $T(n) = n + T(n/2)$ siendo $T(0) = 1$, donde $n$ es el tamaño del problema, ¿a qué clase de complejidad pertenece?
A: 0
C: Julio 2024
O: $O(n)$
O: $O(n \log n)$
O: $O(n^2)$

Q: Indica cuál de las siguientes afirmaciones es cierta:
A: 1
C: Julio 2024
O: Si un esquema de ramificación y poda encuentra la solución óptima a un problema, un esquema de vuelta atrás también la encuentra siempre.
O: Si un esquema de ramificación y poda encuentra la solución óptima a un problema, un esquema de vuelta atrás podría no encontrarla.
O: Si un esquema de ramificación y poda encuentra la solución óptima a un problema, un esquema de vuelta atrás siempre es más ineficiente.

Q: En un algoritmo de ramificación y poda, si la lista de nodos vivos no está ordenada de forma apropiada...
A: 2
C: Julio 2024
O: ...podría ocurrir que se descarten nodos factibles
O: ...podría ocurrir que se pode el nodo que conduce a la solución óptima
O: ...podría ocurrir que se exploren nodos de forma innecesaria

Q: Para resolver el problema del árbol de recubrimiento mínimo en un grafo con pesos no negativos, ¿qué algoritmo es más eficiente en términos de complejidad temporal si el grafo es denso? (tiene muchos arcos con respecto a los vértices)
A: 1
C: Julio 2024
O: Algoritmo de Kruskal
O: Algoritmo de Prim
O: Da igual

Q: ¿Qué se necesita para realizar la poda basada en la mejor solución hasta el momento?
A: 1
C: Julio 2024
O: Un almacén donde se guarda el mejor valor con el que se llega a cada nodo del árbol de búsqueda
O: Una manera de calcular una cota optimista para cada nodo, además de la propia mejor solución hasta el momento
O: Una manera de calcular una cota optimista para cada nodo y una manera de calcular una cota pesimista del mismo nodo, además de la propia mejor solución hasta el momento

Q: Estamos ante un nodo del árbol de búsqueda de ramificación y poda y hemos decidido no explorarlo. ¿Qué podría haber ocurrido?
A: 2
C: Julio 2024
O: Que sus cotas, optimista y pesimista, han coincidido en el mismo valor
O: Que su cota pesimista no mejora la mejor solución encontrada hasta el momento
O: Podría haber ocurrido cualquiera de las otras dos alternativas

Q: En la resolución mediante ramificación y poda del problema del camino de coste mínimo, ordenamos ascendentemente las casillas del mapa por coste. Dado un nodo parcial (o nodo incompleto), sumamos al coste del camino que llevamos hasta el momento, la suma de las $k$ casillas con menor coste, siendo $k = \max(n-1-i, m-1-j)$. $(i,j)$ es la posición actual y $(n,m)$ el número de filas y columnas del mapa. El valor obtenido es:
A: 0
C: Julio 2024
O: Una cota optimista
O: Una cota pesimista
O: Ninguna de las anteriores
