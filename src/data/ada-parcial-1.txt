¿Cuál es el objetivo de la etapa de análisis en el Diseño y Análisis de un Algoritmo?: 
2
Determinar el lenguaje y herramientas disponibles para su desarrollo. 
Estimar los recursos que consumirá el algoritmo una vez implementado.
Estimar la potencia y características del equipo informático necesarios para el correcto funcionamiento del algoritmo. 

¿Cuál de las siguientes jerarquías de complejidades es la correcta? 
3
O(1)⊂O(lg n)⊂O(lg lg n) ⊂ ... 
... ⊂ (n!)⊂O(2^n) ⊂O(n^n) 
... ⊂ (2^n)⊂O(n!) ⊂O(n^n) 

¿Cuál de los siguientes algoritmos de ordenación tiene menor complejidad? 
3
Burbuja 
Inserción directa
Mergesort

¿El tiempo de ejecución de un algoritmo depende de la talla del problema? 
3
Sí, siempre 
No, nunca 
No necesariamente

Ordena de menor a mayor las siguientes complejidades \n\t1. O(1) \n\t2. O(n^2) \n\t3. O(nlgn) \n\t4. O(n!) 
2
3, 1, 2 y 4
1, 3, 2 y 4
1, 3, 4 y 2

El estudio de la complejidad resulta realmente interesante para tamaños grandes de problema por varios motivos: 
3
Las diferencias reales en tiempo de compilación de algoritmos con diferente coste para tamaños pequeños del problema no suelen ser muy significativas. 
Las diferencias reales en tiempo de ejecución de algoritmos con diferente coste para tamaños grandes del problema no suelen ser muy significativas. 
Ninguna de las anteriores. 

¿Por que se emplean funciones de coste para expresar el coste de una algoritmo? 
2
Para poder expresar el coste de los algoritmos con mayor exactitud 
Para que la expresión del coste del algoritmo sea válida para cualquier entrada al mismo
Para poder expresar el coste de un algoritmo mediante una expresión matemática

El caso base de una ecuación de recurrencia asociada a la complejidad temporal de un algoritmo expresa:
3
El coste de dicho algoritmo en el mejor de los casos. 
El coste de dicho algoritmo en el peor de los casos.
Ninguna de las anteriores.

La complejidad de la función TB es: ```función TB (A: vector[λ]; iz , de : N) : N \nvar n,i:N; \n\tn=iz-de+1 \n\topcion \n\t\t(n < 1) : devuelve ( 0 ) ; \n\t\t(n = 1) : devuelve ( 1 ) ; \n\t\t(n > 1) : si (A[iz] = A[de]) entonces \n\t\t\t\tdevuelve (TB( A, iz + 1, de - 1 ) + 1); \n\t\t\tsino \n\t\t\t\tdevuelve (TB( A, iz + 1, de - 1 )) ; \n\t\t\tfinsi ; \n\tfopcion \nfin ```
1
Θ (n)
Θ (n · lg n) 
Θ (n^2 · lg n)

Dado el polinomio $$f(n)= a_mn^m + a_{m-1}n^{m-1} + … + a_0,$$ con $$a_m \in{R^+}$$ entonces f pertenece al orden:
3
$$O(n^m)$$. 
$$Ω(n^m)$$.
Las dos respuestas anteriores son correctas.

Si $$f1(n) \in{ Ο(g1(n))}$$ y $$f2(n) \in{ Ο(g2(n))}$$ entonces:
2
$$f1(n)·f2(n) \in{ Ο(maximo(g1(n),g2(n)))}$$
$$f1(n)·f2(n) \in{ Ο (g1(n)· g2(n))}$$
Ambas son correctas 

Si $$f1(n) \in{ Ο(g1(n))}$$ y $$f2(n) \in{ Ο(g2(n))}$$ entonces:
3
$$f1(n)+f2(n) \in{ Ο(maximo(g1(n),g2(n)))}$$ 
$$f1(n)+f2(n) \in{ Ο (g1(n)+g2(n))}$$
Ambas son correctas 

Un algoritmo cuya talla es n y que tarda $$40^n$$ segundos en resolver cualquier instancia tiene una complejidad temporal:
2
$$\Theta{( n^n )}$$
$$\Theta{( 4^n )}$$
Ninguna de las anteriores

Si dos algoritmos tienen la misma complejidad asintótica:
1
No necesitan exactamente el mismo tiempo para su ejecución. 
Necesitan exactamente el mismo tiempo para su ejecución.
Ninguna de las anteriores 

Los algoritmos directos de ordenación, respecto de los indirectos:
1
Presentan una mayor complejidad temporal y sus tiempos de ejecución absolutos son mayores. 
Presentan una menor complejidad temporal y sus tiempos de ejecución absolutos son menores.
Presentan una mayor complejidad temporal si bien sus tiempos de ejecución absolutos son menores. 

La talla o tamaño de un problema depende de: 
3
Conjunto de valores asociados a la entrada y salida del problema.
Conjunto de valores asociados a la salida del problema.
Conjunto de valores asociados a la entrada del problema.

En un algoritmo recursivo, la forma de dividir el problema en subproblemas:
2
Influye en la complejidad espacial del mismo. 
Influye en su complejidad temporal.
No influye en ninguna de sus complejidades. 

$$f(n) = 5n+3m·n +11$$ entonces $$f(n)$$ pertenece a: 
3
$$O (n·m)$$. 
$$O (n^m)$$.
Las dos son correctas

El sumatorio, desde $$i=1$$ hasta n, de $$i^k$$ pertenece a:
1
$$Ο(n^{k+1})$$ 
$$Ο(n^k)$$
Ninguna de las anteriores 

La complejidad de la función A2 es: ```Funcion A2 (n, a: entero):entero; \nVar r: entero; fvar \n\tsi (a² > n) devuelve 0 \n\tsino \n\t\tr:= A2(n, 2a); \n\t\topción \n\t\t\tn < a²: devuelve r; \n\t\t\tn ≥ a² : devuelve r + a; \n\t\tfopción \n\tfsi \nfin```
2
$$O(\sqrt{n} · a)$$
$$O( \sqrt{n} / a)$$
$$O( n / \sqrt{a} )$$

Cual de las siguientes definiciones es cierta: 
1
Las cotas de complejidad se emplean cuando para una misma talla se obtienen diferentes complejidades dependiendo de la entrada al problema.
Las cotas de complejidad se emplean cuando para diferentes tallas se obtienen diferentes complejidades dependiendo de la entrada al problema.
Ninguna de las anteriores 

Cuando para distintas instancias de problema con el mismo tamaño no obtenemos el mismo resultado: 
3
No es posible calcular la complejidad a priori y debemos ejecutar el programa varias veces con la misma talla y obtener el tiempo medio para hallar la complejidad media. 
No se puede aplicar la técnica de paso de programa, ya que esta técnica es para calcular la complejidad a priori. 
Calculamos el máximo y mínimo coste que nos puede dar el algoritmo.

$$f(n) = 5n+5$$ ¿ $$f(n)$$ pertenece a $$O(n)$$? 
3
Si. El valor de c es 5 y el valor mínimo de n_0 es de 3 
Si. El valor de c es 9 y el valor mínimo de n_0 es de 1
Si. El valor de c es 6 y el valor mínimo de n_0 es de 5

$$f(n) = 10n+7$$ ¿ $$f(n)$$ pertenece a $$O(n 2)$$$? 
2
Si. Para c = 1 y a partir de un valor de n_0 =10. 
Sí Para cualquier valor de c positivo siempre existe un n_0 a partir del que se cumple. 
No. 

Si f(n) ∈ Ω (g(n)) entonces:
1
∃ c, n_0 ∈ R^+ : f(n) ≥ c· g(n) ∀ n ≥ n_0
∃ c, n_0 ∈ R^+ : f(n) ≥ c· g(n) ∀ n
∃ c, n_0 ∈ R^+ : f(n) ≤ c· g(n) ∀ n ≥ n_0

El coste asociado a la siguiente ecuación de recurrencia es: \n$$f(n) = \begin{cases} 1 & n \leq 1 \\ n + f(\frac{n}{2}) + f(\frac{n}{2}) & n > 1 \end{cases}$$
3
Θ(n lg n^2) 
Θ(n^2 lg n) 
Θ(n lg n)

Un algoritmo recursivo basado en el esquema divide y vencerás...
1
... será más eficiente cuanto más equitativa sea la división en subproblemas.
Las demás opciones son verdaderas.
... nunca tendrá una complejidad exponencial.

Indicad cuál de estas tres expresiones es falsa.
2
Θ(n / 2) = Θ(n)
Θ(n) ⊆ Θ(n^2)
Θ(n) ⊆ Θ(n)

¿Cuál de estas tres expresiones es falsa?
3
3n^2 + 1 ∈ O(n^3)
n + n log(n) ∈ Ω(n)
n + n log(n) ∈ Θ(n)

Indica cuál es la complejidad en el peor caso de la función replace:```unsigned bound( const vector<int>& v ) {\n\tfor( unsigned i = 0; i < v.size(); i++ )\n\t\tif( v[i] == '0')\n\t\t\treturn i;\n\treturn v.size();\n}\n\nvoid replace( vector<int>& v, int c ) {\n\tfor( unsigned i = 0; i < bound(v); i++)\n\t\tv[i] = c;\n}\n```
2
O(n log n)
O(n^2)
O(n)

¿Cuál es la complejidad temporal de la siguiente función recursiva?```unsigned desperdicio (unsigned n){ \n\tif (n<=1) \n\t\treturn 0; \n\tunsigned sum = desperdicio(n/2) + desperdicio(n/2); \n\tfor (unsigned i=1; i<=n-1; i++) \n\t\tfor (unsigned j=1; j<=i; j++) \n\t\t\tsum+=1; \n\treturn sum; \n} \n```
1
Θ(n^2)
Θ(2^n)
Θ(n^2 log n)

Sea f(n) la solución de la relación de recurrencia f(n) = 2f(n/2) + 1; f(1) = 1. Indica cual de estas tres expresiones es cierta.
1
f(n) ∈ Θ(n)
f(n) ∈ Θ(n^2)
f(n) ∈ Θ(n log n)

Considerad estos dos fragmentos:```s=0; for(i=0;i<n;i++) s+=i;``` y ```s=0; for(i=0;i<n;i++) if (a[i] != 0) s+=i;``` y un array a[i] de números enteros. Indicad cuál de estas tres afirmaciones es cierta:
2
El coste temporal asintótico del primer programa en el caso peor es más alto que en el segundo.
El coste temporal asintótico, tanto en el caso mejor como en el caso peor, de los dos programas es el mismo.
El coste temporal asintótico del segundo programa en el caso peor es más alto que en el primero.

Indica cual es la complejidad, en función de n, del fragmento siguiente:```int a = 0; \nfor( int i = 0; i < n; i++ ) \n\tfor( int j = i; j > 0; j /= 2 ) \n\t\ta += a[i][j];```
1
O(n log n)
O(n)
O(n^2)

Indica cuál es la complejidad en función de n, donde K es una constante (no depende de n ), del fragmento siguiente:```for( int i = K; i < n - K; i++ ){ \n\tA[i] = 0; \n\tfor( int j = i - K; j < i + K; j++ ) \n\t\tA[i] += B[j]; \n}```
1
O(n)
O(n log n)
O(n^2)

Pertenece $$3n^2 + 3$$ a $$O(n^3)$$?
3
Solo para c = 1 y n_0 = 5.
No.
Sí.

La complejidad temporal en el mejor de los casos...
3
Las demás opciones son verdaderas.
... es el tiempo que tarda el algoritmo en resolver la talla más pequeña que se le puede presentar.
... es una función de la talla que tiene que estar definida para todos los posibles valores de esta.

La versión de Quicksort que utiliza como pivote la mediana del vector...
3
... se comporta mejor cuando el vector ya está ordenado.
... se comporta peor cuando el vector ya está ordenado.
... El hecho de que el vector estuviera previamente ordenado o no, no influye en la complejidad temporal de este algoritmo.

Dada la siguiente relación de recurrencia, ¿Qué cota es verdadera? \n\n$$f(n) = \begin{cases} 1 & n = 1 \\ \sqrt{n} + 3f(\frac{n}{3}) & n > 1 \end{cases}$$
1
f(n) ∈ Θ(n)
f(n) ∈ Θ(n^3)
f(n) ∈ Θ(√n log n)

Un problema de tamaño $$n$$ puede transformarse en tiempo $$O(n^2)$$ en nueve de tamaño $$n/3$$. Por otro lado, la solución al problema cuando la talla es $$1$$ requiere un tiempo constante. \n¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
2
O(n^2)
O(n^2 log n)
O(n log n)

Indica cuál es la complejidad, en función de $$n$$, del siguiente fragmento de código: ```s=0; for(i=0;i<n;i++) for(j=i;j<n;j++) s+=i*j;```
1
$$\Theta(n^2)$$
$$O(n^2)$$ pero no $$\Omega(n^2)$$
$$\Theta(n)$$

Sea ƒ(n) la solución de la relación de recurrencia ƒ (n) = 2ƒ(n-1)+1 ƒ(1) = 1. Indicad cuál de estas tres expresiones es cierta:
2
ƒ(n) ∈ Θ(n)
ƒ(n) ∈ Θ(2^n)
ƒ(n) ∈ Θ(n^2)

Un programa con dos bucles anidados uno dentro del otro, El primero hace $$n$$ iteraciones aproximadamente y el segundo la mitad, tarda un tiempo
2
$$O(n \log{n})$$
$$O(n^2)$$
$$O(n \sqrt{n})$$

Un problema de tamaño $$n$$ puede transformarse en tiempo $$O(\frac{n}{2})$$ en nueve de tamaño $$\frac{n}{3}$$; por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante. ¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
2
$$O(n \log n)$$
$$O(n^2 \log n)$$
$$O(n^2)$$

¿Cuál es la complejidad temporal de la siguiente función recursiva?```unsigned desperdicio (unsigned n){ \nif (n<=1) \n\treturn 0; \nunsigned sum = desperdicio (n/2) + desperdicio (n/2); \nfor (unsigned i=1; i<n-1; i++) \n\tfor (unsigned j=1; j<=i; j++) \n\t\tfor (unsigned k=1; k<=j; k++) \n\t\t\tsum+=i*j*k; \nreturn sum; \n}```
3
$$O(2^n)$$
$$O(n^3 \log n)$$
$$O(n^3)$$

Los algoritmos de ordenación Quicksort y Mergesort tienen en común ...
3
... que se ejecutan en tiempo O(n).
... que ordenan el vector sin usar espacio adicional.
... que aplican la estrategia de divide y vencerás.

Indica cuál es la complejidad de la función siguiente:```unsigned sum( const mat &A ) {    # A es una matriz cuadrada \n\tunsigned d = A.n_rows(); \n\tunsigned a = 0; \n\tfor( unsigned i = 0; i < d; i++ ) \n\t\tfor( unsigned j = 0; j < d; j++ ) \n\t\t\ta += A(i,j); \n\treturn a; \n}```
2
$$O(n^2)$$
$$O(n)$$
$$O(n \log n)$$

Indicad cuál de estas tres expresiones es falsa.
3
$$\Theta(n/2) = \space\space\space\space\space\space\space \Theta(n)$$
$$\Theta(n) \subseteq \space \Theta(n)$$
$$\Theta(n) \subseteq \space \Theta(n^2)$$

¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, una solución voraz óptima?
2
El árbol de cobertura de coste mínimo de un grafo conexo.
El problema de la mochila discreta o sin fraccionamiento.
El problema de la mochila continua o con fraccionamiento.

Los algoritmos de programación dinámica hacen uso ...
2
... de que la solución óptima se puede construir añadiendo a la solución el elemento óptimo de los elementos restantes, uno a uno.
... de que se puede ahorrar cálculos guardando resultados anteriores en un almacén. 
... de una estrategia trivial consistente en examinar todas las soluciones posibles.

Cuando se calculan los coeficientes binomiales usando la recursión $$\binom{n}{r} = \binom{n-1}{r} + \binom{n-1}{r-1} $$, con $$ \binom{n}{0} = \binom{n}{n} = 1 $$, qué problema se da y cómo se puede resolver?
3
La recursión puede ser infinita y por tanto es necesario organizarla según el esquema iterativo de programación dinámica.
Se repiten muchos cálculos y ello se puede evitar haciendo uso de una estrategia voraz.
Se repiten muchos cálculos y ello se puede evitar usando programación dinámica.

Sea $$f(n)$$ la solución de la relación de recurrencia $$f(n) = 2f(n/2) + n $$; $$ f(1) = 1 $$. Indicad cuál de estas tres expresiones es cierta.
3
$$ f(n) \in \Theta(n^2) $$
$$ f(n) \in \Theta(n) $$
$$ f(n) \in \Theta(n \log n) $$

Para que la complejidad de un algoritmo presente caso mejor y peor distintos ...
2
... es condición necesaria y suficiente que existan instancias distintas del problema con el mismo tamaño.
... es condición necesaria que existan instancias distintas del problema con el mismo tamaño.
... es condición suficiente que existan instancias distintas del problema con el mismo tamaño.

Indicad cuál de estas tres expresiones es cierta:
3
$$ O(n^2) \subseteq O(2^{\log(n)}) \subset   O(2^n) $$
$$ O(n^2) \subseteq O(2^{\log(n)}) \subseteq O(2^n) $$
$$ O(2^{\log(n)}) \subseteq O(n^2) \subseteq O(2^n) $$

La complejidad temporal en el mejor de los casos de un algoritmo recursivo...
2
... coincide con el valor del caso base de la ecuación de recurrencia que expresa la complejidad temporal del algoritmo.
Las demás opciones son falsas. 
... siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo.

Considerad la función siguiente:```int M( int i, int f ) { \n\tif ( i == f ) \n\t\treturn i; \n\telse { \n\t\te = v[ M( i, (i+f)/2 ) ]; \n\t\tf = v[ M( (i+f)/2+1, f ) ]; \n\t\tif (e<f) \n\t\t\treturn e; \n\t\telse \n\t\t\treturn f; \n\t} \n}```Si la talla del problema viene dada por $$ n = f - i + 1 $$, ¿cuál es el coste temporal asintótico en el supuesto de que $$ n $$ sea una potencia de 2?
1
$$ O(n) $$. 
$$ O(n^2) $$.
$$ O(n \log(n)) $$.

El coste temporal asintótico del fragmento ```s=0; for(i=0;i<n;i++) for(j=i;j<n;j++) s+=i*j;``` y el del fragmento ```s=0; for(i=0;i<n;i++) for(j=0;j<n;j++) s+=i*i*j;```son ...
1
a. ... iguales.
b. ... el del segundo, menor que el del primero.
c. ... el del primero, menor que el del segundo.

La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición ...
2
... se comporta mejor cuando el vector ya está ordenado.
... se comporta peor cuando el vector ya está ordenado.
... El hecho de que el vector estuviera previamente ordenado o no, no influye en la complejidad temporal de este algoritmo.

La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la posición central ...
1
... se comporta mejor cuando el vector ya está ordenado.
... se comporta peor cuando el vector ya está ordenado.
... no presenta casos mejor y peor distintos para instancias del mismo tamaño.

Dada la siguiente relación de recurrencia, ¿Qué cota es verdadera? \n\n $$ f(n) = \begin{cases} 1 & n = 1 \\ n + 3f(n/3) & n > 1 \end{cases} $$
1
$$ f(n) \in \Theta(n \log n) $$
$$ f(n) \in \Theta(n^3) $$
$$ f(n) \in \Theta(n) $$

Sobre la complejidad temporal de la siguiente función: ```unsigned desperdicio (unsigned n){ \n\tif (n<=1) \n\t\treturn 0; \n\tunsigned sum = desperdicio (n/2) + desperdicio (n/2) + desperdicio (n/2); \n\tfor (unsigned i=1; i<n-1; i++) \n\t\tfor (unsigned j=1; j<=i; j++) \n\t\t\tfor (unsigned k=1; k<=j; k++) \n\t\t\t\tsum+=i*j*k; \n\treturn sum; \n}```
1
Ninguna de las otras dos alternativas es cierta.
Las complejidades en los casos mejor y peor son distintas.
El mejor de los casos se da cuando n ≤ 1 y en tal caso la complejidad es constante.

Con respecto al esquema Divide y vencerás, ¿es cierta la siguiente afirmación? \nSi la talla se reparte equitativamente entre los subproblemas, entonces la complejidad temporal resultante es una función logarítmica. \n
2
No, nunca, puesto que también hay que añadir el coste de la división en subproblemas y la posterior combinación.
No tiene porqué, la complejidad temporal no depende únicamente del tamaño resultante de los subproblemas.
Sí, siempre, en Divide y Vencerás la complejidad temporal depende únicamente del tamaño de los subproblemas.

¿Qué cota se deduce de la siguiente relación de recurrencia? \n\n $$ f(n) = \begin{cases} 1 & n = 1 \\ n + 4f(\frac{n}{2}) & n > 1 \end{cases} $$
1
f(n) ∈ Θ(n^2)
f(n) ∈ Θ(n)
f(n) ∈ Θ(n log n)

¿Cuál de estas tres expresiones es falsa?
3
$$ 2n^3 - 10n^2 + 1 \in O(n^3) $$
$$ n + n \sqrt{n} \in \Omega(n) $$
$$ n + n \sqrt{n} \in \Theta(n) $$

Sea $$ f(n) = n \log(n) + n $$.
3
... $$ f(n) \in \Omega(n \log(n)) $$
... $$ f(n) \in O(n \log(n)) $$
Las otras dos opciones son ciertas

¿Cuál es la complejidad temporal de la siguiente función?```int ejemplo (vector < int > & v){ \n\tint n=v.size(); \n\tint j,i=2; \n\tint sum=0; \n\twhile (n>0 && i<n){ \n\t\tj=i; \n\t\twhile (v[j] != v[1]){ \n\t\t\tsum+=v[j]; \n\t\t\tj=j/2; \n\t\t} \n\t\ti++; \n\t} \n\treturn sum; \n}```
1
$$ \Theta(n \log n) $$
$$ \Theta(n^2) $$
$$ \Omega(n) $$

En cuanto a la complejidad temporal de la siguiente función:```int ejemplo (vector < int > & v){ \n\tint n=v.size(); \n\tint j,i=2; \n\tint sum=0; \n\twhile (n>0 && i<n){ \n\t\tj=i; \n\t\twhile (v[j] != v[1]){ \n\t\t\tsum+=v[j]; \n\t\t\tj=j/2; \n\t\t} \n\t\ti++; \n\t} \n\treturn sum; \n}```
1
Las complejidades en el mejor y en el peor de los casos no coinciden.
El mejor de los casos se da cuando \( n = 0 \), su complejidad es constante.
Esta función no presenta casos mejor y peor puesto que solo puede haber una instancia para cada una de las posibles talla

Indica cuál es la complejidad, en función de \( n \), del fragmento siguiente:```for( int i = n; i > 0; i /= 2 ) \n\tfor( int j = n; j > 0; j /= 2 ) \n\t\ta += A[i][j]; \n```
1
$$ O(\log^2(n)) $$
$$ O(n \log(n)) $$
$$ O(n^2) $$

Indica cuál es la complejidad, en función de \( n \), del fragmento siguiente:```a = 0; \nfor( int i = 0; i < n*n; i++ ) \n\ta += A[(i + j) % n];```
1
$$ O(n^2) $$
$$ O(n \log(n)) $$
$$ O(n) $$

La versión deQuicksort que utiliza como pivote la mediana del vector...
1
... no presenta caso mejor y peor distintos para instancias del mismo tamaño.
... es más eficiente si el vector ya está ordenado.
... es la versión con mejor complejidad en el mejor de los casos.

El siguiente fragmento del algoritmo de ordenación Quicksort reorganiza los elementos del vector para obtener una subsecuencia de elementos menores que el pivote y otra de mayores. Su complejidad temporal, con respecto al tamaño del vector v, que está delimitado por los valores pi y pf, es...```x = v[pi]; \ni = pi+1; \nj = pf; \ndo { \n\twhile (i<=pf && v[i] < x) i++; \n\twhile (v[j] > x ) j--; \n\tif (i <= j ) { \n\t\tswap( v[i],v[j] ); \n\t\ti++; \n\t\tj--; \n\t} \n} while (i < j); \nswap(v[pi],v[j]);``` \nNota: La función swap se realiza en tiempo constante.
1
... lineal en cualquier caso.
... cuadrática en el peor de los casos.
... lineal en el caso peor y constante en el caso mejor.

Dada la siguiente relación de recurrencia, ¿Qué cota es verdadera?  \n\n$$ f(n) = \begin{cases} 1 & n = 1 \\ n + 2f(n-1) & n \geq 1 \end{cases} $$
1
$$ f(n) \in \Omega(2^n) $$
$$ f(n) \in \Theta(n^2) $$
$$ f(n) \in \Theta(2^n) $$

¿Cuál es la solución a la siguiente relación de recurrencia? \n\n$$ f(n) = \begin{cases} \Theta(1) & n = 0 \\ \Theta(1) + f(n/3) & n > 0 \end{cases} $$
1
$$ f(n) \in \Theta(\log(n)) $$.
$$ f(n) \in \Theta(n/3) $$.
Ninguna de las otras dos es cierta.

De las siguientes expresiones, o bien dos son verdaderas y una es falsa o bien al contrario: dos son falsas y una es verdadera. Marca la que en este sentido es distinta a las otras dos.
3
$$ 2n^3 - 10n^2 + 1 \in O(n^3) $$
$$ n + n\sqrt{n} \in \Omega(n) $$
$$ n + n\sqrt{n} \in \Theta(n) $$

Si $$ f \in \Omega(g_1) $$ y $$ f \in \Omega(g_2) $$ entonces
3
$$ f \not\in \Omega(\min(g_1, g_2)) $$
$$ f \in \Omega(g_1 \cdot g_2) $$
$$ f \in \Omega(g_1 + g_2) $$

¿Cuál de las siguientes relaciones de recurrencia expresa mejor la complejidad espacial es la del algoritmo Mergesort?
3
$$ T(n) = n + T(n - 1) \space\space$$ para $$\space\space n > 1 \space\space$$ y $$\space\space T(n) \space = \space\space\space\space\space\space\space 1 \space\space$$ para $$\space\space n \leq \space\space 1 $$
$$ T(n) = n + T(n/2) \space\space$$ para $$\space\space n > 1 \space\space$$ y $$\space\space T(n) \space = \space\space\space\space\space\space\space 1 \space\space$$ para $$\space\space n \leq \space\space 1 $$
$$ T(n) = n + 2T(n/2) \space\space$$ para $$\space\space n > 1 \space\space$$ y $$\space\space T(n) \space\ = \space\space\space\space\space\space\space 1 \space\space$$ para $$\space\space n \leq \space\space 1 $$

De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
3
$$ \log(n^3) \not\in \Theta(\log_3(n)) $$
$$ \Theta(\log^2(n)) = \Theta(\log^3(n)) $$
$$ \Theta(\log_2(n)) = \Theta(\log_3(n)) $$

Un problema de tamaño $$ n $$ puede transformarse en tiempo $$ O(1) $$ en siete de tamaño $$ \frac{n}{7} $$; por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante. \n¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
3
$$ O(n^2) $$
$$ O(n) $$
$$ O(n \log n) $$

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){\n\tif(n<2)return;\n\tfor(int i=0;i<pow(n,2);i++)\n\t\tcout<< "*";\n\tfor(int i=0;i<5;i++)\n\t\tf(n/2);\n}```
1
$$O(5^{log\,n})$$
$$O(n^2\,log\,n)$$
$$O(n^2)$$

Se pretende obtener la complejidad temporal en el caso más desfavorable de la siguiente función. \n```int exa(vector<int> &v){ \n\tint i, sum = 0, n = v.size(); \n\tif(n>0){ \n\t\tint j=n; \n\t\twhile(sum<100 and j!=0({ \n\t\t\tj = j /2; \n\t\t\tsum = 0; \n\t\t\tfor(i = j;i<n;i++) \n\t\t\t\tsum += v[i]; \n\t\t} \n\t\treturn j; \n\t} \n\telse return -1; \n}```
1
$$ C_s(n)=\sum^{log(n+1)}_{k=1}(n-n/2^k)\in O(n\log n) $$
$$ C_s(n)=\sum^{log\,n}_{j=1}\sum^{j}_{i=1}(1/2)^i \in O(n\log n) $$
$$ C_s(n)=\sum^{n/2}_{j=0}(1/2\sum^{n}_{i=j}1) \in O(n\log n) $$

Las siguientes funciones calculan el valor de potencia n-+esima de dos. ¿Cuál es el más eficiente en cuanto a coste temporal?\n```unsigned long pot2_1 (unsigned n){ \n\tif(n==0) return 1; \n\tif(n%2==0) return pot2_1(n/2) * pot2_1(n/2); \n\telse return 2 * pot2_1(n/2) * pot2_1(n/2); \n} \n\nunsigned long pot2_2(unsigned n){ \n\tif(n==0) return 1; \nm\t unsigned long aux= pot2_2(n/2); \n\tif(n%2==0) return aux * aux; \n\telse return 2 * aux * aux; \n}``` \n Seleccione una:
3
La primera, pot2_1(n), es más eficiente que la otra.
Las dos funciones son equivalentes en cuanto a coste temporal.
La segunda, pot2_2(n), es más eficiente que la otra.

Tenemos un vector desordenado y queremos obtener los tres elementos más pequeños. ¿Cuál seria la complejidad emporal más ajustada para hacerlo? (sin pérdida de generalidad puedes suponer que en el vector todos los elementos son distintos) \nSeleccione una:
2
El logaritmo de la longitud del vector
Lineal con la longitud del vector
Cuadrática con la longitud del vector

Supongamos que una solución recursiva a un problema de optimización muestra estas dos características: por un lado, se basa en obtener soluciones óptimas a problemas parciales más pequeños, y por otro, estos subproblemas se resuelven más de una vez durante el proceso recursivo. Este problema es candidato a tener una solución alternativa basada en \nSeleccione una:
1
un algoritmo de programación dinámica.
un algoritmo voraz.
un algoritmo del estilo de divide y vencerás.

Si $$ f ∉ O(g_1) $$ y $$ f \in O(g_2) $$ entonces siempre se cumplirá: \nSeleccione una:
1
$$ f \in \Omega(min(g_1,g_2)) $$
$$ f \in \Omega(g_1 + g_2) $$
$$ f ∉ O(max(g_1, g_2)) $$

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){ \n\t if(n < 1) return; \n\tfor(int i = 0; i < n; i++) \n\t\tfor(int j = 0; j < n;j++) \n\t\t\tfor(int k = 0; k < n;k++) \n\t\t\t\tcout << "*"; \n\tfor(int i = 0;i < 8;i++) \n\t\tf(n / 2); \n}``` \nSeleccione una:
1
$$ \Theta(n^3 \log n) $$
$$ \Theta(n^3) $$
$$ \Theta(n^2 \log n) $$

¿En qué caso la complejidad temporal del algoritmo de ordenación Quicksort es igual a la complejidad temporal del algoritmo Mergesort? \nSeleccione una:
1
En el caso mejor de ambos.
En el caso peor de ambos.
Tanto en el caso peor como en el caso mejor de ambo

Di cuál de estos resultados de coste temporal asintótico es falsa: \nSeleccione una:
2
La ordenación de un vector usando el algoritmo Quicksort requiere en el peor caso un tiempo en $$ O(n^2) $$
La ordenación de un vector usando el algoritmo Mergesort requiere en el peor caso un tiempo en $$ O(n^2) $$
La búsqueda binaria en un vector ordenado requiere en el peor caso un tiempo en $$ O(\log n) $$

De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es  distinta a las otras dos. \nSeleccione una:
2
$$ O(n^2) \subset O(2^{\log_2(n)}) \subset O(2^n) $$
$$ O(2^{\log_2(n)}) \subset O(n^2) \subset O(n!) $$
$$ O(4^{\log_2(n)}) \subset O(n) \subset O(2^n) $$

Tenemos un vector ordenado de tamano $$n_0$$ y un vector desordenado de tamano $$n_d$$ y queremos obtener un vector ordenado con todos los elementos. ¿Qué serå más rápido? \nSeleccione una:
3
Depende de si $$ n_o > n_d $$ o no.
Insertar los elementos del vector desordenado (uno a uno) en el vector ordenado.
Ordenar el desordenado y luego mezclar las listas.

La complejidad temporal (o coste temporal asintötico) en el mejor de los casos... \nSeleccione una:
2
Las otras dos opciones son ambas verdaderas.
... es una función de la talla, o tamano del problema, que tiene que estar definida para todos los posibles valores de ésta
... es el tiempo que tarda el algoritmo en resolver la talla más pequena que se le puede presentar.

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){ \n\tif(n < 1) return; \n\tfor( int i = 0;i < n; i++) \n\t\tfor(int j = 0; j < n; j++) \n\t\t\tfor(int k = 0; k < n; k++) \n\t\t\t\tcout << "*"; \n\tfor(int i = 0; i < 8; i++) \n\t\tif(n / 2); \n}``` \nSeleccione una:
3
$$ \Theta(n^3) $$
$$ \Theta(n^2 \log n) $$
$$ \Theta(n^3 \log n) $$

Sea la siguiente relacion de recurrencia: \n$$ T(n) = \begin{cases} 1 & si\,n \le 1 \\ 8T(\frac{n}{8}) + g(n) & en\,otro\, caso\end{cases} $$ \nSi $$ T(n) \in \Theta(n^2) $$, ¿en cuál de estos tres casos nos podemos encontrar? \nSeleccione una:
2
$$ g(n) = \space\space\space\space\space\space\space n^3  $$
$$ g(n) = \space\space\space\space\space\space\space n^2 $$
$$ g(n) = \space\space\space\space\space\space\space n $$

¿Cuál de los siguientes algoritmos de ordenación necesita un espacio de almacenamiento adicional al vector que se ordena con complejidad O(n)? \nSeleccione una:
1
Mergesort.
Quicksort.
Bubblesort.

Si $$ f ∉ O(g_1) $$ y $$ f \in O(g_2) $$ entonces siempre se cumplirá: \nSeleccione una:
3
$$ f \in \Omega(g_1 + g_2) $$
$$ f ∉ O(max(g_1, g_2)) $$
$$ f \in \Omega(min(g_1, g_2)) $$

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){ \n\tif(n < 2) return; \n\tfor(int i = 0; i < pow(n,2); i++) \n\t\tcout << "*"; \n\tf(n - 2); \n}``` \nSeleccione una:
3
$$ \Theta(n^2 \log n) $$
$$ \Theta(n^2) $$
$$ \Theta(n^3) $$

Si $$ f ∉ O(g_1) $$ y $$ f \in O(g_2) $$ enbtonces siempre se cumplirá: \nSeleccione una:
1
$$ f \in \Omega(min(g_1, g_2)) $$
$$ f \in \Omega(g_1 + g_2) $$
$$ f ∉ \Omega(max(g_1, g_2)) $$

¿Qué nos proporciona la media entre el coste temporal asintótico (o complejidad temporal) en el peor caso y el coste temporal asintótico en el mejor caso? \nSeleccione una:
3
El coste temporal promedio.
El coste temporal asintótico en eI caso medio.
En general, nada de interés.

Las siguientes funciones calculan el valor de la potencia n-ésima de dos. ¿Cuál es más eficiente en cuanto a coste temporal? \n```unsigned long pot2_1(unsigned n){ \n\tif(n==0) return 1; \n\tif(n%2==0)return pot2_1(n/2) * pot2_1(n/2); \n\telse return 2 * pot2_1(n/2) * pot2_1(n/2); \n} \n\nunsigned long pot2_2(unsigned n){ \n\t if(n==0) return 1; \n\treturn 2 * pot2_2(n-1); \n}``` \nSeleccione una:
2
La segunda, pot2_2(n), es más eficiente que la otra.
Las dos funciones son equivalentes en cuanto a coste temporal. 
La primera, pot2_1(n), es más eficiente que la otra.

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){ \n\tif(n < 2) return; \n\tfor(int i = 0; i < pow(n,2); i++) \n\t\tcout << "*"; \n\tfor(int i = 0; i < 5; i++) \n\t\tf(n/2); \n}``` \nSeleccione una:
3
$$ \Theta(n^2) $$
$$ \Theta(n^2 \log n) $$
$$ \Theta(5^{\log n}) $$

¿Qué algoritmo es asintóticamente más rápido, el Quicksort o el Mergesort? \nSeleccione una:
3
Los dos son igual de rápidos ya que el coste temporal asintótico de ambos es O(n log(n)).
como su nombre indica, el Quicksort.
el Mergesort es siempre más rápido o igual (salvo una constante) que el Quicksort.

La solucion Optima al problema de encontrar el arbol de recubrimiento de coste minimo para un grafo no dirigido, conexo y ponderado \nSeleccione una:
2
... se construye haciendo crecer varios arboles que al final acaban injertados en un unico arbol.
... puede construir un unico arbol que va creciendo o bien construir un bosque de arboles que al final se injenan en un unico arbol
... se construye haciendo crecer un unico arbol.

Se pretende implementar mediante programación dinámica iterativa la función recursiva: \n```int f(int x, int y){ \n\tif(x <= y) return 1; \n\treturn x + f(x-1,y); \n}``` \n¿Cuál es la mejor complejidad espacial que se puede conseguir? \nSeleccione una:
2
$$ O(x) $$
$$ O(1) $$
$$ O(x^2) $$

iCual de los siguientes pares de problemas son equivalentes en cuanto al tipo de solucian (Optima, factible, etc.) aportada por el método voraz? \nSeleccione una:
3
La mochila continua y la asignación de tareas.
El fontanero diligente y el problema del cambio.
La mochila discreta y la asignación de tareas.

De los problemas siguientes, indicad cual no se puede tratar eficientemente como los otros dos: \nSeleccione una:
2
El problema de cortar un tubo de forma que se obtenga el maximo beneficio posible.
El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores.
El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el minimo de monedas posibles.

La eficiencia de los algoritmos voraces se basa en el hecho de que ... \nSeleccione una:
2
... antes de tomar una decisiön se comprueba si satisface las retricciones del problema.
... las decisiones tomadas nunca se reconsideran.
... con antelaciön, Ias posibles decisiones se ordenan de mejor a peor.
