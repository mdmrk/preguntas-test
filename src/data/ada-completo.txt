Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? $f(n) = n(n-1) + f(n-1)$ si $n > 0$; $f(0) = 1$ si $n = 0$
O: $f(n) \in \Theta(n^2)$
O: $f(n) \in \Theta(n^3)$
O: $f(n) \in \Theta(n^4)$
A: 1

Q: El coste temporal de un algoritmo se ajusta a la siguiente ecuación de recurrencia:$t(n) = \begin{cases} 1 & \text{para } n = 0 \\ n + \sum_{j=0}^{n-1} t(j) & n > 1 \end{cases}$¿Qué coste temporal asintótico o complejidad temporal tendrá el algoritmo?
O: $O(n^2)$
O: $O(n \log n)$
O: $O(2^n)$
A: 2

Q: Sea el problema de la función compuesta mínima. Si no acotamos el número máximo de operaciones posibles, un esquema de ramificación y poda:
O: Podría no acabar, al tener que expandir indefinidamente nuevos nodos.
O: Si incluimos memorización, podría no encontrar la solución óptima pero siempre acabaría.
O: Si incluimos memorización, siempre encuentra la solución óptima.
A: 0

Q: ¿Cuál es el coste temporal de crear un montículo de máximos a partir de un vector ordenado de mayor a menor?
O: $\Theta(1)$
O: $\Theta(n)$
O: $\Theta(n \cdot \log(n))$
A: 1

Q: ¿Cuál de estos problemas tiene una solución eficiente utilizando programación dinámica?
O: El problema de la asignación de tareas.
O: El problema del cambio.
O: La mochila discreta sin restricciones adicionales.
A: 1

Q: ¿Cuál de estas afirmaciones sobre el algoritmo para calcular x^n es falsa? 
```
Función potencia ( ent x: entero, ent n: entero): entero
Inicio
	si n==1 entonces
		retorna (x);
	si no
		retorna (x*potencia(x,n-1));
	finsi
fin
```
O: Se utiliza un esquema de divide y venceras para su solucion
O: Su precondición es {Q} = {x entero, n natural, n>=1}
O: Su ecuación de recurrencia es T(n) = T(n-1)+1
O: Su coste temporal es O(x^n)
A: 3

Q: Con respecto a los algoritmos estudiados durante el curso que encuentran el árbol de recubrimiento de mínimo coste, de las afirmaciones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos
O: El algoritmo de Prim se puede acelerar notablemente si los vértices se organizan en una estructura union-find.
O: La complejidad temporal del algoritmo de Prim es cúbica con respecto al número de vértices del grafo.
O: El algoritmo de Kruskal va construyendo un bosque de árboles que va uniendo hasta que acaba con un árbol de recubrimiento de coste mínimo.
A: 2

Q: ¿Qué algoritmo es asintóticamente más rápido el quicksort o el mergesort?
O: El mergesort es siempre el más rápido o igual (salvo una constante) que el quicksort.
O: Como su nombre indica, quicksort.
O: Son los dos igual de rápidos, ya que el coste temporal asintótico de ambos es $O(n \log n)$.
A: 2

Q: Cuál de las siguientes formulaciones expresa mejor el coste temporal asintótico de la siguiente función?
```cpp
int f(int n) {
  int count = 0;
  for (int i = n; i > 0; i /= 2)
    for (int j = 0; j < 2 * i; j++)
      count += 1;
  return count;
}
```
O: $f(n) = \sum_{i=1}^{\log n} 4n \left( \frac {1}{2} \right)^i$
O: $f(n) = \sum_{i=0}^{n/2} \sum_{j=0}^{2*i} 1$
O: Ninguna de las otras dos opciones es correcta.
A: 0

Q: En el metodo voraz
O: es habitual preparar los datos para disminuir el coste temporal de la funcion que determina cual es la siguiente decision a tomar.
O: siempre se encuentra solucion pero puede que no sea la optima.
O: el dominio de las decisiones solo pueden ser conjuntos discretos o discretizables
A: 0

Q: Dado un problema de optimización cualquiera, ¿la estrategia de backtracking garantiza la solución óptima?
O: Sí, siempre que el dominio de las decisiones sea discreto o discretizable y además se empleen mecanismos de poda basados en la mejor solución hasta el momento.
O: Sí, puesto que ese método analiza todas las posibilidades.
O: Es condición necesaria que el dominio de las decisiones sea discreto o discretizable y que el número de decisiones a tomar esté acotado.
A: 2

Q: Una de las prácticas de laboratorio consistió en el cálculo empírico de la complejidad temporal promedio del algoritmo de ordenación de vectores Quicksort tomando como centinela el elemento del vector que ocupa la posición central. ¿Cuál es el orden de complejidad que se obtuvo?
O: $n^2$
O: $n \log n$
O: $n \log^2 n$
A: 1

Q: Indica cuál es el coste temporal en función de n del problema siguiente 
```cpp
s = 0;
for (i = 0; i < n; i++)
  for (j = i; j < n; j++)
    s += n * i * j;
```
O: Es $\Theta(n)$
O: Es $O(n^2)$ pero no $\Omega(n^2)$
O: Es $\Theta(n^2)$
A: 2

Q: Que calcula el siguiente algoritmo:
```
función Ejercicio (ent A: ÁrbolBinario, ent/sal actual:entero):nada
variables		x: entero
		Izq, Der: ÁrbolBinario
inicio
	si A.Vacio entonces
		A.HijoIzq(Izq)
		A.HijoDer(Der)
		A.Raíz(x)
		actual:=actual + x
		Ejercicio (Izq, actual)
		Ejercicio (Der, actual)
	finsi
fin
Llamada desde el programa principal:
n:= 0			// Arb es un árbol
Ejercicio(Arb, n)
```
O: n devuelve la suma de los valores de los nodos que no son hojas en el arbol
O: n devuelve la suma de valores de los nodos del arbol
O: n devuelve el valor de la raiz del arbol
O: n devuelve la suma de los valores de las hojas del arbol
A: 1

Q: Asumiendo que n es par, las siguientes recurrencias matematicas, obtienen el valor de la potencia enésima ($x^n$), cual de las siguientes afirmaciones es cierta
O: Ambas recurrencias son equivalentes en cuanto a complejidad temporal
O: La primera recurrencia resultara ser la mas eficiente siempre que se utilice la programacion dinamica recursiva para su implementacion.
O: La segunda recurrencia resulta ser la mas eficiente siempre que se utilice divide y venceras.
A: 1

Q: Indicad cuál de estas tres expresiones es falsa.
O: $\Theta(n/2) = \space\space\space\space\space\space\space \Theta(n)$
O: $\Theta(n) \subseteq \space \Theta(n)$
O: $\Theta(n) \subseteq \space \Theta(n^2)$
A: 2

Q: En la estrategia de ramificación y poda se suele usar una cola de prioridad para decidir en qué orden se expanden los nodos. Imaginemos un problema de optimización. ¿Puede ser que el valor por el cual se ordenan los nodos sea una cota pesimista del nodo?
O: No, porque para podar necesitamos una cota optimista.
O: Sí.
O: No, porque una cota pesimista es típicamente el valor que se encuentra en una de las hojas que cuelga del nodo.
A: 1

Q: ¿Cuál sería la complejidad temporal de la siguiente función tras aplicar programación dinámica?
```cpp
double f(int n, int m) {
  if (n == 0)
    return 1;
  return m * f(n - 1, m) * f(n - 2, m);
}
```
O: $\Theta(n)$
O: $\Theta(n \cdot m)$
O: $\Theta(n^2)$
A: 0

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? 
```
f(n) = n(n - 1) + f(n - 1)   // si n > 0
f(0) = 1                      // si n = 0
```
O: $f(n) \in \Theta(n^2)$
O: Ninguna de las otras dos opciones es cierta.
O: $f(n) \in \Theta(n^3)$
A: 2

Q: Una empresa de transportes dispone de M vehículos para repartir N paquetes, todos al mismo destino. Cada paquete i tiene un peso $P_i$ y se tiene que entregar antes de que transcurra un tiempo $T_{pi}$. Por otro lado, cada vehículo j puede transportar una carga máxima $C_j$, tarda un tiempo $T_{vj}$ para llegar al destino y consume una cantidad $L_j$ de litros de combustible, independientemente de la carga que transporta. Imaginad un algoritmo de vuelta atrás que obtenga la manera en que se tienen que transportar los objetos (en qué vehículo j tiene que ir cada objeto i) para que el consumo sea el mínimo. ¿Cuál sería una buena cota optimista?
O: La solución voraz del problema de cargar cada paquete en el camión de menor consumo donde cada paquete llega a tiempo, sin tener en cuenta si el camión se sobrecarga o no.
O: La solución voraz del problema de cargar cada paquete en el camión de menor consumo, sin sobrecargarlo, sin tener en cuenta si el paquete llega a tiempo o no.
O: Ambas son cotas optimistas válidas.
A: 2

Q: Considera el siguiente algoritmo: Nos interesa medir cuantas veces se ejecuta nº 3 entonces el caso mejor se obtiene cuando:
```cpp
Ordena(vector V[N] de enteros) {
  int i, j, aux;
  for (i = 1; i < N; i++) {
    for (j = 0; j < N - i; j++) {
      if (V[j] > V[j + 1]) { // (2)
        aux = V[j];
        V[j] = V[j + 1]; // (3)
        V[j + 1] = aux;
      }
    }
  }
}
```
O: Cuando los datos vienen dispuestos en orden inverso, que se ejecuta del orden de $n^2$ veces
O: Cuando los datos vienen ordenados ascendentemente, que se ejecuta del orden de $n^2$ veces
O: Cuando los datos vienen ordenados ascendentemente, que se ejecuta del orden de n veces
O: Cuando los datos vienen ordenados ascendentemente, que se ejecuta 0 veces.
A: 3

Q: ¿Cuál de estos problemas no tiene una solución eficiente utilizando programación dinámica?
O: El problema de la asignación de tareas.
O: El problema del cambio.
O: La mochila discreta cuyos pesos son números naturales.
A: 0

Q: Cuando resolvemos un problema mediante RyP
O: las decisiones solo pueden ser binarias
O: los valores entre los cuales se elige en cada una de las decisiones pueden formar un conjunto infinito
O: los valores entre los cuales se elige en cada una de las decisiones tienen que formar un conjunto finito
A: 2

Q: La estrategia de ramificación y poda genera las soluciones posibles al problema mediante
O: Un recorrido en profundidad del árbol que representa el espacio de soluciones.
O: Un recorrido en anchura del árbol que representa el espacio de soluciones.
O: Un recorrido guiado por estimaciones de las mejores ramas del árbol que representa el espacio de soluciones.
A: 2

Q: Mediante el algoritmo de Floyd podemos
O: IV Las respuestas I, II y III son correctas
O: II calcular el coste mínimo de ir desde un vértice i a todos los demás
O: V Las respuesta I y II son correctas
O: II calcular el coste mínimo de ir desde cualquier vértice i a cualquier otro
O: I calcular el coste mínimo de ir desde un vértice i a un vértice j
A: 0

Q: Sobre la propiedad de subestructura óptima de un problema de optimización (por selección discreta):
O: Es condición necesaria para poder aplicar divide y vencerás.
O: Es condición necesaria para poder aplicar programación dinámica.
O: Las otras dos opciones son ambas ciertas.
A: 2

Q: Dadas 2 soluciones recursivas A y B, para un problema de manera que las ecuaciones de recurrencia para el caso general (n > 1) son Ta(n)=Ta(n-1)+n y Tb(n-1)+1. (Los casos base de ambos problemas se resuelven con tiempo constante cuando n < =1). Desde el punto de vista asintotico ¿ cual de las dos soluciones es mejor?
O: La solución B
O: La solución A
O: Faltan datos para poder decirlo
O: Ambas por igual
A: 1

Q: Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. Queremos listar todas las posibilidades de fabricación de objetos teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$. Para ello hemos hecho el siguiente programa donde faltan unas líneas:
```cpp
void combinations(const vector<int> &m, const vector<double> &t, double T,
                  size_t k, vector<int> &x) {
  if (k == m.size()) {
    print_comb(x);
    return;
  }
  // ==> Aquí falta código <= =
}
```
```cpp
void combinations(const vector<int> &m, const vector<double> &t, double T) {
  vector<int> x(m.size());
  combinations(m, t, T, 0, x);
}
```
¿Cuales son las líneas que faltan? [suponed que `print_comb()` imprime correctamente la combinación que hay codificada en x]
O: ```cpp
for (int j = 0; j <= m[k]; j++) {
  x[k] = j;
  if (T >= j * t[k])
    combinations(m, t, T - j * t[k], k + 1, x);
}
```
O: ```cpp
for (int j = 0; j < m[k]; j++) {
  x[k] = j;
  if (T >= j * t[k])
    combinations(m, t, T - j * t[k], k + 1, x);
}
```
O: ```cpp
for (int j = 0; j < m[k]; j++) {
  x[j] = k;
  if (T >= j * t[k])
    combinations(m, t, T - j * t[k], k + 1, x);
}
```
A: 0

Q: Se pretende mejorar mediante programación dinámica iterativa la siguiente función (v1 y v2 son vectores definidos como variables globales). ¿Cuál es la mejor complejidad espacial que se puede conseguir?
```cpp
float f(unsigned n, int m) {
  if (m < 0)
    return 0;
  float A = 0.0;
  if (v1[m] <= n)
    A = v2[m] + f(n - v1[m], m - 1);
  float B = f(n, m - 1);
  return A + B;
}
```
O: $O(m \cdot n)$
O: $O(n)$
O: $O(m)$
A: 1

Q: La programación dinámica...
O: En algunos casos se puede utilizar para resolver problemas de optimización con dominios continuos pero probablemente pierda su eficacia ya que puede disminuir drásticamente el número de subproblemas repetidos
O: Normalmente se usa para resolver problemas de optimización con dominios discretizables puesto que las tablas se han de indexar con este tipo de valores
O: Las otras dos opciones son ciertas
A: 2

Q: Si $\lim_{n \to \infty} \frac{g(n)}{f(n)} = 0$, ¿Cuál de las siguientes expresiones NO puede darse?
O: $g(n) \notin \Theta(f(n))$
O: $f(n) \notin \Theta(g(n))$
O: $g(n) \in \Omega(f(n))$
A: 2

Q: El problema del alfarero (solución discreta con tiempos continuos): Se dispone de $n$ clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. El tiempo disponible para la fabricación de objetos está limitado por $T \in \mathbb{R}$. Se pretende resolver mediante ramificación y poda y para ello se hace uso de una cota que consiste en asumir que de las restantes clases de objetos aún no tratadas se va a fabricar exactamente una pieza. ¿Qué podemos decir de esta cota?
O: Que no es cota, ni optimista ni pesimista
O: Que es una cota pesimista.
O: Que es una cota optimista.
A: 0

Q: Un árbol binario ordenado se caracteriza porque
O: Se construye desde la raíz hasta las hojas y no existe una relacion de orden entre los datos
O: Se construye desde las hojas a la raíz y existe una relacion jerárquica entre los datos
O: Se construye desde las hojas a la raíz y existe una relacion de orden entre los datos
O: Se construye desde la raíz hasta las hojas y existe una relacion exclusivamente jerárquica entre los datos
O: Se construye desde la raíz hasta las hojas y no existe ninguna relacion entre los datos
A: 1

Q: Se desea resolver el problema de la potencia enésima ($x^n$), asumiendo que n es par y que se utilizará la siguiente recurrencia: pot(x,n) = pot(x,n/2) * pot(x,n/2); ¿Qué esquema resulta ser más eficiente en cuanto al coste temporal?
O: Divide y vencerás.
O: En este caso tanto programación dinámica como divide y vencerás, resultan ser equivalentes en cuanto a la complejidad temporal.
O: Programación dinámica.
A: 2

Q: Sea A una matriz cuadrada n × n. Se trata de buscar una permutación de las columnas tal que la suma de los elementos de la diagonal de la matriz resultante sea mínima. Indicad cuál de las siguientes afirmaciones es falsa.
O: La complejidad temporal de la mejor solución posible al problema es $O(n \log n)$.
O: Si se construye una solución al problema basada en el esquema de ramificación y poda, una buena elección de cotas optimistas y pesimistas podría evitar la exploración de todas las permutaciones posibles.
O: La complejidad temporal de la mejor solución posible al problema está en $\Omega(n^2)$.
A: 0

Q: La solución al problema de encontrar el k-ésimo mínimo de un vector pone en práctica la siguiente estrategia:
O: Ordena totalmente el vector
O: Ordena parcialmente el vector
O: No ordena ningún elemento del vector
A: 1

Q: ¿Qué algoritmo es asintóticamente más rápido, el Quicksort o el Mergesort?
O: Los dos son igual de rápidos ya que el coste temporal asintótico de ambos es O(n log(n)).
O: como su nombre indica, el Quicksort.
O: el Mergesort es siempre más rápido o igual (salvo una constante) que el Quicksort.
A: 2

Q: Indica cuál es la complejidad, en función de n, del fragmento siguiente:
```cpp
for (int i = 0; i < n; i++) {
  A[i] = 0;
  for (int j = 0; j < 2 * n; j++)
    A[i] += B[j];
}
```
O: $\Theta(n^2)$
O: $\Theta(n \log n)$
O: $\Theta(n)$
A: 0

Q: El siguiente fragmento del algoritmo de ordenación Quicksort reorganiza los elementos del vector para obtener una subsecuencia de elementos menores que el pivote y otra de mayores. Su complejidad temporal, con respecto al tamaño del vector `v`, que está delimitado por los valores `pi` y `pf`, es...
```cpp
x = v[pi];
i = pi + 1;
j = pf;
do {
  while (i <= pf && v[i] < x)
    i++;
  while (v[j] > x)
    j--;
  if (i <= j) {
    swap(v[i], v[j]);
    i++;
    j--;
  }
} while (i < j);
swap(v[pi], v[j]);
```
Nota: La función `swap` se realiza en tiempo constante.
O: ... lineal en cualquier caso.
O: ... cuadrática en el peor de los casos.
O: ... lineal en el caso peor y constante en el caso mejor.
A: 0

Q: Sea $f(n)$ la solución de la relación de recurrencia $f(n) = 2f(n/2) + n$; $f(1) = 1$. Indicad cuál de estas tres expresiones es cierta.
O: $f(n) \in \Theta(n^2)$
O: $f(n) \in \Theta(n)$
O: $f(n) \in \Theta(n \log n)$
A: 2

Q: De las siguientes expresiones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
O: $$\sum_{i=1}^{n/2} \sum_{j=1}^{i} 2^j = O(n \log n)$$
O: $$\sum_{i=1}^{n} \sum_{j=1}^{\log i} 2^j = O(n^2)$$
O: $$\sum_{i=1}^{\log n} \sum_{j=1}^{n} 2^j = O(n \log n)$$
A: 1

Q: ¿En qué caso la complejidad temporal de quicksort es la misma que la del algoritmo de ordenación por inserción?
O: En el caso mejor.
O: En el caso peor.
O: En ningún caso.
A: 2

Q: En la estrategia de ramificación y poda se usa una cola de prioridad para decidir en qué orden se expanden los nodos. Imaginemos un problema de optimización. ¿Puede ser que el valor por el cual se ordenan los nodos sea una cota pesimista del nodo?
O: Sí.
O: No, porque para podar necesitamos una cota optimista.
O: No, porque una cota pesimista es típicamente el valor que se encuentra en una de las hojas que cuelga del nodo.
A: 0

Q: Uno de estos tres problemas no tiene una solución trivial y eficiente que siga el esquema voraz.
O: El problema de la mochila discreta sin limitación en la carga máxima de la mochila.
O: El problema de la mochila continua.
O: El problema del cambio.
A: 2

Q: ¿Con qué esquema de programación obtenemos algoritmos que calculan la distancia de edición entre dos cadenas?
O: Programación Dinámica
O: Divide y vencerás
O: Ambos
A: 0

Q: Existen dos algoritmos que para ordenar un vector de n elementos, buscan el máximo de esos n elementos, lo intercambian con el n-ésimo elemento para ponerlo al final, y luego ordenan, usando el mismo algoritmo, el vector de las primeras $n - 1$ componentes. ¿Cuál de las afirmaciones siguientes es cierta?
O: Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por selección; el primero tiene un coste temporal $O(n \log n)$ y el segundo, $O(n^2)$.
O: Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por burbuja o bubblesort; el primero tiene un coste temporal $O(n \log n)$ y el segundo, $O(n^2)$.
O: Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por selección; el primero tiene un coste temporal $O(n)$ y el segundo, $O(n^2)$.
A: 0

Q: Indica cuál es la complejidad en función de n, donde k es una constante (no depende de n), del fragmento siguiente:
```cpp
for (int i = k; i < n - k; i++) {
  A[i] = 0;
  for (int j = i - k; j < i + k; j++)
    A[i] += B[j];
}
```
O: $O(n \cdot \log(n))$
O: $O(n)$
O: $O(n^2)$
A: 1

Q: Sea un árbol binario de profundidad k con nodos, donde n - 2^k este dato nos permite saber entre otras cosas
O: Existen en árbol todos los nodos de nivel k
O: El árbol es equilibrado
O: Las 3 respuestas conjuntamente
O: El árbol es completo
A: 2

Q: En un algoritmo de ramificación y poda, el orden escogido para priorizar los nodos en la lista de nodos vivos...
O: ...determina la complejidad temporal en el peor de los casos del algoritmo.
O: ...nunca influye en el resultado.
O: ...puede influir en el número de nodos que se descartan sin llegar a expandirlos.
A: 2

Q: Sobre la complejidad temporal de la siguiente función:
```cpp
unsigned desperdicio(unsigned n) {
  if (n <= 1)
    return 0;
  unsigned sum = desperdicio(n / 2) + desperdicio(n / 2) + desperdicio(n / 2);
  for (unsigned i = 1; i < n - 1; i++)
    for (unsigned j = 1; j <= i; j++)
      for (unsigned k = 1; k <= j; k++)
        sum += i * j * k;
  return sum;
}
```
O: Ninguna de las otras dos alternativas es cierta.
O: Las complejidades en los casos mejor y peor son distintas.
O: El mejor de los casos se da cuando n ≤ 1 y en tal caso la complejidad es constante.
A: 0

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es menor que el valor de una cota optimista? (se entiende que ambas cotas se aplican sobre el mismo nodo)
O: Sí, siempre es así.
O: En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
O: En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
A: 2

Q: El problema del alfarero (solución discreta con tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. El tiempo disponible para la fabricación de objetos está limitado por $T \in \mathbb{R}$. Se pretende resolver mediante ramificación y poda y para ello se hace uso de una cota que consiste en coger, de entre las clases aún no consideradas, un número al azar de objetos a fabricar siempre que se cumpla las restricciones del problema ¿Que podemos decir de esta cota?
O: Que es una cota optimista
O: Que no es cota, ni optimista ni pesimista
O: Que es una cota pesimista.
A: 2

Q: Se quiere desarrollar un programa que compruebe si es posible que un caballo de ajedrez, mediante una secuencia de sus movimientos permitidos, recorra todas las casillas de un tablero $N \times N$ a partir de una determinada casilla dada como entrada y sin repetir ninguna casilla. De entre las estrategias que se citan, ¿cuál sería la eficiente para resolver el problema?
O: Programación dinámica.
O: Vuelta atrás.
O: Algoritmo voraz.
A: 1

Q: ¿Qué nos proporciona la media entre el coste temporal asintótico (o complejidad temporal) en el peor caso y el coste temporal asintótico en el mejor caso?
O: El coste temporal promedio.
O: El coste temporal asintótico en eI caso medio.
O: En general, nada de interés.
A: 2

Q: Una empresa de transportes dispone de M vehículos para repartir N paquetes, todos al mismo destino. Cada paquete i tiene un peso Pi y se tiene que entregar antes de que transcurra un tiempo TPi. Por otro lado, cada vehículo j puede transportar una carga máxima Cj, tarda un tiempo TVj para llegar al destino y consume una cantidad Lj de litros de combustible, independientemente de la carga que transporta. Imaginad un algoritmo de vuelta atrás que obtenga la manera en que se tienen que transportar los objetos (en qué vehículo j tiene que ir cada objeto i) para que el consumo sea el mínimo. ¿Cuál sería una buena cota optimista?
O: Ambas son cotas optimistas válidas.
O: La solución voraz del problema de cargar cada paquete en el camión de menor consumo donde cada paquete llega a tiempo, sin tener en cuenta si el camión se sobrecarga o no.
O: La solución voraz del problema de cargar cada paquete en el camión de menor consumo, sin sobrecargarlo, sin tener en cuenta si el paquete llega a tiempo o no.
A: 0

Q: La versión del quicksort que ocupa como pivote el elemento que ocupa la posición central
O: No presenta caso mejor y peor para instancias del mismo tamaño.
O: Se comporta peor cuando el vector ya está ordenado.
O: Se comporta mejor cuando el vector ya está ordenado.
A: 2

Q: ¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, una solución voraz que es óptima?
O: El problema de la mochila discreta
O: El árbol de cobertura de coste mínimo de un grafo conexo.
O: El problema de la mochila continua o con fraccionamiento.
A: 0

Q: ¿Cómo se vería afectada la solución voraz al problema de la asignación de tareas en el caso de que se incorporaran restricciones que contemplen que ciertas tareas no pueden ser adjudicadas a ciertos trabajadores?
O: Ya no se garantizaría la solución óptima pero sí una factible.
O: Habría que replantearse el criterio de selección para comenzar por aquellos trabajadores con más restricciones en cuanto a las tareas que no pueden realizar para asegurar, al menos, una solución factible.
O: La solución factible ya no estaría garantizada, es decir, pudiera ser que el algoritmo no llegue a solución alguna.
A: 2

Q: La siguiente relación de recurrencia expresa la complejidad de un algoritmo recursivo, donde g(n) es una función polinómica:$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 2T(n/2) + g(n) & \text{en otro caso} \end{cases}$Di cuál de las siguientes afirmaciones es cierta:
O: Si $g(n) \in \Theta(n)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación mergesort.
O: Si $g(n) \in \Theta(n^2)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación mediante inserción binaria.
O: Si $g(n) \in \Theta(1)$ la relación de recurrencia representa la complejidad temporal del algoritmo de búsqueda dicotómica.
A: 2

Q: Un tubo de n cm de largo se puede cortar en segmentos de 1 centímetro, 2 centímetros etc. Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es que más ingresos nos producirá. Se quiere resolver el problema mediante vuelta atrás ¿cuál sería la forma más adecuada de representar las posibles soluciones?
O: Un par de enteros que indiquen los cortes realizados y el valor acumulado.
O: Un vector de booleanos.
O: Una tabla que indique para cada posición donde se va a cortar cada uno de los posibles valores acumulados.
A: 2

Q: Sabemos que un árbol se construye
O: Se construye de la raíz a las hojas si es un AVL, y de las hojas a la raíz si es un binario
O: Ninguna de las anteriores
O: Si el árbol es binario de la raíz a las hojas igual que si es un árbol en general
O: Se construye empezando por la raíz luego por la izquierda y después por la derecha hasta llegar a las hojas si es binario ordenado y de las hojas a la raíz si es binario
A: 0

Q: Tratandose de un esquema general para resolver problemas de maximizacion ¿que falta en el hueco? `Solution BB(Problem p) if(????????????)`
O: `n.pesimistic_b() <= pb`
O: `n.optimistic_b() >= pb`
O: `n.optimistic_b() <= pb`
A: 1

Q: Un tubo de centímetros de largo se puede cortar en segmentos de 1 centímetro, 2 centímetros, etc. Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es la que más ingresos nos producirá. Di cuál de estas tres afirmaciones es falsa.
O: Hacer una evaluación exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $O(n!)$.
O: Es posible evitar hacer la evaluación exhaustiva "de fuerza bruta" guardando, para cada posible longitud $j < n$ el precio más elevado posible que se puede obtener dividiendo el tubo correspondiente.
O: Hacer una evaluación exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $O(2^n)$.
A: 0

Q: ¿Qué esquema de programación es el adecuado para resolver el problema de la búsqueda binaria?
O: Programación Dinámica
O: Divide y Vencerás
O: Ninguno de los dos
A: 1

Q: Sea f(n) la solución de la relación de recurrencia $f(n) = 2f(n/2) + n$; $f(1) = 1$. Indicad cuál de estas tres expresiones es cierta
O: $f(n) \in \Theta(n \log n)$
O: $f(n) \in \Theta(n)$
O: $f(n) \in \Theta(n^2)$
A: 0

Q: Indica cuál es la complejidad, en función de $n$, del siguiente fragmento de código: `s=0; for(i=0;i<n;i++) for(j=i;j<n;j++) s+=i*j;`
O: $\Theta(n^2)$
O: $O(n^2)$ pero no $\Omega(n^2)$
O: $\Theta(n)$
A: 0

Q: ¿Cuál de las siguientes relaciones de recurrencia expresa mejor la complejidad espacial es la del algoritmo Mergesort?
O: $T(n) = n + T(n - 1)$ para $n > 1$ y $T(n) = 1$ para $n \leq 1$
O: $T(n) = n + T(n/2)$ para $n > 1$ y $T(n) = 1$ para $n \leq 1$
O: $T(n) = n + 2T(n/2)$ para $n > 1$ y $T(n) = 1$ para $n \leq 1$
A: 2

Q: El coste temporal asintótico del programa 
```cpp
s = 0;
for (i = 0; i < n; i++)
  for (j = i; j < n; j++)
    s += i * j;
```
y del programa 
```cpp
s = 0;
for (i = 0; i < n; i++)
  for (j = 0; j < n; j++)
s += i * i * j
```
O: El del segundo, menor que el primero.
O: Iguales.
O: El del primero, menor que el segundo.
A: 1

Q: Si n es el número de elementos de un vector. Podemos encontrar una solución al problema de encontrar su k-ésimo que esté acotada superiormente por :
O: $O(n^3)$
O: $O(n)$
O: Ninguna de las dos
A: 0

Q: En un algoritmo de ramificación y poda, ¿Qué ocurre si coinciden los valores obtenidos por las cotas pesimista y optimista del mismo nodo?
O: Esta situación no puede ocurrir en ningún caso; por lo tanto, una de las cotas está mal calculada (o ambas).
O: Que ese valor es a su vez el mejor valor que se puede obtener con ese nodo.
O: Que es un nodo hoja, esta situación sólo es posible en los nodos hoja.
A: 1

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. El tiempo total disponible viene dado por $T \in \mathbb{N}$. Se pretende listar todas las posibilidades de fabricación de objetos. ¿Qué estrategia es la más adecuada?
O: Ramificación y poda.
O: Vuelta atrás.
O: Un algoritmo voraz.
A: 1

Q: En cuanto a la complejidad temporal de la siguiente función, ¿qué podemos decir acerca del mejor de los casos?
```cpp
int f(vector<int> &v) {
  int n = v.size(), i = 2, k = 0;
  while (i < n) {
    int j = i;
    while (v[j] != v[1]) {
      k++;
      j = j / 2;
    }
    i = i + 2;
  }
  return k;
}
```
O: Que uno de los mejores casos ocurre cuando v[j] = v[1] ∀j ∈ N y la complejidad es $\Omega(n)$.
O: Las otras dos opciones son ambas falsas.
O: Que el mejor de los casos ocurre cuando el vector tiene 2 elementos o menos y la complejidad es $\Omega(1)$.
A: 0

Q: ¿Cual de los siguientes pares de problemas son equivalente en cuanto al tipo de solución(óptima, factible, etc) aportada por el método voraz?
O: El fontanero diligente y el problema del cambio
O: La mochila discreta y la asignación de tareas
O: La mochila continua y la asignación de tareas
A: 1

Q: Sea $f(n) = 2f(n - 1) + 1$
O: $f(n) \in O(n)$
O: $f(n) \in O(2^n)$
O: $f(n) \in O(n^2)$
A: 1

Q: Si n es el número de elementos de un vector. La solución de menor coste al problema de la búsqueda binaria tiene la siguiente complejidad:
O: $\Omega(\log n)$ y $O(n \log n)$
O: $\Theta(n \log n)$
O: $\Omega(1)$ y $O(\log n)$
A: 2

Q: La complejidad temporal en el mejor de los casos...
O: ... es el tiempo que tarda el algoritmo el resolver la talla más pequeña que se le puede presentar
O: ... es una función de la talla que tiene que estar definida en todos los posibles valores de esta
O: Las demás son correctas
A: 1

Q: El algoritmo de ordenación Quicksort divide el problema en dos subproblemas. ¿Cuál es la complejidad temporal asintótica de realizar esa división?
O: $\Theta(\log n)$
O: $\Theta(n \log n)$
O: $\Theta(n)$
A: 2

Q: Se dispone de un conjunto de n valores numéricos dispuestos en un vector sin orden preestablecido. Se desea escribir una función que reciba ese vector y un valor k ($n/2 \leq k \leq n$) y que devuelva los k valores más pequeños dispuestos en otro vector de manera ordenada. ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
O: $O(kn)$
O: $O(k \log n)$
O: Ninguna de las otras dos opciones es cierta.
A: 1

Q: Un problema tiene subestructura óptima cuando....
O: ...se trata de un problema con complejidad inherentemente prohibitiva.
O: ...es posible escribir una solución voraz para el problema
O: ...su solución se puede construir eficientemente a partir de soluciones de subproblemas suyos.
A: 2

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición...
O: ... se comporta mejor cuando el vector ya está ordenado
O: ... El hecho de que el vector estuviera previamente ordenado o no, no incluye en la complejidad temporal de este algoritmo.
O: ... se comporta peor cuando el vector ya está ordenado
A: 2

Q: Uno de estos tres problemas no tiene una solución eficiente que siga el esquema de programación dinámica
O: El problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud.
O: El problema de la mochila discreta.
O: El problema de las torres de Hanoi.
A: 2

Q: ¿Qué hace la siguiente función?
```cpp
void f(vector<int> &A) {
  priority_queue<int> pq;
  for (auto a : A)
    pq.push(a);
  A.clear();
  while (!pq.empty()) {
    A.push_back(pq.top());
    pq.pop();
  }
}
```
O: Ordena el vector A
O: Invierte el vector A (el último elemento quedará el primero)
O: Nada, deja el vector como estaba
A: 0

Q: Las relaciones de recurrencia
O: Aparecen solo cuando la solución es del tipo divide y vencerás.
O: Sirven para reducir el coste temporal de una solución cuando es prohibitivo.
O: Expresan recursivamente el coste temporal de un algoritmo.
A: 2

Q: La mejor solución que se conoce para el problema de la mochila continua sigue el esquema ...
O: ...divide y vencerás.
O: ...ramificación y poda.
O: ...voraz.
A: 2

Q: La versión de Quicksort que utiliza como pivote la mediana del vector...
O: ... se comporta mejor cuando el vector ya está ordenado.
O: ... se comporta peor cuando el vector ya está ordenado.
O: ... El hecho de que el vector estuviera previamente ordenado o no, no influye en la complejidad temporal de este algoritmo.
A: 2

Q: Dada la siguiente función: 
```cpp
int exa(vector<int> &v) {
  int j, i = 1, n = v.size();
  if (n > 1)
    do {
      int x = v[i];
      for (j = i; j > 0 && v[j - 1] > x; j--)
        v[j] = v[j - 1];
      v[j] = x;
      i++;
    } while (i < n);
  return 0;
}
```
O: La complejidad temporal en el mejor de los casos es $\Omega(n)$.
O: La complejidad temporal en el mejor de los casos es $\Omega(1)$.
O: La complejidad temporal exacta es $\Theta(n^2)$.
A: 0

Q: ¿Cuál es la complejidad temporal de la siguiente función recursiva?
```cpp
unsigned desperdicio(unsigned n) {
  if (n <= 1)
    return 0;
  unsigned sum = desperdicio(n / 2) + desperdicio(n / 2);
  for (unsigned i = 1; i < n - 1; i++)
    for (unsigned j = 1; j <= i; j++)
      for (unsigned k = 1; k <= j; k++)
        sum += i * j * k;
  return sum;
}
```
O: $O(2^n)$
O: $O(n^3 \log n)$
O: $O(n^3)$
A: 2

Q: La siguiente relación de recurrencia expresa la complejidad de un algoritmo recursivo, donde $g(n)$ es una función polinómica: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 2T(n/2)+g(n) & \text{en otro caso} \end{cases}$ Di cuál de las siguientes afirmaciones es cierta:
O: Si $g(n) \in O(n)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación Mergesort.
O: Si $g(n) \in O(n^2)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación mediante inserción binaria.
O: Si $g(n) \in O(1)$ la relación de recurrencia representa la complejidad temporal del algoritmo de búsqueda dicotómica.
A: 0

Q: Uno de estos tres algoritmos no resuelve el mismo problema que los otros dos. ¿Cuál?
O: El algoritmo de Floyd y Warshall.
O: El algoritmo de Prim.
O: El algoritmo de Kruskal.
A: 0

Q: Un informatico quiere subir a una montana y para ello decide que tras cada paso, el siguiente debe tomarlo en la direccion de maxima pendiente hacia arriba. Ademas, entendera que ha alcanzado la cima cuando llegue a un punto en el que no haya ninguna direccion que sea cuesta arriba. ¿que tipo de algoritmo esta usando nuestro informatico?
O: un algoritmo de programacion dinamica.
O: un algoritmo voraz
O: un algoritmo divide y venceras
A: 1

Q: Sea V el conjunto de todos los valores faciales que presentan las monedas de un pais, una cantidad M¿Cual de las siguientes afirmaciones es falsa?
O: El algoritmo que calcularia n(M) asi seria un algoritmo voraz y tendria un coste razonable.
O: El algoritmo recursivo que calcularia n(M) asi tendria un coste prohibitivo
O: El algoritmo recursivo que calcularia n(M) se podria convertir en un algoritmo con coste razonable usando memoizacion.
A: 0

Q: El funcionamiento del algoritmo de ordenación Heapsort es similar al algoritmo de ordenación por selección, ya que localiza el valor más grande y lo sitúa en la posición final del vector; a continuación, localiza el siguiente valor más grande y lo sitúa en la posición anterior a la última, etc. ¿Cuál de las afirmaciones siguientes es cierta?
O: El algoritmo Heapsort tiene una complejidad $O(n)$ en el caso peor, mejor que la complejidad $O(n^2)$ del algoritmo de selección, porque Heapsort utiliza una algoritmo mucho más eficiente para localizar los valores del vector que valen más.
O: El algoritmo Heapsort tiene una complejidad $O(n \log n)$ en el caso peor, mejor que la complejidad $O(n^2)$ del algoritmo de selección, porque Heapsort utiliza una algoritmo mucho más eficiente para localizar los valores del vector que valen más.
O: Por ello, los dos algoritmos tienen la misma complejidad en el caso peor, $O(n^2)$, aunque la complejidad en el caso mejor de Heapsort es $O(n \log n)$.
A: 1

Q: Cuando se calculan los coeficientes binomiales usando la recursión $\binom{n}{r} = \binom{n-1}{r} + \binom{n-1}{r-1}$, con $\binom{n}{0} = \binom{n}{n} = 1$, qué problema se da y cómo se puede resolver?
O: La recursión puede ser infinita y por tanto es necesario organizarla según el esquema iterativo de programación dinámica.
O: Se repiten muchos cálculos y ello se puede evitar haciendo uso de una estrategia voraz.
O: Se repiten muchos cálculos y ello se puede evitar usando programación dinámica.
A: 2

Q: El estudio de la complejidad resulta realmente interesante para tamaños grandes de problema por varios motivos:
O: Las diferencias reales en tiempo de compilación de algoritmos con diferente coste para tamaños pequeños del problema no suelen ser muy significativas.
O: Las diferencias reales en tiempo de ejecución de algoritmos con diferente coste para tamaños grandes del problema no suelen ser muy significativas.
O: Ninguna de las anteriores.
A: 2

Q: La solución de programación dinámica iterativa del problema de la mochila discreta...
O: ... calcula menos veces el valor de la mochila que la correspondiente solución de programación dinámica recursiva
O: ... tiene la restricción de que los valores tienen que ser enteros positivos
O: ... tiene un coste temporal asintótico exponencial con respecto al número de objetos
A: 1

Q: Los algoritmos de ordenación Quicksort y Mergesort tienen en común...
O: que ordenan el vector sin usar espacio adicional
O: que aplican la estrategia divide y vencerás
O: que se ejecutan en $O(n)$
A: 1

Q: Cuando se resuelve usando backtracking un problema de n decisiones en el que siempre hay como mínimo 2 opciones para cada decisión, ¿cuál de las siguientes complejidades es la mejor que nos podemos encontrar?
O: $O(n!)$
O: $O(n^2)$
O: $O(2^n)$
A: 2

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición ...
O: ... se comporta mejor cuando el vector ya está ordenado.
O: ... se comporta peor cuando el vector ya está ordenado.
O: ... El hecho de que el vector estuviera previamente ordenado o no, no influye en la complejidad temporal de este algoritmo.
A: 1

Q: Qué diferencia (entre otras) hay entre el algoritmo de Prim y el de Kruskal?
O: Aún siendo el grafo de partida totalmente conexo, el algoritmo de Kruskal garantiza la solución óptima mientras que el de Prim sólo garantiza un subóptimo.
O: El algoritmo de Prim es voraz y el de Kruskal no.
O: El subgrafo que paso a paso va generando el algoritmo de Prim siempre contiene una única componente conexa mientras que el de Kruskal no tiene por qué.
A: 2

Q: Un algoritmo recursivo basado en el esquema de divide y vencerás ...
O: Las demás opciones son verdaderas
O: ... nunca tendrá una complejidad exponencial
O: ... será más eficiente cuanto más equitativa sea la división en subproblemas
A: 2

Q: Con respecto al tamaño del problema ¿Cual es el orden de complejidad temporal asintotica de la siguiente funcion? `void traspuesta(mat & A)`
O: constante
O: lineal
O: cuadratico
A: 1

Q: Un problema de tamaño $n$ puede transformarse en tiempo $O(n^2)$ en nueve de tamaño $n/3$. Por otro lado, la solución al problema cuando la talla es $1$ requiere un tiempo constante. ¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
O: O(n^2)
O: O(n^2 log n)
O: O(n log n)
A: 1

Q: ¿Podemos saber cuál sería el elemento en posición k cuando ordenáramos un vector de n elementos sin tener que ordenarlo?
O: Sí, y el algoritmo es $\Omega(n)$ y $O(n^2)$, aunque la frecuencia de los casos peores disminuye muy rápidamente con n.
O: Sí, y el algoritmo es $\Omega(n \cdot \log(n))$ y $O(n^2)$, aunque la frecuencia de los casos peores disminuye muy rápidamente con n.
O: No. Debemos ordenarlo.
A: 0

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
O: $O(n^2) \subset O(2^{\log_2(n)}) \subset O(2^n)$
O: $O(2^{\log_2(n)}) \subset O(n^2) \subset O(n!)$
O: $O(4^{\log_2(n)}) \subset O(n) \subset O(2^n)$
A: 1

Q: Si un problema de optimización lo es para una función que toma valores continuos
O: El uso de memoria de la programación dinámica iterativa y de la programación dinámica recursiva es el mismo independientemente de si el dominio es discreto o continuo.
O: La programación dinámica recursiva puede resultar mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
O: La programación dinámica iterativa siempre es mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
A: 1

Q: La programacion dinamica...
O: en algunos casos se puede utilizar para resolver problemas de optimizacion con dominios continuos pero probablemente pierda su eficacia ya que puede disminuir drasticamente el numero de subproblemas repetidos
O: Las otras dos opciones son ciertas
O: normalmente se usa para resolver problemas de optimizacion con dominios discretizables puesto que las tablas se han de indexar con este tipo de valores.
A: 1

Q: Considera la función siguiente, donde todos los elementos del vector L son distintos. Considera como medida significativa las asignaciones a max, entonces el numero de asignaciones para el caso mejor y peor son, respectivamente:
```cpp
int maximo(int L[N]) {
  int i, max;
  max = L[0];
  for (i = 1; i < N; i++)
    if (max < L[i])
      max = L[i];
  return (max);
}
```
O: 1 cuando el mayor elemento esta en la posición inicial y n cuando los elementos están ordenados ascendentemente
O: 1 cuando los elementos están ordenados ascendentemente y n cuando los elementos están en orden inverso
O: depende siempre del valor de N, estén como estén dispuestos los datos, si N=1 se obtiene el mejor caso, y el peor con el mayor numero de N
O: siempre tiene un coste lineal, independiente del orden inicial, pues todos los elementos son distintos por hipótesis y se realiza un numero fijo de iteraciones
A: 0

Q: Queremos aplicar la técnica de memoización a la siguiente función recursiva:
```cpp
double f(double x) {
  if (x <= 2)
    return x;
  return f(sqrt(x - 1)) + f(sqrt(x - 2));
}
```
¿Cuál sería un buen candidato para el almacén? (La función `sqrt()` obtiene la raíz cuadrada; xMax es el valor de x en la primera llamada.)
O: `vector < vector < double > > M(xMax+1, vector < double > (xMax+1))`
O: `vector < double > M(xMax+1)`
O: Ninguna de las otras dos opciones es válida.
A: 2

Q: Un conjunto es
O: Ninguna de las anteriores
O: Una estructura no lineal en la que deberemos tener en cuenta el orden de llegada de los dats
O: Una estructura lineal en la que puede haber repetidos
O: Una estructura lineal y ordenada en la que no puede haber repetidos
O: Una estructura no lineal en la que no puede haber elementos repetido y los elementos están ordenados
A: 0

Q: La serie de números de Fibonacci se define de la siguiente forma:$$fib(n) = \begin{cases} 1 & n \leq 1 \\ fib(n-1) + fib(n-2) & n > 1 \end{cases}$$¿Qué implementación de entre las siguientes supone el menor coste?
O: Divide y vencerás
O: Programación dinámica
O: Cualquiera de las dos anteriores
A: 1

Q: La complejidad temporal en el mejor de los casos...
O: Las demás opciones son verdaderas.
O: ... es el tiempo que tarda el algoritmo en resolver la talla más pequeña que se le puede presentar.
O: ... es una función de la talla que tiene que estar definida para todos los posibles valores de esta.
A: 2

Q: Los algoritmos de ordenación quicksort y mergesort tienen en común:
O: Que ordenan el vector sin usar espacio adicional.
O: Que aplican la estrategia de Divide y vencerás.
O: Que ejecutan en tiempo $O(n)$.
A: 1

Q: La complejidad en el peor de los casos de un algoritmo de ramificación y poda
O: Es exponencial con el número de decisiones a tomar.
O: Puede ser polinómica con el número de decisiones a tomar.
O: Puede ser exponencial con el número de alternativas por cada decisión.
A: 0

Q: Al resolver el problema del viajante de comercio mediante backtracking asumiendo un grafo de n vértices totalmente conexo ¿cuál de estas es una buena cota pesimista al iniciar la búsqueda?
O: Se ordenan las aristas restantes de menor a mayor distancia y se calcula la suma de las n aristas más cortas.
O: Se resuelve el problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido.
O: Se multiplica n por la distancia de la arista más corta que nos queda por considerar.
A: 1

Q: ¿Por qué muchos algoritmos voraces presentan complejidades temporales en $O(n \log n)$?
O: Porque primero ordenan de alguna manera los elementos y porque una vez ordenados la complejidad temporal del proceso de selección de los elementos que se incorporarán a la solución está en $O(n \log n)$.
O: Porque primero ordenan de alguna manera los elementos y porque una vez ordenados la complejidad temporal del proceso de selección de los elementos que se incorporarán a la solución es estrictamente inferior a $O(n \log n)$.
O: Porque el proceso de selección de los elementos que se incorporarán a la solución es siempre $O(n \log n)$.
A: 0

Q: Tenemos un problema en el que hay que almacenar un numero variable de tiendas en la que existen un numero también variable de artículos tanto las tiendas como los artículos tienen una clave identificativa teniendo en cuenta que tenemos que realizar muchas consultar inserciones y borrados de artículos que estructura será la mas adecuada para implementarlo tened en cuenta que una tienda se puede cerrar en cualquier momento y todos sus artículos serian repartidos por las demás tiendas
O: Un árbol AVL para las tiendas y dentro de cada AVL otro para los artículos
O: Una tabla hashing para las tiendas, y dentro de cada celda un conjunto de artículos
O: Una tabla hashing para almacenar las tiendas y dentro de cada tienda un árbol AVL para los artículos
O: Un árbol AVL para las tiendas y dentro de cada nodo un árbol de búsqueda
A: 3

Q: Dado un problema de minimización resuelto mediante un esquema de ramificación y poda, ¿qué propiedad cumple una cota optimista?
O: Las otras dos opciones son ambas falsas.
O: Siempre es mayor o igual que la mejor solución posible alcanzada.
O: Asegura un ahorro en la comprobación de todas las soluciones factibles.
A: 1

Q: ¿Qué cota se deduce de la siguiente relación de recurrencia?
$f(n) = \begin{cases} 1 & n = 1 \\ n + 4f(\frac{n}{2}) & n > 1 \end{cases}$
O: $f(n) \in \Theta(n^2)$
O: $f(n) \in \Theta(n)$
O: $f(n) \in \Theta(n \log n)$
A: 0

Q: ¿Qué ocurre si la cota pesimista de un nodo se corresponde con una solución que no es factible?
O: Que el algoritmo sería incorrecto pues podría descartarse un nodo que conduce a la solución óptima.
O: Que el algoritmo sería más lento pues se explorarían más nodos de los necesarios.
O: Nada especial, las cotas pesimistas no tienen por qué corresponderse con soluciones factibles.
A: 0

Q: La ventaja de RyP frente a Backtracking es que la primera genera las soluciones posibles al problema mediante..
O: Las otras dos son verdaderas
O: un recorrido guiado por la cola de prioridad de donde se extraen primero los nodos que representan subárboles más prometedores del espacio de soluciones
O: Un recorrido guiado por estimaciones de las mejores ramas del árbol que representa el espacio de soluciones
A: 0

Q: ¿Cuál es la complejidad espacial del algoritmo Quicksort?
O: $O(n)$.
O: $O(n \log n)$.
O: $O(1)$.
A: 2

Q: Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
  if (n < 1)
    return;
  for (int i = 0; i < n; i++)
    for (int j = 0; j < n; j++)
      for (int k = 0; k < n; k++)
        cout << "*";
  for (int i = 0; i < 8; i++)
    if (n / 2)
      ;
}
```
O: $\Theta(n^3)$
O: $\Theta(n^2 \log n)$
O: $\Theta(n^3 \log n)$
A: 2

Q: Se quieren ordenar d números distintos comprendidos entre 1 y n. Para ello se usa un array de n booleanos que se inicializan primero a false. A continuación se recorren los d números cambiando los valores del elemento del vector de booleanos correspondiente a su número a true. Por último se recorre el vector de booleanos escribiendo los índices de los elementos del vector de booleanos que son true. ¿Es este algoritmo más rápido (asintóticamente) que el mergesort?
O: Sí, ya que el mergesort es $O(n \log n)$ y este es $O(n)$.
O: Solo si $d \log d > kn$ (donde k es una constante que depende de la implementación).
O: No, ya que este algoritmo ha de recorrer varias veces el vector de booleanos.
A: 1

Q: En cuanto a la complejidad temporal de la siguiente función, ¿qué podemos decir acerca del mejor de los casos?
```cpp
int f(vector<int> &v) {
  int n = v.size(), i = 2, k = 0;
  while (i < n) {
    int j = i;
    while (v[j] != v[1]) {
      k++;
      j = j / 2;
    }
    i = i + 2;
  }
  return k;
}
```
O: Que el mejor de los casos ocurre cuando el vector tiene 2 elementos o menos y la complejidad es $\Omega(1)$.
O: Que uno de los mejores casos ocurre cuando $v[j] = v[1] \forall j \in \mathbb{N}$ y la complejidad es $\Omega(n)$.
O: Las otras dos opciones son ambas falsas.
A: 1

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa o bien al contrario: dos son falsas y una es verdadera. Marca la que en este sentido es distinta a las otras dos.
O: $2n^3 - 10n^2 + 1 \in O(n^3)$
O: $n + n\sqrt{n} \in \Omega(n)$
O: $n + n\sqrt{n} \in \Theta(n)$
A: 2

Q: Indicad cuál de estas tres expresiones es falsa
O: $\Theta(n) \subset O(n)$
O: $\Theta(n) \subset \Theta(n^2)$
O: $\Theta(n/2) = \Theta(n)$
A: 1

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
O: ... será más eficiente cuanto más equitativa sea la división en subproblemas.
O: Las demás opciones son verdaderas.
O: ... nunca tendrá una complejidad exponencial.
A: 0

Q: La complejidad en el caso peor un algoritmo RyP
O: puede ser exponencial con el número de alternativas por cada decisión
O: puede ser polinómica con el número de decisiones a tomar
O: es exponencial con el número de decisiones a tomar
A: 2

Q: Indica cuál es la complejidad, en función de $n$, del fragmento siguiente:
```cpp
a = 0;
for (int i = 0; i < n * n; i++)
  a += A[(i + j) % n];
```
O: $O(n^2)$
O: $O(n \log(n))$
O: $O(n)$
A: 0

Q: ¿Se puede reducir el coste temporal de un algoritmo recursivo almacenando los resultados devueltos por las llamadas recursivas?
O: No, ello no reduce el coste temporal ya que las llamadas recursivas se deben realizar de cualquier manera.
O: Sí, si se repiten llamadas a la función con los mismos argumentos.
O: No, solo se puede reducir el coste convirtiendo el algoritmo recursivo en iterativo.
A: 1

Q: En una cuadrícula se quiere dibujar el contorno de un cuadrado de n casillas de lado, ¿cuál será la complejidad temporal del mejor algoritmo que pueda existir?
O: $O(n^2)$
O: $O(\sqrt{n})$
O: $O(n)$
A: 2

Q: El problema del alfarero (solución continua con tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$? Si el alfarero pudiera vender objetos sin terminar a un precio proporcional al estado de terminación. ¿Cuál de las siguientes estrategias sería más apropiada para resolverla?
O: Vuelta atrás.
O: Un algoritmo voraz.
O: Programación dinámica.
A: 1

Q: Sea un grafo no dirigido con n vertices entonces
O: Si se hace un recorrido en anchura partiendo del nodo x el conjunto de vértices visitados es igual al conjunto total de vértices del grafo
O: Si se hace un recorrido en anchura que parte del nodo x el conjunto de visitados al final será igual que resultaría si el recorrido fuera en profundidad
O: Si se hace un recorrido en anchura partiendo del nodo x no puede asegurarse que el conjunto de visitados al final resulte ser el mismo que si el recorrido fueran en profundidad
O: Si se hace un recorrido en anchura que parte del nodo x y el grafo es cíclico se entra en un bucle infinito
O: Si se hace un recorrido en anchura partiendo del nodo x y el conjunto de visitados resultante n es igual al conjunto total de vértices es porque el grafo no es fuertemente conexo
A: 1

Q: ¿Garantiza el uso de una estrategia "divide y vencerás" la existencia de una solución de complejidad temporal polinómica a cualquier problema?
O: No.
O: Sí, en cualquier caso.
O: Sí, pero siempre que la complejidad temporal conjunta de las operaciones de descomposición de problema y la combinación de las soluciones sea polinómica.
A: 0

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva:
```cpp
unsigned f(unsigned y, unsigned x) {
  // suponemos y >= x
  if (x == 0 || y == x)
    return 1;
  return f(y - 1, x - 1) + f(y - 1, x);
}
```
¿Cuál es la mejor estructura para el almacén?
O: `int A[]`
O: `int A`
O: `int A[][]`
A: 1

Q: Considerad estos dos fragmentos:`s=0; for(i=0;i<n;i++) s+=i;` y `s=0; for(i=0;i<n;i++) if (a[i] != 0) s+=i;` y un array a[i] de números enteros. Indicad cuál de estas tres afirmaciones es cierta:
O: El coste temporal asintótico del primer programa en el caso peor es más alto que en el segundo.
O: El coste temporal asintótico, tanto en el caso mejor como en el caso peor, de los dos programas es el mismo.
O: El coste temporal asintótico del segundo programa en el caso peor es más alto que en el primero.
A: 1

Q: Tenemos un vector desordenado y queremos obtener los tres elementos más pequeños. ¿Cuál seria la complejidad emporal más ajustada para hacerlo? (sin pérdida de generalidad puedes suponer que en el vector todos los elementos son distintos)
O: El logaritmo de la longitud del vector
O: Lineal con la longitud del vector
O: Cuadrática con la longitud del vector
A: 1

Q: ¿Para qué se utiliza el TAD "Union-find" en el algoritmo de Kruskal?
O: Para comprobar si un arco forma ciclos
O: Para comprobar si un vétice ya ha sido visitado
O: Para comprobar si dos vértices son equivalentes
A: 0

Q: Tenemos n sustancias diferentes en polvo y queremos generar todas las distintas formas de mezclarlas de forma que el peso no supere un gramo. Como la balanza que tenemos solo tiene precisión de 0.1 gramos no se considerarán pesos que no sean múltiplos de esa cantidad. Queremos hacer un programa que genere todas las combinaciones posibles.
O: No hay ningún problema en usar una técnica de vuelta atrás.
O: No se puede usar backtracking porque el número de combinaciones es infinito.
O: No se puede usar backtracking porque las decisiones no son valores abstractos.
A: 0

Q: Para resolver la versión general del problema de la mochila con n objetos y carga máxima W, hemos escrito un algoritmo de divide y vencerás que, sucesivamente, divide el problema en dos subproblemas; cada uno de ellos toma la mitad de los objetos y la mitad de la carga máxima de la mochila. El caso base ocurre cuando solo hay un objeto que se añade a la solución si cabe en la fracción de carga máxima que corresponde a ese subproblema, y si no cabe se descarta. Asumiendo que n y W son potencias exactas de 2, ¿qué podemos decir de esta solución?
O: Que con los resultados de los subproblemas no siempre se puede componer la solución del problema original.
O: Que no cumple el teorema de reducción.
O: Que, aunque con los resultados de los subproblemas se puede componer la solución del problema original, esta formulación no mejora la solución estudiada en clase.
A: 0

Q: ¿Cuál de las siguientes formulaciones expresa mejor la complejidad temporal, en función del parámetro n, de la siguiente función? (asumimos que n es potencia exacta de 2)
```cpp
int f(int n) {
  int k = 0;
  for (int i = 2; i <= n; i *= 2)
    for (int j = i; j > 0; j -= 2)
      k++;
  return k;
}
```
O: $$\sum_{p=2}^{n/2} \frac{p-1}{2}$$
O: $$\sum_{p=1}^{\log n} 2^{p-1}$$
O: $$\sum_{p=1}^{\log n} 2 \cdot (p-1)$$
A: 1

Q: Un vector de enteros de tamaño n tiene sus elementos estructurados en forma de montículo (heap). ¿Cuál es la complejidad temporal en el peor de los casos de borrar el primer elemento del vector y reconstruirlo posteriormente para que siga manteniendo la estructura de montículo?
O: $O(n)$.
O: $O(\log n)$.
O: $O(n \log n)$.
A: 1

Q: Sea el vector v = {1, 3, 2, 7, 4, 6, 8} cuyos elementos están dispuestos formando un montículo de mínimos. Posteriormente añadimos en la última posición del vector un elemento nuevo con valor 5. ¿Qué operación hay que hacer para que el vector siga representando un montículo de mínimos?
O: Intercambiar el 8 con el 5.
O: No hay que hacer nada pues el vector v = {1, 3, 2, 7, 4, 6, 8, 5} también es un montículo de mínimos.
O: Intercambiar el 7 con el 5.
A: 2

Q: Se pretende implementar mediante programación dinamica iterativa la función recursiva:
```cpp
unsigned f(unsigned x, unsigned v[]) {
  if (x == 0)
    return 0;
  unsigned m = 0;
  for (unsigned k = 0; k < x; k++)
    m = max(m, v[k] + f(x - k, v));
  return m;
}
```
¿Cuál es la mejor estructura para el almacén?
O: `int A`
O: `int A[]`
O: `int A[][]`
A: 1

Q: Di cuál de estos resultados de coste temporal asintótico es falso
O: La ordenación de un vector usando el algoritmo quicksort requiere en el peor caso $\Omega(n^2)$.
O: La búsqueda binaria en un vector ordenado requiere en el peor caso un tiempo en $O(\log n)$.
O: La ordenación de un vector usando el algoritmo mergesort requiere en el peor caso un tiempo de $\Omega(n^2)$.
A: 2

Q: Cuando la descomposición de un problema da lugar a subproblemas de tamaño similar al original, muchos de los cuales se repiten, ¿qué esquema es a priori más apropiado?
O: Ramificación y poda.
O: Programación dinámica.
O: Divide y vencerás.
A: 1

Q: En un problema de minimización resuelto mediante ramificación y poda, una cota pesimista es...
O: Ninguna de las otras dos opciones es cierta.
O: ... una cota superior para el valor óptimo, pero que nunca coincide con este.
O: ... una cota inferior para el valor óptimo que a veces coincide con este.
A: 0

Q: Encargamos a un becario que elabore un algoritmo para sumar todos los números de un vector. Al cabo de un rato nos viene con un algoritmo cuya complejidad temporal es $O(\log(n))$. ¿Qué hacemos?
O: Despedimos al becario, eso es imposible.
O: Subimos el sueldo al becario, ha encontrado un algoritmo innovador.
O: Damos las gracias al becario, ese es el algoritmo obvio.
A: 0

Q: Una de las tres afirmaciones siguientes sobre los algoritmos que obtienen el árbol de recubrimiento mínimo de un grafo ponderado no dirigido es cierta. ¿Cuál es?
O: El algoritmo de Kruskal va ampliando un único árbol de recubrimiento mínimo.
O: El algoritmo de Prim se puede acelerar usando una estructura de datos de conjuntos disjuntos con las operaciones union y find.
O: El algoritmo de Prim va ampliando un único árbol de recubrimiento mínimo.
A: 2

Q: La complejidad temporal (o coste temporal asintótico) en el mejor de los casos
O: Las dos anteriores son verdaderas.
O: Es el tiempo que tarda el algoritmo en resolver la talla más pequeña que se le puede presentar.
O: Es una función de la talla, o tamaño del problema, que tiene que estar definida para todos los posibles valores de esta.
A: 2

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos
O: $O(n^2) \subset O(2^{\log_2 n})$
O: $n + n \log_2 n \in \Omega(n + n \log_2 n)$
O: $\Omega(n^2) \subset \Omega(n)$
A: 0

Q: La mejor solución que se conoce para el problema de la mochila continua sigue el esquema
O: Divide y vencerás.
O: Voraz.
O: Ramificación y poda.
A: 0

Q: Qué complejidad temporal asintótica cabe esperar de un algoritmo divide y vencerás cuya función descomponer produce, en tiempo constante, dos subproblemas iguales de tamaño $n - 2$ cada uno y cuya función combinar es lineal con n, donde n es el tamaño del problema.
O: $O(n \log n)$
O: $O(2^n)$
O: $O(n^2)$
A: 0

Q: Comparando los algoritmos de multiplicacion de matrices y warshall para un grafo no valuado G tenemos que
O: Tienen complejidad diferente la multiplicación de matrices tiene O(n^4) y warshall O(n^3) la multiplicación de matrices se basa en aplicaciones de espacio de búsqueda y warshall se basa en ir obteniendo caminos de longitud mayor
O: Ambos tienen la misma complejidad, multiplicación de matrices se basa en ir obteniendo caminos de longitud mayor aplicaciones de espacio de búsqueda y warshall se basa en aplicaciones de espacio de búsqueda
O: Ambos tienen la misma complejidad, multiplicación de matrices se basa en aplicaciones de espacio de búsqueda y warshall se basa en ir obteniendo caminos de longitud mayor
O: Tienen complejidad diferente la multiplicación de matrices tiene O(n^4) y warshall O(n^3) la multiplicación de matrices se basa en ir obteniendo caminos de longitud mayor y warshall se basa en aplicaciones de espacio de búsqueda
A: 3

Q: Cuando se resuelve, usando Backtracking, un problema de n decisiones, en el que siempre hay como mínimo dos opciones por decisión, cual de estas complejidades en el caso peor es la mejor que nos podemos encontrar
O: $O(n!)$
O: $O(2^n)$
O: $O(n^2)$
A: 1

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición...
O: ... se comporta mejor cuando el vector ya está ordenado.
O: ... no presenta caso mejor y caso peor para instancias del mismo tamaño.
O: ... se comporta peor cuando el vector ya está ordenado.
A: 2

Q: Dado el algoritmo el caso peor el numero de nodos procesados: 
```
Módulo Ejercicio (ent A es ArbolBinario) devuelve entero
variables
	Izq, Der es ArbolBinario
inicio
	si no A.Vacio entonces
		A.HijoIzq (Izq);
		A.HijoDer (Der);
		devolver (ejercicio(izq) + ejercicio(der) + 1)
	si no
		devolver (0)
	finsi
fin
```
O: es proporcional al logaritmo siempre
O: es proporcional a n*logn
O: sigue una función lineal siempre
O: depende del grado de equilibrio que tenga
O: ninguna respuesta es correcta
A: 2

Q: Se dispone de un conjunto de n valores numéricos dispuestos en forma de árbol binario y se desea obtener el valor de la suma de todos ellos. ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
O: $O(\log(n))$
O: $O(n)$
O: $O(n \cdot \log(n))$
A: 1

Q: Puede ser que una solución recursiva con memoización a un problema de optimización realice menos evaluaciones de la función que computa el valor de una solución parcial que una basada en programación dinámica iterativa y por lo tanto acabo siendo más rápida?
O: Sí; de hecho, esto pasa con el problema de la mochila discreta con pesos enteros.
O: No; las dos soluciones tienen que realizar el mismo número de evaluaciones de la función que computa el valor de una solución parcial, y la solución recursiva es más lenta porque tiene que gestionar las llamadas recursivas (argumentos, reserva de espacio temporal, etc).
O: No; las soluciones recursivas realizan más evaluaciones de la función que computa el valor de una solución parcial que las iterativas correspondientes.
A: 0

Q: La talla o tamaño de un problema depende de:
O: Conjunto de valores asociados a la entrada y salida del problema.
O: Conjunto de valores asociados a la salida del problema.
O: Conjunto de valores asociados a la entrada del problema.
A: 2

Q: Dada la siguiente función recursiva:
```cpp
unsigned f(unsigned a, unsigned b) {
  if (a < 3)
    return a + 2 * b;
  return f(a - 1, (7 * b) % 10);
}
```
donde suponemos que siempre se va a invocar la función con b < 10. Queremos acelerarla aplicando la técnica de programación dinámica iterativa. ¿Cómo quedaría?
O: ```cpp
unsigned f(unsigned a, unsigned b) {
  vector<vector<unsigned>> M(a, vector<unsigned>(10));
  for (unsigned j = 0; j < 10; j++)
    for (unsigned i = 0; i <= a; i++)
      if (i < 3)
        M[i][j] = i + 2 * j;
      else
        M[i][j] = M[i - 1][(7 * j) % 10];
  return M[a][b];
}
```
O: ```cpp
unsigned f(unsigned a, unsigned b) {
  vector<vector<unsigned>> M(a + 1, vector<unsigned>(10));
  for (unsigned i = 0; i <= a; i++)
    for (unsigned j = 0; j < 10; j++)
      if (i < 3)
        M[i][j] = i + 2 * j;
      else
        M[i][j] = M[i - 1][(7 * j) % 10];
  return M[a][b];
}
```
O: ```cpp
unsigned f(unsigned a, unsigned b) {
  vector<vector<unsigned>> M(a + 1, vector<unsigned>(10));
  for (unsigned j = 0; j < 10; j++)
    for (unsigned i = 0; i <= a; i++)
      if (i < 3)
        M[i][j] = i + 2 * j;
      else
        M[i][j] = M[i - 1][(7 * j) % 10];
  return M[a][b];
}
```
A: 0

Q: ¿Tiene sentido usar una función que indique cómo de prometedor es un nodo cuando resolvemos un problema que no es de optimización mediante ramificación y poda?
O: No. Los problemas que no son de optimización no se pueden resolver mediante ramificación y poda.
O: No. Sólo tiene sentido usar una función de promesa en problemas de optimización, y esta ha de ser necesariamente una cota optimista.
O: Sí, si se puede diseñar de manera que intente predecir si un nodo conducirá o no a la solución.
A: 2

Q: Se desea ordenar una lista enlazada de n elementos haciendo uso del algoritmo Mergesort. En este caso, al tratarse de una lista, la complejidad temporal asintótica de realizar la división en subproblemas resulta ser lineal con el tamaño de esa lista. ¿Cuál sería entonces el coste temporal de realizar dicha ordenación?
O: $\Theta(n \log n)$
O: Ninguna de las otras dos opciones es cierta.
O: $\Theta(n^2)$
A: 0

Q: Sea la siguiente relacion de recurrencia:$T(n) = \begin{cases} 1 & si\,n \le 1 \\ 8T(\frac{n}{8}) + g(n) & en\,otro\, caso\end{cases}$Si $T(n) \in \Theta(n^2)$, ¿en cuál de estos tres casos nos podemos encontrar?
O: $g(n) = n^3$
O: $g(n) = n^2$
O: $g(n) = n$
A: 1

Q: La complejidad temporal en el mejor de los casos
O: Es una función del tamaño o talla del problema que tiene que estar definida para todos los posibles valores de esta.
O: Las otras dos opciones son ciertas.
O: Es el tiempo que tarda el algoritmo en resolver el problema de tamaño o talla más pequeña que se le puede presentar.
A: 0

Q: ¿Qué aporta la técnica de ramificación y poda frente a la de vuelta atrás?
O: Eficiencia. Los algoritmos de ramificación y poda son más eficientes que los de vuelta atrás.
O: La posibilidad de combinar el uso de cotas pesimistas y optimistas para cualquier nodo ya sea completado o sin completar. En vuelta atrás esto no se puede hacer.
O: La posibilidad de analizar diferentes estrategias para seleccionar el siguiente nodo a expandir.
A: 2

Q: Tenemos un vector ordenado de tamaño $n_0$ y un vector desordenado de tamaño $n_d$ y queremos obtener un vector ordenado con todos los elementos. ¿Qué será más rápido?
O: Depende de si $n_o > n_d$ o no.
O: Insertar los elementos del vector desordenado (uno a uno) en el vector ordenado.
O: Ordenar el desordenado y luego mezclar las listas.
A: 2

Q: Dado el siguiente programa recursivo:
```cpp
int f(int n) {
  // Se asume que n >= 0 if (n == 0) return 1;
  return f(n - 1) + f(n - 2);
}
```
si quisiéramos mejorarlo haciendo uso de la técnica de programación dinámica, ¿cuáles serían las complejidades temporal y espacial más ajustadas del algoritmo resultante?
O: Respectivamente, $O(n)$ y $O(1)$
O: Ambas complejidades serían $O(1)$
O: Ambas complejidades serían $O(n)$
A: 0

Q: La mejor solución que se conoce para el problema de la mochila continua sigue el esquema de...
O: ... ramificación y poda.
O: ... voraz.
O: ... divide y vencerás
A: 2

Q: Tenemos un conjunto de n enteros positivos y queremos encontrar el subconjunto de tamaño m de suma mínima
O: Una técnica voraz daría una solución óptima
O: Para encontrar la solución habría que probar con todas las combinaciones posibles de m enteros, con lo que RyP no aporta nada con respecto a Backtracking
O: Lo mas adecuado sería usar una técnica de ramificación y poda, aunque en el peor caso el coste temporal sería exponencial
A: 0

Q: Una de estas tres situaciones no es posible
O: $f(n) \in O(n)$ y $f(n) \in \Omega(1)$
O: $f(n) \in O(n)$ y $f(n) \in O(n^2)$
O: $f(n) \in \Theta(n^2)$ y $f(n) \in O(n)$
A: 2

Q: Un algoritmo recursivo basado en divide y vencerás
O: Las demás son ciertas
O: será mas eficiente cuanto mas equitativa sea la división en subproblemas
O: Nunca tendrá complejidad exponencial
A: 1

Q: Un programa con dos bucles anidados uno dentro de otro, cada uno de los cuales hace aproximadamente n iteraciones, tarda un tiempo
O: $O(n)$
O: $O(n^2)$
O: $O(2^n)$
A: 1

Q: Un ladrón entra por la noche en la quesería más prestigiosa del mercado central con una larga mochila cilíndrica que tiene exactamente el diámetro de los quesos (todos los quesos son cilindros del mismo diámetro y altura, siguiendo un nuevo estándar de la UE) en la que puede cargar exactamente un metro de quesos y con una sofisticada sierra radial quesera (con baterías) que le permite cortar un queso horizontalmente en lugar de hacer cuñas, de manera que se lleve un cilindro. Cada queso tiene un precio único, que no se repite en la tienda. Se quiere llevar queso por el máximo importe posible. Indica cuál de las siguientes afirmaciones sobre la carga óptima es falsa.
O: Lleva la mochila llena hasta arriba y como mucho ha usado la sierra radial para cortar un queso.
O: Los primeros quesos que ha cargado son, enteros, los quesos más caros de toda la quesería.
O: Lleva la mochila llena hasta arriba y ha usado la sierra radial más de una vez para llevarse porciones bien calculadas de los quesos más caros.
A: 2

Q: Indica cuál es la complejidad temporal en función de $n$, donde $A$ es un vector de enteros y $k$ es una constante que no depende de $n$, del fragmento siguiente:
```cpp
for (int i = k; i < n - k; i++) {
  A[i] = 0;
  for (int j = i - k; j < i + k; j++) {
    A[i] += B[j];
  }
}
```
O: $\Theta(k)$
O: $\Theta(n^2)$
O: $\Theta(n)$
A: 2

Q: Sea $f(n) = 3n + 4$. Dos de las tres afirmaciones siguientes prueban que $f(n) \in O(n)$. ¿Cuál es la que no?
O: Para todo $n > 4$ se cumple que $3n + 4 < 4n$
O: Para todo $n > 4/(c-3)$, con $c > 3$, se cumple que $3n + 4 < cn$.
O: Para todo $n < 4/(c-3)$, con $c > 4$, se cumple que $3n + 4 < cn$.
A: 2

Q: La función test() procesa una lista de n elementos y devuelve un real. La definición de la función es recursiva. Primero descompone la lista en dos sublistas de la misma longitud usando un segmento de código que tiene una complejidad lineal con la longitud de la lista, envía cada una de dos sublistas a test() para que la procese, hace una serie de operaciones, con el resultado y el valor de retorno, de coste temporal constante. ¿Cuál es el coste temporal asintótico de la función test() en función de n?
O: $\Theta(\log n)$
O: $\Theta(n \log n)$
O: $\Theta(n)$
A: 2

Q: El problema del alfarero (solución discreta con tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$? ¿Cuál de los siguientes esquemas algorítmicos resultaría más eficiente para resolverlo?
O: Programación dinámica.
O: Un algoritmo voraz.
O: Vuelta atrás.
A: 0

Q: Sea $f(n)$ la solución de la relación de recurrencia $f(n) = 2f(n/2) + 1$; $f(1) = 1$. Indica cual de estas tres expresiones es cierta.
O: $f(n) \in \Theta(n)$
O: $f(n) \in \Theta(n^2)$
O: $f(n) \in \Theta(n \log n)$
A: 0

Q: Dado un problema de optimización, se puede usar backtracking cuando...
O: Es condición necesaria y suficiente que el dominio de decisiones sea discreto o discretizable
O: De cumplirse que se puedan emplear mecanismos de poda basados en la mejor solución hasta el momento
O: Es condición necesaria, (aunque no suficiente) que el dominio de decisiones sea discreto o discretizable
A: 2

Q: La solución óptima al problema de encontrar el árbol de recubrimiento de coste mínimo para un grafo no dirigido, conexo y ponderado ...
O: ... se construye haciendo crecer un único árbol.
O: ... se construye haciendo crecer varios árboles que al final acaban injertados en un único árbol.
O: ... puede construir un único árbol que va creciendo o bien construir un bosque de árboles que al final se injertan en un único árbol
A: 2

Q: Si $f \in \Omega(g_1)$ y $f \in \Omega(g_2)$ entonces
O: $f \not\in \Omega(\min(g_1, g_2))$
O: $f \in \Omega(g_1 \cdot g_2)$
O: $f \in \Omega(g_1 + g_2)$
A: 2

Q: Sea el vector $v = \{1, 3, 2, 7, 4, 6, 8\}$ cuyos elementos están dispuestos formando un montículo de mínimos. Posteriormente añadimos en la última posición del vector un elemento nuevo con valor 5. ¿Qué operación hay que hacer para que el vector siga representando un montículo de mínimos?
O: Intercambiar el 7 con el 5.
O: Intercambiar el 8 con el 5.
O: No hay que hacer nada pues el vector $v = \{1, 3, 2, 7, 4, 6, 8,5\}$ también es un montículo de mínimos.
A: 0

Q: Sea $T(n) = n + T(n - 1)$ para $n > 1$ y $T(1) = 1$. Una de las afirmaciones siguientes es cierta. ¿Cuál?
O: $T(n) \in O(n^3)$
O: $T(n) \in O(n \log n)$
O: $T(n) \in O(n)$
A: 0

Q: Si $f \notin O(g_1)$ y $f \in O(g_2)$ entonces siempre se cumplirá:
O: $f \in \Omega(g_1 + g_2)$
O: $f \notin O(\max(g_1, g_2))$
O: $f \in \Omega(\min(g_1, g_2))$
A: 2

Q: ¿Cual de los siguientes pares de problemas son equivalentes en cuanto al tipo de solucian (Optima, factible, etc.) aportada por el método voraz?
O: La mochila continua y la asignación de tareas.
O: El fontanero diligente y el problema del cambio.
O: La mochila discreta y la asignación de tareas.
A: 2

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? $f(n) = 1 + f(n/b)$ si $n > 1$; $f(1) = 1$, con $b \in \mathbb{N}, b > 1$
O: $f(n) \in \Theta(n)$
O: $f(n) \in \Theta(\log n)$
O: Depende del valor de b.
A: 1

Q: Indica cuál es la complejidad, en función de n, del fragmento siguiente:
```cpp
for (int i = 0; i < n; i++) {
  A[i] = 0;
  for (int j = 0; j < 20; j++)
    A[i] += B[j];
}
```
O: $\Theta(n)$
O: $\Theta(n^2)$
O: $\Theta(n \log n)$
A: 0

Q: Tengo que sumar una larga lista de n cantidades diferentes y se me ha ocurrido que una manera de ganar tiempo es la siguiente estrategia recursiva: parto la lista en dos sublistas iguales, calculo su suma por separado usando la misma técnica y luego sumo las dos cantidades. Cuando al partir una lista me quedo con una cantidad sólo, la suma es esa cantidad, y si me quedan cero cantidades, la suma es cero. ¿Gano tiempo, es decir, hago menos sumas?
O: No, en este caso el coste temporal es $\Theta(n \log n)$.
O: Sí, ya que en este caso el coste temporal se reduce a $\Theta(\log n)$.
O: No, ya que la complejidad temporal del método propuesto es la misma que la de sumar una a una las cantidades
A: 2

Q: La complejidad del algoritmo es:
```cpp
función recursiva(n : entero) : entero;
var i : entero;
{
  if (n <= 1)
    then recursiva : = 1 else for (i = 1; i <= n; i++) writeln(i);
recursiva:
  = recursiva(n / 2) + recursiva(n / 2)
}
```
O: $O(2^n)$
O: $O(\log^2(n))$
O: $O(n \cdot \log(n))$
O: $O(\log(n))$
A: 2

Q: La complejidad de un algoritmo recursivo con dos llamadas recursivas crece de manera exponencial
O: Ninguna de las anteriores es correcta
O: Si el algoritmo es recursivo y tenemos el numero de datos es de 2^k, siendo k el numero de llamadas recursivas
O: Si en cada llamada recursiva vuelven a entrar los n datos
O: Si se va decrementando los datos de forma lineal
A: 3

Q: Una de las afirmaciones siguientes es cierta y las otras dos falsas. Indicad cuál es la cierta.
O: $O(n^n) \subset O(n!)$
O: $O(3^n) \subset O(2^n)$
O: $O(2^n) \subset O(n!)$
A: 2

Q: Se desea encontrar el camino más corto entre dos ciudades. Para ello se dispone de una tabla con la distancia entre los pares de ciudades en los que hay carreteras o un valor centinela (por ejemplo, -1) si no hay, por lo que para ir de la ciudad inicial a la final es posible que haya que pasar por varias ciudades. También se conocen las coordenadas geográficas de cada ciudad y por tanto la distancia geométrica (en línea recta) entre cada par de ciudades. Se pretende acelerar la búsqueda de un algoritmo de ramificación y poda priorizando los nodos vivos (ciudades) que estén a menor distancia geográfica de la ciudad objetivo
O: El nuevo algoritmo siempre será más rápido.
O: El nuevo algoritmo no garantiza que vaya a ser más rápido para todas las instancias del problema posibles.
O: Esta estrategia no asegura que se obtenga el camino más corto.
A: 1

Q: Dado el polinomio $f(n)= a_mn^m + a_{m-1}n^{m-1} + … + a_0,$ con $a_m \in{R^+}$ entonces f pertenece al orden:
O: $O(n^m)$.
O: $\Omega(n^m)$.
O: Las dos respuestas anteriores son correctas.
A: 2

Q: El coste temporal asintótico de insertar un elemento en un vector ordenado de forma que continúe ordenado es...
O: ...$O(n)$
O: ...$O(\log n)$
O: ...$O(n^2)$
A: 0

Q: Indica cuál es la complejidad temporal en función de n, donde A es un vector de enteros y k es una constante que no depende de n, del fragmento siguiente: 
```cpp
for (int i = k; i < n - k; i++) {
  A[i] = 0;
  for (int j = i - k; j < i + k; j++)
    A[i] += B[j];
}
```
O: $\Theta(k)$
O: $\Theta(n^2)$
O: $\Theta(n)$
A: 2

Q: Cuál de la siguientes es la complejidad temporal más ajustada para un algoritmo que calcula la potencia n-ésima de una matriz cuadrada, expresada en función de n?
O: $O(\log n)$
O: $O(n \log n)$
O: $O(n)$
A: 2

Q: Ante un problema que presenta una solución recursiva siempre podemos aplicar:
O: Divide y vencerás
O: Programación dinámica
O: Cualquiera de las dos anteriores
A: 0

Q: El esquema voraz...
O: Puede que no encuentre una solución pero si lo hace se garantiza que es óptima.
O: Garantiza encontrar una solución a cualquier problema, aunque puede que no sea óptima.
O: Las otras dos opciones son ambas falsas.
A: 2

Q: ¿Cuál es el coste temporal de crear un montículo a partir de un vector no ordenado?
O: $\Theta(n)$
O: $\Theta(n \log n)$
O: $\Omega(n \log n)$ y $O(n^2)$.
A: 0

Q: ¿Cuál es el coste temporal asintótico de la siguiente función?
```cpp
void f(int n, int arr[]) {
  int i = 0, j = 0;
  for (; i < n; ++i)
    while (j < n && arr[i] < arr[j])
      j++;
}
```
O: $O(n)$
O: $O(n \log n)$
O: $O(n^2)$
A: 0

Q: Sea G un grado no dirigido de n vértices sabemos que G con n vértices en un árbol libre si es acíclico y conexo entonces
O: G tiene exactamente n-1 arcos
O: G tiene al menos n arcos
O: G tiene al menos n-1 arcos
O: Ninguna de las anteriores
A: 0

Q: Uno de estos tres algoritmos de ordenación no opera directamente sobre el vector, y necesita almacenamiento adicional para los elementos del mismo. ¿Cuál es?
O: Mergesort
O: Quicksort
O: Heapsort
A: 0

Q: Queremos resolver por ramificacion y poda el problema de la mochila discreta.Si resolvemos el mismo problema de la forma voraz PERMITIENDO COGER OBJETOS FRACCIONADOS pero sin ordenar previamente los objetos por valor/peso, obtendremos
O: Una cota pesimista
O: Una cota optimista
O: Nada que podamos utilizar
A: 2

Q: Una de estas tres situaciones no es posible:
O: $f(n) \in \Omega(n^2)$ y $f(n) \in O(n)$
O: $f(n) \in O(n)$ y $f(n) \in O(n^2)$
O: $f(n) \in O(n)$ y $f(n) \in \Omega(1)$
A: 0

Q: $f(n) = 10n+7$ ¿ $f(n)$ pertenece a $O(n^2)$?
O: Si. Para c = 1 y a partir de un valor de n_0 =10.
O: Sí Para cualquier valor de c positivo siempre existe un n_0 a partir del que se cumple.
O: No.
A: 1

Q: Si $f1(n) \in{ Ο(g1(n))}$ y $f2(n) \in{ Ο(g2(n))}$ entonces:
O: $f1(n)·f2(n) \in{ Ο(maximo(g1(n),g2(n)))}$
O: $f1(n)·f2(n) \in{ Ο (g1(n)· g2(n))}$
O: Ambas son correctas
A: 1

Q: Con respecto al esquema Divide y vencerás, ¿es cierta la siguiente afirmación?Si la talla se reparte equitativamente entre los subproblemas, entonces la complejidad temporal resultante es una función logarítmica.
O: No, nunca, puesto que también hay que añadir el coste de la división en subproblemas y la posterior combinación.
O: No tiene porqué, la complejidad temporal no depende únicamente del tamaño resultante de los subproblemas.
O: Sí, siempre, en Divide y Vencerás la complejidad temporal depende únicamente del tamaño de los subproblemas.
A: 1

Q: ¿Cuál es la solución a la siguiente relación de recurrencia
?$f(n) = \begin{cases} \Theta(1) & n = 0 \\ \Theta(1) + f(n/3) & n > 0 \end{cases}$
O: $f(n) \in \Theta(\log(n))$.
O: $f(n) \in \Theta(n/3)$.
O: Ninguna de las otras dos es cierta.
A: 0

Q: La mejora que en general aporta la programación dinámica frente a la solución ingenua se consigue gracias al hecho de que ...
O: ... en la solución ingenua se resuelve pocas veces un número relativamente grande de subproblemas distintos.
O: ... en la solución ingenua se resuelve muchas veces un número relativamente pequeño de subproblemas distintos.
O: El número de veces que se resuelven los subproblemas no tiene nada que ver con la eficiencia de los problemas resueltos mediante programación dinámica
A: 1

Q: De los problemas siguientes, indicad cuál no se puede tratar eficientemente como los otros dos
O: El problema del viajante de comercio.
O: El problema del corte de tubos, que se obtenga el máximo beneficio posible.
O: El problema del cambio, o sea, el de entregar una cantidad de dinero usando las mínimas monedas.
A: 1

Q: De las siguientes tres afirmaciones, una es cierta y dos falsas, o bien una es falsa y dos son ciertas. Marca la que en ese sentido es diferente a las otras dos.
O: Para que un problema tenga solución mediante programación dinámica es condición necesaria que pueda resolverse mediante divide y vencerás.
O: Todo problema que tiene solución mediante divide y vencerás también la tendrá mediante programación dinámica.
O: Todo problema que tiene solución mediante ramificación y poda también la tendrá mediante programación dinámica.
A: 2

Q: Suponiendo la implementación mas eficiente para cada TAD, establecer el coste en el borrado del elemento menor en una lista ordenada, una lista desordenada un árbol binario ordenado y un montículo de mínimos respectivamente.
O: O(1),O(n),O(n),O(log n)
O: O(1),O(n),O(log n),O(1)
O: O(log n),O(n),O(n),O(1)
O: O(n),O(1),O(log n),O(log n)
A: 0

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la posición central ...
O: ... se comporta mejor cuando el vector ya está ordenado.
O: ... se comporta peor cuando el vector ya está ordenado.
O: ... no presenta casos mejor y peor distintos para instancias del mismo tamaño.
A: 0

Q: Sea un grafo dirigido con n vértices entonces
O: El grafo puede tener como máximo n^2-n arcos
O: El grafo debe tener con mínimo 1 arco ya que de lo contrario no se puede saber si es dirigido o no
O: Si tiene mas de n-1 arcos necesariamente tiene un ciclo
O: si tiene menos de n-1 arcos es imposible que tenga un ciclo
O: El grafo puede tener máximo n^2
A: 0

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
O: ...nunca tendrá un coste temporal asintótico (o complejidad temporal) exponencial.
O: ...alcanza su máxima eficiencia cuando el problema de tamaño n se divide en a problemas de tamaño n/a.
O: Las otras dos opciones son ambas verdaderas.
A: 2

Q: ¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, un solución voraz óptima?
O: El árbol de cobertura de coste mínimo de un grafo conexo
O: El problema de la mochila continua o con fraccionamiento
O: El problema de la mochila discreta o sin fraccionamiento
A: 2

Q: Cuando la descomposición recursiva de un problema da lugar a subproblemas de tamaño similar, ¿qué esquema promete ser más apropiado?
O: El método voraz.
O: Programación dinámica.
O: Divide y vencerás, siempre que se garantice que los subproblemas no son del mismo tamaño.
A: 1

Q: ¿Garantiza el uso de una estrategia "divide y vencerás" la existencia de una solución de complejidad temporal polinómica a cualquier problema?
O: Sí, en cualquier caso.
O: Sí, pero siempre que la complejidad temporal conjunta de las operaciones de descomposición del problema y la combinación de las soluciones sea polinómica.
O: No.
A: 2

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva: ¿Cuál es la mejor complejidad espacial que se puede conseguir?
```cpp
int f(int x, int y) {
  if (x <= y)
    return 1;
  return x + f(x - 1, y);
}
```
O: $O(x^2)$
O: $O(x)$
O: $O(1)$
A: 2

Q: ¿Cuál es el objetivo de la etapa de análisis en el Diseño y Análisis de un Algoritmo?:
O: Determinar el lenguaje y herramientas disponibles para su desarrollo.
O: Estimar los recursos que consumirá el algoritmo una vez implementado.
O: Estimar la potencia y características del equipo informático necesarios para el correcto funcionamiento del algoritmo.
A: 1

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva:
```cpp
unsigned f(unsigned x, unsigned v[]) {
  if (x == 0)
    return 0;
  unsigned m = 0;
  for (unsigned k = 0; k < x; k++)
    m = max(m, v[k] + f(x - k, v));
  return m;
}
```
¿Cuál es la mejor complejidad espacial que se puede conseguir?
O: $O(x)$
O: $O(1)$
O: $O(x^2)$
A: 0

Q: En el problema del viajante de comercio (travelling salesman problem) queremos listar todas las soluciones factibles
O: el orden en el que se exploran las soluciones parciales no es relevante; por ello, la tecnica ramificacion y poda no aporta nada con respecto a vuelta atras
O: lo mas adecuado seria usar una tecnica de ramificacion y poda ya que es muy importante el orden en el que se exploran las soluciones parciales
O: lo mas importante es conseguir una cota pesimista adecuada. Las diferencias entre ramificacion y poda y vuelta atras son irrelevantes en este caso
A: 0

Q: Un algoritmo cuya talla es n y que tarda $40^n$ segundos en resolver cualquier instancia tiene una complejidad temporal:
O: $\Theta{( n^n )}$
O: $\Theta{( 4^n )}$
O: Ninguna de las anteriores
A: 1

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva: ¿Cuál es la mejor complejidad espacial que se puede conseguir?
```cpp
float f(unsigned x, int y) {
  if (y < 0)
    return 0;
  float A = 0.0;
  if (v1[y] <= x)
    A = v2[y] + f(x - v1[y], y - 1);
  float B = f(x, y - 1);
  return min(A, 2 + B);
}
```
O: $O(1)$
O: $O(y^2)$
O: $O(y)$
A: 2

Q: Sea f(n) la solución de la relación de recurrencia $f(n) = 2f(n-1) + 1$; $f(1) = 1$. Indicad cuál de estas tres expresiones es cierta
O: $f(n) \in \Theta(2^n)$
O: $f(n) \in \Theta(n^2)$
O: $f(n) \in \Theta(n)$
A: 0

Q: Supongamos que obtenemos de teclado una secuencia ordenada de datos la cual vamos a almacenar en un árbol binario ordenado entonces la gran ventaja de la estructura obtenida con respecto a una lista enlazada lineal
O: Realmente no existen ventajas
O: Esta en el coste de la operación de borrado
O: Esta en el coste de la operación de inserción
O: Esta en el coste de la operación de busqueda
A: 0

Q: Para resolver un mismo problema usamos un algoritmo de RyP y lo modificamos para convertirlo en Backtracking
O: Provocamos que las cotas optimistas pierdan eficacia
O: Sería necesario comprobar si las soluciones son factible o no puesto que RyP solo genera nodos factibles
O: Cambiamos la función que damos a la cota pesimista
A: 0

Q: ¿Cuál es la complejidad temporal en función de n, del siguiente fragmento:
```cpp
for (int i = 0; i < n; i++) {
  A[i] = 0;
  for (int j = 0; j < 20; j++) {
    A[i] += B[j];
  }
}
```
O: $\Theta(n \log n)$
O: $\Theta(n^2)$
O: $\Theta(n)$
A: 2

Q: Si $f \notin O(g_1)$ y $f \in O(g_2)$ entonces siempre se cumplirá:
O: $f \in \Omega(\min(g_1, g_2))$
O: $f \in \Omega(g_1 + g_2)$
O: $f \notin \Omega(\max(g_1, g_2))$
A: 0

Q: Indica cuál es la complejidad, en función de n, del fragmento siguiente: (suponed que A está definido como `vector<int> A(n)` y `sort` es la función de ordenación de la STL)
```cpp
sort(begin(A), end(A));
int acc = 0;
for (auto i : A)
  acc += i;
```
O: $\Theta(n \log n)$
O: $\Theta(n^2)$
O: $\Theta(n)$
A: 0

Q: ¿En qué caso la complejidad temporal del algoritmo de ordenación Quicksort es igual a la complejidad temporal del algoritmo Mergesort?
O: En el caso mejor de ambos.
O: En el caso peor de ambos.
O: Tanto en el caso peor como en el caso mejor de ambos.
A: 0

Q: Tras aplicar el algoritmo MM sobre un grafo dirigido y no valuado se obtiene que la matriz C resultante tiene todo a 1's menos la diagonal principal que esta a 0's entonces con este resultado podemos asegurar
O: Que existen n componentes fuertemente conexas
O: Que el grafo no es fuertemente conexo
O: Ninguna de las anteriores
O: Que el grado es aciclico
A: 2

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Se pretende resolver mediante ramificación y poda y para ello se hace uso de una cota que consiste en asumir que de las restantes clases de objetos aún no tratadas se va a fabricar exactamente una pieza. ¿Que podemos decir de esta cota?
O: Que no es cota, ni optimista ni pesimista
O: Que es una cota optimista.
O: Que es una cota pesimista.
A: 0

Q: Si un problema de optimización lo es para una función que toma valores continuos...
O: La programación dinámica iterativa siempre es mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
O: La programación dinámica recursiva puede resultar mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
O: El uso de memoria de la programación dinámica iterativa y de la programación dinámica recursiva es el mismo independientemente de si el dominio es discreto o continuo.
A: 1

Q: ¿Qué se deduce de f(n) y g(n) si se cumple $\lim_{n \to \infty} \frac{f(n)}{g(n)} = K$, con K distinto de 0?
O: $f(n) \in O(g(n))$ y $g(n) \in O(f(n))$
O: $g(n) \in O(f(n))$ pero $f(n) \notin O(g(n))$
O: $f(n) \in O(g(n))$ pero $g(n) \notin O(f(n))$
A: 0

Q: Tenemos una lista recursiva con la siguiente cabecera: `double f(const double &)` Con solo esta informacion, cual podria ser la definicion adecuada para el almacen?
O: `int A[]`
O: `vector<double> A`
O: Ninguna de las dos otras opciones son verdaderas
A: 2

Q: 
```cpp
unsigned f(unsigned y, unsigned x) {
  // suponemos y >= x
  if (x == 0 || y == x)
    return 1;
  return f(y - 1, x - 1) + f(y - 1, x);
}
```
O: $O(x-y)$
O: $O(y)$
O: $O(x)$
A: 0

Q: El uso de funciones de cota en ramificación y poda
O: Transforma en polinómicas complejidades que antes eran exponenciales.
O: Puede reducir el número de instancias del problema que pertenecen al caso peor.
O: Garantiza que el algoritmo va a ser más eficiente ante cualquier instancia del problema.
A: 1

Q: El coste temporal asintótico del fragmento `s=0; for(i=0;i<n;i++) for(j=i;j<n;j++) s+=i*j;` y el del fragmento `s=0; for(i=0;i<n;i++) for(j=0;j<n;j++) s+=i*i*j;`son ...
O: ... iguales.
O: ... el del segundo, menor que el del primero.
O: ... el del primero, menor que el del segundo.
A: 0

Q: Sea el vector v={1,3,2,7,4,6,8} cuyos elementos están dispuestos formando un montículo de mínimos. Posteriormente añadimos en la última posición del vector un elemento nuevo con valor 5. ¿Qué operación hay que hacer para que el vector siga representando un montículo de mínimos?
O: No hay que hacer nada pues el vector v={1,3,2,7,4,6,8,5} también es un montículo de mínimos.
O: Intercambiar el 8 con el 5.
O: Intercambiar el 7 con el 5.
A: 2

Q: El problema del alfarero (solución discreta con tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$? Se pretende resolver mediante un algoritmo de ramificación y poda. Para determinar si un nodo es prometedor se estima su ganancia máxima haciendo uso de de la solución voraz discreta (sin fraccionamientos) de la parte aún sin completar. ¿Qué podemos decir del algoritmo resultante?
O: Que presumiblemente explorará menos nodos de los necesarios.
O: Que presumiblemente explorará más nodos de los necesarios.
O: Que si comienza con una solución subóptima encontrará antes la óptima.
A: 0

Q: Sea el vector v[8] = {8, 6, 4, 5, 4, 3, 2, 2}. Indica cuál de las siguientes opciones es cierta. (se asume la notación del lenguaje C/C++ en la que el primer elemento del vector está en la posición 0, es decir, en v[0]).
O: El vector v no es un montículo máximo porque el elemento v[2]=4 debe ser "hundido" (desplazado hacia la derecha).
O: El vector v no es un montículo máximo porque el elemento v[3]=5 debe ser "flotado" (desplazado hacia la izquierda).
O: El vector v es un montículo máximo.
A: 2

Q: Para que la complejidad de un algoritmo presente caso mejor y peor distintos ...
O: ... es condición necesaria y suficiente que existan instancias distintas del problema con el mismo tamaño.
O: ... es condición necesaria que existan instancias distintas del problema con el mismo tamaño.
O: ... es condición suficiente que existan instancias distintas del problema con el mismo tamaño.
A: 1

Q: Di cuál de estos tres problemas de optimización no comporta, en el peor caso, tener que considerar $O(n!)$ posibles soluciones.
O: El problema de la asignación de n tareas a n trabajadores de forma que cada trabajador hace exactamente una tarea y cada tarea es asignada a un trabajador exactamente, de forma que la suma de los costes de las tareas es mínimo.
O: El problema del viajante de comercio (travelling salesman problem, o sea, el de encontrar un ciclo hamiltoniano de coste mínimo en un grafo conexo de n vértices donde cada arista tiene un coste asignado.
O: El problema de buscar un árbol que cubre todos los vértices de un grafo de n vértices de forma que el coste es mínimo (minimum spanning tree).
A: 2

Q: Marca la FALSA
O: La ordenación de un vector usando Mergesort requiere en el caso peor un tiempo de $O(n^2)$
O: La ordenación de un vector usando el algoritmo Quicksort requiere en el peor caso un tiempo $O(n^2)$
O: La búsqueda binaria en un vector ordenado requiere en el peor caso un tiempo de $O(\log n)$
A: 0

Q: Si $f(n) \in O(n^3)$, ¿puede pasar que $f(n) \in O(n^2)$?
O: Sólo para valores bajos de n.
O: Es perfectamente posible, ya que $O(n^2) \subset O(n^3)$
O: No, porque $n^3 \notin O(n^2)$.
A: 1

Q: En el esquema de vuelta atrás el orden en el que se van asignando los distintos valores a la componentes del vector que contendrá la solución...
O: ... puede ser relevante si se utilizan mecanismos de poda basados en estimaciones optimistas.
O: ... es irrelevante si no se utilizan mecanismos de poda basados en la mejor solución hasta el momento.
O: Las otras dos opciones son correctas.
A: 2

Q: ¿Cuál de las siguientes estrategias de búsqueda es más apropiada en un esquema de vuelta atrás?
O: Ninguna de las otras dos estrategias es compatible con el esquema de vuelta atrás.
O: Explorar primero los nodos con mejor cota optimista.
O: Explorar primero los nodos con mejor valor hasta el momento en la función que se pretende optimizar.
A: 2

Q: Se pretende ordenar un vector cuyos n elementos están organizados formando un montículo (Heap). Sin tener en cuenta el tiempo empleado para este preproceso, ¿Con qué coste temporal asintótico se podría realizar la ordenación?
O: $O(n)$.
O: Ninguna de las otras dos opciones es la correcta.
O: $O(n \log n)$.
A: 2

Q: ¿Puede utilizarse relaciones de recurrencia para analizar la complejidad de un algoritmo de vuelta atrás?
O: No, ya que siempre saldría una complejidad exponencial
O: No, las relaciones de recurrencia no se pueden aplicar en este caso.
O: Sí
A: 2

Q: La búsqueda de un elemento dentro de un árbol tiene un coste de
O: Siempre constante, O(1)
O: Si es ABO es logarítmica siempre
O: Si es un AVL es logarítmica siempre
O: Siempre lineal, O(n)
O: Ninguna de las anteriores
A: 4

Q: Si un problema de optimización lo es para una función que toma valores continuos...
O: La programación dinámica recursiva siempre es mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
O: El uso de memoria de la programación dinámica iterativa y de la programación dinámica recursiva es el mismo independientemente de si el dominio es discreto o continuo.
O: La programación dinámica recursiva puede resultar mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
A: 2

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
O: ...será más eficiente cuanto más equitativa sea la división en subproblemas.
O: Las dos anteriores son ciertas.
O: ...nunca tendrá una complejidad exponencial.
A: 0

Q: Queremos aplicar la técnica de memoización a la función recursiva de la imagen. ¿Cuál sería un buen candidato para el almacén? (La función `sqrt()` obtiene la raíz cuadrada; xMax es el valor de x en la primera llamada.)
```cpp
double f(double x) {
  if (x <= 2)
    return x;
  return f(sqrt(x - 1)) + f(sqrt(x - 2));
}
```
O: Ninguna de las otras dos opciones es válida.
O: `vector<double> M(xMax+1)`
O: `vector<vector<double>> M(xMax+1, vector<double>(xMax+1))`
A: 0

Q: ¿Cual de estas estrategias voraces obtiene siempre un mejor valor para la mochila discreta?
O: Meter primero los elementos de mayor valor especifico o valor por unidad de peso.
O: Ninguna de las otras dos opciones es cierta.
O: Meter primero los elementos de mayor valor.
A: 1

Q: De los problemas siguientes, indicad cuál no se puede tratar eficientemente como los otros dos
O: El problema de cortar un tubo de forma que se obtenga el máximo beneficio posible
O: El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores
O: El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el mínimo de monedas posibles
A: 1

Q: Mediante el algoritmo de floyd podemos
O: e. Las respuestas a y c son correctas
O: d. Las respuestas a b y c son correctas
O: c. Calcular el coste mínimo de ir desde cualquier vértice i a cualquier otro
O: b. Calcular el coste mínimo de ir desde un vértice i a todos los demás
O: a. Calcular el coste mínimo de ir desde un vértice i a un vértice j
A: 1

Q: Un problema de optimización cuya solución se puede expresar mediante una secuencia de decisiones cumple el principio de optimalidad si, dada una secuencia óptima:
O: Existe una subsecuencia de esa solución que corresponde a la solución óptima de su subproblema asociado
O: Existe al menos una subsecuencia de esa solución que corresponde a la solución óptima de su subproblema asociado
O: Cualquier subsecuencia de esa solución corresponde a la solución óptima de su subproblema asociado
A: 2

Q: El problema de encontrar el árbol de recubrimiento de coste mínimo para un grafo dirigido y ponderado...
O: ... se puede resolver siempre con una estrategia voraz
O: sólo se puede resolver con una estrategia voraz si existe una arista para cualquier par de vértices del grafo
O: ... no se puede resolver en general con una estrategia voraz
A: 0

Q: Suponiendo que T1 E O(f) y que T2 E O(f) indicar cual de las siguientes afirmaciones es cierta
O: I y II son ciertas
O: II T1 - T2 E O(f)
O: III Ninguna de las anteriores
O: I T1+T2 E O(f)
A: 0

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la posición central...
O: .... se comporta mejor cuando el vector ya está ordenado
O: ... se comporta peor cuando el vector ya está ordenado
O: ... no presenta casos mejor y peor distintos para instancias del mismo tamaño
A: 0

Q: Sea la siguiente relación de recurrencia:$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 2T(n/2) + g(n) & \text{en otro caso} \end{cases}$Si $T(n) \in O(n^2)$, ¿en cuál de estos tres casos nos podemos encontrar?
O: $g(n) = 1$
O: $g(n) = n$
O: $g(n) = n^2$
A: 2

Q: El problema de encontrar el árbol de recubrimiento de coste mínimo para un grafo no dirigido, conexo y ponderado ...
O: ... se puede resolver siempre con una estrategia voraz
O: sólo se puede resolver con una estrategia voraz si existe una arista para cualquier par de vértices del grafo
O: ... no se puede resolver en general con una estrategia voraz
A: 0

Q: Suponiendo la implementación mas eficiente para cada TAD establecer el coste en el borrado del elemento menor en una lista ordenada una lista desordenada y un montículo de mínimos respectivamente
O: O(1),O(n),O(1)
O: O(log n),O(n),O(1)
O: O(1),O(n),O(log n)
O: O(n),O(1),O(log n)
A: 2

Q: ¿Cuál de las siguientes relaciones de recurrencia expresa mejor la complejidad espacial es la del algoritmo Mergesort?
O: $T(n) = n + T(n - 1)$ para $n > 1$ y $T(n) = 1$ para $n < 1$
O: $T(n) = n + T(n/2)$ para $n > 1$ y $T(n) = 1$ para $n < 1$
O: $T(n) = n + 2T(n/2)$ para $n > 1$ y $T(n) = 1$ para $n < 1$
A: 2

Q: Sea $f(n) = n \log(n) + n$.
O: $f(n) \in \Omega(n \log(n))$
O: $f(n) \in O(n \log(n))$
O: Las otras dos opciones son ciertas
A: 2

Q: Dado un problema de optimización cualquiera, ¿la estrategia de vuelta atrás garantiza la solución óptima?
O: Sí, puesto que este método analiza todas las posibilidades.
O: Sí, siempre que el dominio de las decisiones sea discreto o discretizable y además se empleen mecanismos de poda basados en la mejor solución hasta el momento.
O: Es condición necesaria que el dominio de las decisiones sea discreto o discretizable y que el número de decisiones a tomar esté acotado.
A: 2

Q: 
```cpp
unsigned f(unsigned y,
           unsigned x) { // suponemos y >= x
  if (x == 0 || y == x)
    return 1;
  return f(y - 1, x - 1) + f(y - 1, x);
}
```
O: $O(y)$
O: $O(x-y)$
O: $O(x)$
A: 1

Q: ¿Qué se entiende por tamaño del problema?
O: El número de parámetros que componen el problema.
O: La cantidad de espacio en memoria que se necesita para codificar una instancia de ese problema.
O: El valor máximo que puede tomar una instancia cualquiera de ese problema.
A: 1

Q: Dada la siguiente función:
```cpp
int exa(string &cad, int pri, int ult) {
  if (pri >= ult) {
    return 1;
  } else {
    if (cad[pri] == cad[ult]) {
      return exa(cad, pri + 1, ult - 1);
    } else {
      return 0;
    }
  }
}
```
¿Cuál es su complejidad temporal asintótica?
O: $O(n)$
O: $O(n \log n)$
O: $O(n^2)$
A: 0

Q: En cuanto a la posibilidad de aplicar la técnica de programación dinámica iterativa para resolver un problema:
O: Se debe conocer de antemano todos los posibles subproblemas y además, se debe disponer de una ordenación entre todos ellos según tamaño.
O: No necesariamente ha de conocerse de antemano todos los posibles subproblemas pero sí debe saberse, dados dos de ellos cualesquiera, cuál es más pequeño.
O: Se debe conocer de antemano todos los posibles subproblemas pero no necesariamente se debe disponer de una ordenación entre todos ellos según tamaño.
A: 0

Q: ¿Cuál de estas tres expresiones es falsa?
O: 3n^2 + 1 ∈ O(n^3)
O: n + n log(n) ∈ Ω(n)
O: n + n log(n) ∈ Θ(n)
A: 2

Q: Cuando un algoritmo recursivo que sigue el esquema divide y vencerás incurre en complejidades temporales prohibitivas porque se resuelven repetidamente los mismos subproblemas...
O: ...debemos convertirlo obligatoriamente a iterativo para evitarlo.
O: ...podemos guardar soluciones parciales en un almacén para evitar esa repetición, pero resolveremos indefectiblemente más problemas que si lo convertimos en iterativo.
O: ...podemos guardar soluciones parciales en un almacén para evitar esa repetición y puede ser que resolvamos menos problemas que si lo convertimos en iterativo.
A: 1

Q: En los algoritmos de ramificación y poda ¿el valor de una cota pesimista es mayor que el valor de una cota optimista? (entendiendo que ambas cotas se aplican sobre el mismo nodo)
O: No, nunca es así.
O: En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
O: En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
A: 2

Q: El problema de la moneda consiste a formar una suma M con el número mínimo de monedas tomadas (con repetición) de un conjunto C donde hay una cantidad suficientemente grande de monedas con cada posible valor facial $C' = \{c_1, c_2, \ldots, c_{|C|}\}$, con $c_1 = 1$. ¿Cuál de estas afirmaciones sobre un algoritmo recursivo de la forma$$n_{opt}(M) = 1 + \min_{1 \leq i \leq |C|} n_{opt}(M - c_i);$$$$n_{opt}(0) = 0;$$
$$n_{opt}(x) = \infty \text{ para } x < 0$$
es falsa?
O: Dependiendo de cuáles sean los valores faciales y la suma, puede ser que el algoritmo recursivo no encuentre solución.
O: Tiene un coste temporal prohibitivo, ya que puede calcular $n_{opt}(x)$ para el mismo valor de x más de una vez.
O: Encuentra siempre la solución óptima.
A: 0

Q: En cual de los siguientes casos no se puede aplicar el esquema Divide y Vencerás:
O: Cuando los subproblemas son de tamaños muy diferentes
O: Cuando el problema no cumple el principio de optimalidad
O: Se puede aplicar en ambos casos
A: 2

Q: Se pretende aplicar la técnica memoización a la siguiente función recursiva:
```cpp
int f(int x, int y) {
  if (x > y)
    return 1;
  return x + f(x, y - 2);
}
```
En el caso más desfavorable, ¿qué complejidades temporal y espacial cabe esperar de la función resultante?
O: $O(x-y)$, tanto temporal como espacial.
O: Ninguna de las otras dos opciones es correcta
O: Temporal $O(x-y)$ y espacial $O(1)$
A: 0

Q: ¿Cómo se vería afectada la solución voraz al problema de la asignación de tareas en el caso de que se incorporaran restricciones que contemplen que ciertas tareas no pueden ser adjudicadas a ciertos trabajadores ?
O: La solución factible ya no estaría garantizada, es decir, pudiera ser que el algoritmo no llegue a solución alguna.
O: Ya no se garantizaría la solución óptima pero sí una factible.
O: Habría que replantearse el criterio de selección para comenzar por aquellos trabajadores con más restricciones en cuanto a las tareas que no pueden realizar para asegurar, al menos, una solución factible.
A: 0

Q: Si $f \in \Theta(g_1)$ y $f \in \Theta(g_2)$ entonces
O: $f \in \Theta(g_1 \cdot g_2)$
O: $f \notin \Theta(\max(g_1,g_2))$
O: $f \in \Theta(g_1+g_2)$
A: 0

Q: Los algoritmos de ordenación Quicksort y Mergesort tienen en común ...
O: ... que se ejecutan en tiempo O(n).
O: ... que ordenan el vector sin usar espacio adicional.
O: ... que aplican la estrategia de divide y vencerás.
A: 2

Q: Un algoritmo que calcula una funcion recursivamente tiene coste prohibitivo y se decide mejorarlo transformandolo en un algoritmo de programacion dinamica iterativa, pero se le añade memoizacion. ¿podria ser que el algoritmo iterativo evalue la funcion mas veces que el recursivo con memoizacion?
O: Podria ser, por ejemplo, como ocurre en el caso de la mochila discreta con pesos enteros.
O: No, ambos evaluan la funcion el mismo numero de veces.
O: No, el recursivo evalua la funcion muchas mas veces.
A: 0

Q: En el método voraz ...
O: ... es habitual preparar los datos para disminuir el coste temporal de la función que determina cuál es la siguiente decisión a tomar.
O: ... para garantizar la solución óptima, las decisiones solo pueden pertenecer a dominios discretos o discretizables.
O: ... para garantizar la solución óptima, las decisiones solo pueden pertenecer a dominios continuos.
A: 0

Q: Dados dos nodos cualesquiera del árbol de búsqueda de ramificación y poda, en general, ¿se puede saber con certeza cuál está más cerca de la solución óptima del problema a resolver?
O: Sí, pero solo si ambos nodos son hoja.
O: Sí, el que tiene mejor cota pesimista.
O: Sí, el que tiene mejor cota optimista.
A: 0

Q: Ordena de menor a mayor las siguientes complejidades 	1. O(1) 	2. O(n^2) 
	3. O(nlgn) 
	4. O(n!)
O: 3, 1, 2 y 4
O: 1, 3, 2 y 4
O: 1, 3, 4 y 2
A: 1

Q: Se pretende resolver el problema del viajante de comercio (travelling salesman problem) mediante el esquema de vuelta atrás, ¿cuál de los siguientes valores se espera que se comporte mejor para decidir si un nodo es prometedor?
O: La suma de los pesos de las k aristas restantes más cortas, donde k es el número de ciudades que quedan por visitar.
O: El valor que se obtiene de multiplicar k por el peso de la arista más corta de entre las restantes, donde k es el número de ciudades que quedan por visitar.
O: El coste del mínimo árbol de recubrimiento de las ciudades restantes.
A: 2

Q: ¿Qué mecanismo se usa para acelerar el algoritmo de Prim?
O: Mantener una lista de los arcos ordenados según su peso.
O: El TAD "Union-find"
O: Mantener para cada vértice el vértice origen de la arista más corta hasta él.
A: 2

Q: Sea A un árbol binario ordenado equilibrado de n elementos, en el que todos sus elementos son distintos, entonces la función búsqueda de un elemento que no esta en el árbol tendrá coste
O: O(log n)
O: Ω(log n) y O(n)
O: Θ(n)
O: Θ(log n)
A: 3

Q: Marca la falsa
O: $n + n \log(n) \in \Theta(n)$
O: $3n^2 + 1 \in O(n^3)$
O: $n + n \log(n) \in \Omega(n)$
A: 0

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es mayor que el valor de una cota optimista? (se entiende que ambas cotas se aplican sobre el mismo nodo)
O: En general, sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
O: En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
O: No, nunca es así.
A: 1

Q: La eficiencia de los algoritmos voraces se basa en
O: El hecho de que, con antelación, las posibles decisiones se ordenan de mejor a peor
O: En el esquema voraz no se puede hablar de eficiencia
O: El hecho de que las decisiones tomadas no se reconsideran
A: 2

Q: Tenemos un vector desordenado y queremos obtener los tres elementos más pequeños. ¿Cuál sería la complejidad temporal más ajustada para hacerlo? (sin pérdida de generalidad puedes suponer que en el vector todos los elementos son distintos)
O: El logaritmo de la longitud del vector
O: Lineal con la longitud del vector
O: Cuadrática con la longitud del vector
A: 1

Q: Una empresa de mensajería tiene n repartidorefs con distintos tiempos de entrega según el tipo de envío. Se trata de asignar los próximos n envíos, uno a cada repartidor, minimizando el tiempo total de todos los envíos. Para ello se conoce de antemano una tabla de tiempos en la que el valor $t_{ij}$ corresponde al tiempo que emplea el repartidor i en realizar el envío j. De entre las estrategias que se citan, ¿cuál sería la eficiente para resolver el problema?
O: Algoritmo voraz.
O: Vuelta atrás.
O: Ramificación y poda.
A: 1

Q: $f(n) = 5n+3m·n +11$ entonces $f(n)$ pertenece a:
O: $O (n·m)$.
O: $O (n^m)$.
O: Las dos son correctas
A: 2

Q: ¿Cuál de estas estrategias para calcular el $n$-ésimo elemento de la serie de Fibonacci$f(n) = f(n - 1) + f(n - 2),\ f(1) = f(2) = 1$es más eficiente?
O: Programación dinámica
O: La estrategia voraz
O: Las dos estrategias citadas serían similares en cuanto a la eficiencia
A: 0

Q: El arbol de expansion de minimo coste de un grafo
O: ...puede utilizarse como cota pesimista para resolver el problema del viajante de comercio
O: ...puede utilizarse como cota optimista para resolver el problema del viajante de comercio
O: Ninguna de las otras dos opciones es verdadera
A: 1

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva:
```cpp
int f(int x, int y) {
  if (x <= y)
    return 1;
  return x + f(x - 1, y);
}
```
¿Cuál es la mejor complejidad espacial que se puede conseguir?
O: $O(x)$
O: $O(1)$
O: $O(x^2)$
A: 1

Q: La serie de números de Fibonacci se define de la siguiente forma:$$fib(n) = \begin{cases} 1 & n \leq 1 \\ fib(n-1) + fib(n-2) & n > 1 \end{cases}$$Para implementar esta función podemos emplear:
O: Divide y vencerás
O: Programación dinámica
O: Cualquiera de las dos anteriores
A: 2

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia?
```cpp
f(n) = n(n - 1) + f(n - 1) si n > 0 f(0) = 1 si n = 0
```
O: $f(n) \in \Theta(n^2)$
O: $f(n) \in \Theta(n^3)$
O: Ninguna de las otras dos opciones es cierta.
A: 1

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es mayor que el valor de una cota optimista? (se entiende que ambas cotas se aplican sobre el mismo nodo)
O: No, nunca es así.
O: En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
O: En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
A: 2

Q: El sumatorio, desde $i=1$ hasta n, de $i^k$ pertenece a:
O: $Ο(n^{k+1})$
O: $Ο(n^k)$
O: Ninguna de las anteriores
A: 0

Q: Cuando para distintas instancias de problema con el mismo tamaño no obtenemos el mismo resultado:
O: No es posible calcular la complejidad a priori y debemos ejecutar el programa varias veces con la misma talla y obtener el tiempo medio para hallar la complejidad media.
O: No se puede aplicar la técnica de paso de programa, ya que esta técnica es para calcular la complejidad a priori.
O: Calculamos el máximo y mínimo coste que nos puede dar el algoritmo.
A: 2

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es menor que el valor de una cota optimista? (se entiende que ambas cotas se aplican sobre el mismo nodo)
O: Sí, siempre es así.
O: En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
O: En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir
A: 2

Q: ¿Cuál de estas estrategias para calcular el n-ésimo elemento de la serie de Fibonacci ($f(n) = f(n-1) + f(n-2)$, $f(1) = f(2) = 1$) es más eficiente?
O: La estrategia voraz.
O: Programación dinámica.
O: Para este problema, las dos estrategias citadas serían similares en cuanto a eficiencia.
A: 1

Q: El caso base de una ecuación de recurrencia asociada a la complejidad temporal de un algoritmo expresa:
O: El coste de dicho algoritmo en el mejor de los casos.
O: El coste de dicho algoritmo en el peor de los casos.
O: Ninguna de las anteriores.
A: 2

Q: Supongamos el problema de la mochila resuelto mediante Programación Dinámica y particularizado para n elementos y un peso máximo trasportable de P. ¿Es necesario calcular valores para toda la matriz auxiliar para obtener el resultado?
O: Si
O: No
O: Depende de los valores de n y P.
A: 1

Q: De las siguientes expresiones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
O: $\sum_{i=1}^{n/2} \sum_{j=1}^{i} 2^j \in O(n \log n)$
O: $\sum_{i=1}^{n} \sum_{j=1}^{\log i} 2^j \in O(n^2)$
O: $\sum_{i=1}^{\log n} \sum_{j=1}^{n} 2^j \in O(n \log n)$
A: 1

Q: Sea un problema de optimización por selección discreta, con restricciones, en el que se deben tomar n decisiones booleanas para optimizar un indicador, y se abordará mediante un método de búsqueda y enumeración (vuelta atrás, ramificación y poda). ¿Cuál de las siguientes afirmaciones es correcta?
O: La complejidad temporal será como mucho $O(n \log n)$ porque en general basta con ordenar adecuadamente las decisiones para convertir cualquier problema de este tipo en un problema de complejidad temporal lineal.
O: Puede haber problemas para los que la complejidad será exponencial o peor; ninguna estrategia de poda puede garantizar que esto no va a ocurrir.
O: La complejidad temporal en el peor caso será $O(n^2)$ ya que se toman n decisiones binarias.
A: 1

Q: Dadas las siguientes ecuaciones de recurrencia. Determinar el orden al que pertenece cada una de ellas: $T_1(n)=2T_1(n-1)+c_1$; $T_2(n)=T_2(n-1)+c_2$, $T_3(n)=T_3(n/2)+c_3$ y $T_4(n)=T_4(n+1)+n+c_4$
O: $T_1(n) \in O(2^n)$, $T_2(n) \in O(n)$, $T_3(n) \in O(\log n)$, $T_4(n) \in O(n^2)$
O: $T_1(n) \in O(n)$, $T_2(n) \in O(n)$, $T_3(n) \in O(\log n)$, $T_4(n) \in O(n^2)$
O: $T_1(n) \in O(\log n)$, $T_2(n) \in O(n)$, $T_3(n) \in O(\log n)$, $T_4(n) \in O(n^2)$
O: $T_1(n) \in O(2^n)$, $T_2(n) \in O(n)$, $T_3(n) \in O(\log n)$, $T_4(n) \in O(2n)$
A: 0

Q: La solución recursiva ingenua (pero correcta) a un problema de optimización llama más de una vez a la función con los mismos parámetros. Una de las siguientes afirmaciones es falsa
O: Se puede mejorar la eficiencia del algoritmo definiendo de antemano el orden en el que se deben calcular las soluciones a los subproblemas y llenando una tabla en ese orden.
O: Se puede mejorar la eficiencia del algoritmo guardando en una tabla el valor devuelto para cada conjunto de parámetros de cada llamada cuando esta se produce por primera vez.
O: Se puede mejorar la eficiencia del algoritmo convirtiendo el algoritmo recursivo directamente en iterativo sin cambiar su funcionamiento básico.
A: 2

Q: En un algoritmo de búsqueda exhaustiva, ¿Qué ocurre si la cota pesimista de un nodo se corresponde con una solución que no es factible?
O: Que el algoritmo sería más lento pues se explorarían más nodos de los necesarios.
O: Nada especial, las cotas pesimistas no tienen por qué corresponderse con soluciones factibles.
O: Que podría descartarse un nodo que conduce a la solución óptima.
A: 2

Q: Tenemos un "superprocesador" que tiene una instrucción que permite la ordenación de 100 elementos en un tiempo constante. Para este superprocesador, adaptamos el algoritmo Mergesort de forma que cada vez que queremos ordenar menos de 100 elementos, en lugar de hacer las llamadas recursivas, llama a esta instrucción. ¿cuál sería la complejidad de este algoritmo?
O: $O(n \log n)$
O: $O(n)$
O: $O(1)$
A: 0

Q: ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
int f(int n) {
  int k = 0;
  for (int i = 1; i < n; i *= 2)
    for (int j = i; j > 0; j -= 2)
      k++;
  return k;
}
```
O: $\Theta(n^2)$
O: $\Theta(n \log n)$
O: $\Theta(n)$
A: 1

Q: ¿Qué estrategia de búsqueda es a priori más apropiada en un esquema de vuelta atrás?
O: Explorar primero los nodos con mejor cota optimista.
O: En el esquema de vuelta atrás no se pueden definir estrategias de búsqueda.
O: Explorar primero los nodos que están más completados.
A: 1

Q: En los algoritmos de Ramificación y poda ...
O: una cota pesimista es necesariamente un valor insuperable, de no ser así se podría podar el nodo que conduce a la solución óptima.
O: una cota pesimista es necesariamente un valor alcanzable, de no ser así no está garantizado que se encuentre la solución óptima.
O: una cota optimista es el valor que a lo sumo alcanza cualquier nodo factible que no es el óptimo.
A: 1

Q: Con respecto al tamaño del problema, ¿Cuál es el orden de complejidad temporal asintótica de la siguiente función? (asumimos que A es una matriz cuadrada)
```cpp
void traspuesta(vector<vector<int>> A) {
  for (int i = 1; i < A.size(); i++)
    for (int j = 0; j < i; j++)
      swap(A[i][j], A[j][i]);
}
```
O: constante
O: cuadrático
O: lineal
A: 2

Q: ¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, una solución voraz óptima?
O: El árbol de cobertura de coste mínimo de un grafo conexo.
O: El problema de la mochila discreta o sin fraccionamiento.
O: El problema de la mochila continua o con fraccionamiento.
A: 1

Q: La eficiencia de los algoritmos voraces se basa en el hecho de que ...
O: ... antes de tomar una decisiön se comprueba si satisface las retricciones del problema.
O: ... las decisiones tomadas nunca se reconsideran.
O: ... con antelaciön, Ias posibles decisiones se ordenan de mejor a peor.
A: 1

Q: Indicad cuál de estas tres expresiones es cierta:
O: $O(n^2) \subseteq O(2^{\log(n)}) \subset O(2^n)$
O: $O(n^2) \subseteq O(2^{\log(n)}) \subseteq O(2^n)$
O: $O(2^{\log(n)}) \subseteq O(n^2) \subseteq O(2^n)$
A: 2

Q: Dado el siguiente código, calcule la complejidad del mismo:
```cpp
int sumaDigitos(int num) {
  int s;
  s = num % 10;
  while (num >= 10) {
    num = num / 10 s = s + (num % 10);
  }
  return (s);
}
```
O: $\Omega(1)$ y $O(\log n)$
O: $O(n)$
O: $O(10n)$
O: $O(1)$
O: $O(\log n)$
A: 1

Q: $f(n) = n^2 + 3f(n/3)$
O: $O(n^2 \log n)$
O: $O(n^2)$
O: $O(n)$
A: 1

Q: El problema del cambio: Se dispone de un conjunto finito de números naturales y se pretende obtener el subconjunto de menor tamaño cuyos elementos suman una cierta cantidad C. ¿Qué estrategia es la más apropiada para resolverlo?
O: Un algoritmo voraz.
O: Ramificación y poda.
O: Programación dinámica.
A: 2

Q: ¿Cuál de estas tres expresiones es cierta?
O: $O(n^2) \subset O(2^{\log n}) \subset O(2^n)$
O: $O(2^{\log n}) \subset O(n^2) \subset O(2^n)$
O: $O(n^2) \subset O(2^{\log n}) \subset O(2^n)$
A: 1

Q: ¿Cuál es la complejidad temporal en función de n, del siguiente fragmento:
```cpp
for (int i = 0; i < n; i++) {
  A[i] = 0;
  for (int j = 0; j < 20; j++)
    A[i] += B[j];
}
```
O: $\Theta(n \log n)$
O: $\Theta(n)$
O: $\Theta(n^2)$
A: 1

Q: Dada la siguiente relación de recurrencia, ¿Qué cota es verdadera?
$f(n) = \begin{cases} 1 & n = 1 \\ n + 2f(n-1) & n \geq 1 \end{cases}$
O: $f(n) \in \Omega(2^n)$
O: $f(n) \in \Theta(n^2)$
O: $f(n) \in \Theta(2^n)$
A: 0

Q: Al resolver el problema del viajante de comercio mediante backtracking, ¿cuál de estas cotas optimistas se espera que pode mejor el árbol de búsqueda?
O: Se multiplica k por la distancia de la arista más corta que nos queda por considerar donde k es el número de saltos que nos quedan por dar.
O: Se ordenan las aristas restantes de menor a mayor distancia y se calcula la suma de las k aristas más cortas, donde k es el número de saltos que nos quedan por dar.
O: Se resuelve el resto del problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido.
A: 1

Q: $f(n) = 2f(n/2) + n$, $f(1) = 1$
O: $f(n) \in O(n \log(n))$
O: $f(n) \in O(n^2)$
O: $f(n) \in O(n)$
A: 0

Q: Se desea resolver el problema de la potencia enésima ($x^n$), asumiendo que n es par y que se utilizará la siguiente recurrencia: pot(x,n) = pot(x,n/2) * pot(x,n/2); ¿Qué estrategia resulta ser más eficiente en cuanto al coste temporal?
O: En este caso tanto programación dinámica como divide y vencerás resultan ser equivalentes en cuanto a la complejidad temporal.
O: Un algoritmo recursivo con memoización.
O: Divide y vencerás.
A: 0

Q: Decid cuál de estas tres es la cota pesimista más ajustada al valor óptimo de la mochila discreta:
O: El valor de una mochila que contiene todos los objetos aunque se pase del peso máximo permitido.
O: El valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor específico de los objetos.
O: El valor de la mochila continua correspondiente.
A: 1

Q: En el problema del viajante de comercio (travelling salesman problem) queremos listar todas las soluciones factibles
O: Lo más importante es conseguir una cota pesimista adecuada. Las diferencias entre ramificación y poda y vuelta atrás son irrelevantes en este caso.
O: El orden en el que se exploran las soluciones parciales no es relevante; por ello, la técnica ramificación y poda no aporta nada con respecto a vuelta atrás.
O: Lo más adecuado sería usar una técnica de ramificación y poda ya que es muy importante el orden en el que se exploran las soluciones parciales.
A: 1

Q: Sea la siguiente relación de recurrencia: $T(n) = 1$ si $n \leq 1$; $2T(n/2) + g(n)$ en otro caso. Si $T(n) \in O(n)$, ¿en cuál de estos tres casos nos podemos encontrar?
O: $g(n) = \log n$
O: $g(n) = n^2$
O: Las otras dos opciones son ambas ciertas.
A: 2

Q: En programación dinámica, dónde almacenamos los valores de los problemas resueltos?
O: En un vector unidimensional
O: En un vector bidimensional
O: Depende del problema
A: 2

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
O: $\Omega(n) \subset \Omega(1)$
O: $\Theta(\log(n^2)) = \Theta(\log(n^3))$
O: $O(n) \subset O(1)$
A: 2

Q: Si $\lim_{n \to \infty} \frac{f(n)}{g(n)} = \infty$ entonces...
O: $f(n) \in O(g(n))$
O: $f(n) \in \Omega(g(n))$
O: $f(n) \in \Theta(g(n))$
A: 1

Q: Un fontanero tiene una jornada de Q cuartos de hora (es así como se organiza la agenda) y tiene C clientes. El trabajo del cliente i tarda $q_i$ cuartos de hora y el fontanero le cobra un precio $p_i$. Es posible que no pueda atender todos los clientes en la jornada, que nunca puede alargar. Este problema tiene una solución bien conocida que permite elegir qué clientes visitar para que la suma cobrada al final de la jornada sea la máxima. ¿Qué podemos decir de esta solución?
O: Que la organización de la agenda en cuartos de hora permite obtener una solución de complejidad temporal $\Theta(QC)$ y complejidad espacial $\Theta(Q)$.
O: Que se ha de implementar forzosamente con un algoritmo de búsqueda y enumeración como el de vuelta atrás.
O: Que no se puede implementar con una solución de "divide y vencerás" con memoización.
A: 0

Q: ¿Puede ocurrir que la solución recursiva de estilo "divide y vencerás" pero con memoización de un problema resuelva menos subproblemas que la mejor solución iterativa posible de programación dinámica?
O: Sí, porque no existe garantía de que la mejor solución iterativa posible no resuelva problemas repetidos, mientras que la técnica de memoización lo garantiza directamente mediante el uso de un almacén.
O: Sí, porque la mejor solución iterativa posible de programación dinámica puede resolver subproblemas que no sean necesarios al resolver subproblemas posteriores.
O: No, nunca.
A: 1

Q: El elemento n-ésimo de la serie tribonacci, $T(n)$, se define como sigue: $T(n) = T(n - 3) + T(n - 2) + T(n - 1)$ para $n > 3$; $T(0) = 0$; $T(1) = 1$ y $T(2) = 1$. ¿Cuál de estas afirmaciones es falsa?
O: Una implementación ingenua de la función $T(n)$, la cual llamaría a $T(n - 1)$, $T(n - 2)$ y $T(n - 3)$ tendría una complejidad prohibitiva por la repetición de cálculos que se produciría.
O: Es posible una implementación de programación dinámica iterativa con complejidad $\Theta(n)$.
O: El problema no tiene una solución de programación dinámica iterativa pero se puede resolver añadiendo memoización al cálculo recursivo ingenuo en el que el cálculo de $T(n)$ comporta realizar las llamadas a $T(n - 1)$, $T(n - 2)$ y $T(n - 3)$.
A: 2

Q: Una de las afirmaciones siguientes es cierta y las otras dos falsas. Indicad cuál es la cierta.
O: $O(2^n) \in O(n!)$
O: $O(3^n) \in O(2^n)$
O: $O(n^n) \in O(n!)$
A: 0

Q: Para que un problema de optimización se pueda resolver mediante PD es necesario que:
O: Cumpla el principio de optimalidad
O: Cumpla el teorema de reducción
O: Cumpla los dos anteriores
A: 0

Q: ¿En qué caso la complejidad temporal del algoritmo de ordenación Quicksort es igual a la complejidad temporal del algoritmo Mergesort?
O: En el caso mejor de ambos.
O: En el caso peor de ambos.
O: Tanto en el caso peor como en el caso mejor de ambos
A: 0

Q: En la solucion al problema de la mochila continua ¿por que es conveniente la ordenacion previa de los objetos?
O: Porque si no se hace no es posible garantizar que la toma de decisiones siga un criterio voraz.
O: Para reducir la complejidad temporal en la toma de cada decision de $O(n)$ a $O(1)$, donde n es el numero de objetos a considerar.
O: Para reducir la complejidad temporal en la toma de cada decision: de $O(n^2)$ a $O(n \log n)$, donde n es el numero de objetos a considerar.
A: 1

Q: Sea la siguiente relación de recurrencia: $T(n) = 1$ si $n \leq 1$; $2T(n/2) + g(n)$ en otro caso. Si $T(n) \in O(n^2)$, ¿en cuál de los casos nos podemos encontrar?
O: $g(n) = 1$
O: $g(n) = n^2$
O: $g(n) = n$
A: 1

Q: Si aplicamos Programación Dinámica a un problema que también tiene solución por divide y vencerás podemos asegurar que...
O: El coste temporal se reduce y el espacial aumenta con respecto a la solución por DyV
O: El coste temporal aumenta y el espacial se reduce con respecto a la solución por DyV
O: Ninguna de las anteriores.
A: 2

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
O: ...nunca tendrá un coste temporal asintótico (o complejidad temporal) exponencial.
O: Las otras dos opciones son ambas verdaderas.
O: ...alcanza su máxima eficiencia cuando el problema de tamaño n se divide en "a" problemas de tamaño n/a.
A: 2

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos
O: $O(2^{\log n}) \subset O(n^2)$
O: $n + n \log n \in \Omega(n)$
O: $\Theta(n) \subset \Theta(n^2)$
A: 2

Q: Se pretende resolver el problema del viajante de comercio (travelling salesman problem) mediante Ramificación y poda. ¿Cuál de las siguientes acciones resulta ser mejor cota optimista para aplicarla a los nodos intermedios?
O: Obtener el árbol de recubrimiento de mínimo coste a los vértices aún no visitados.
O: Completar el recorrido pendiente mediante un algoritmo voraz.
O: Asumir que ya no quedan más vértices por visitar y cerrar el camino desde el último vértice visitado.
A: 0

Q: La solución recursiva ingenua (pero correcta) a un problema de optimización llama más de una vez a la función con los mismos parámetros. Una de las siguientes afirmaciones es falsa.
O: Se puede mejorar la eficiencia del algoritmo guardando en una tabla el valor devuelto para cada conjunto de parámetros de cada llamada cuando ésta se produce por primera vez.
O: Se puede mejorar la eficacia del algoritmo definiendo de antemano el orden en el que se deben calcular las soluciones a los subproblemas y llenando una tabla en ese orden.
O: Se puede mejorar la eficiencia del algoritmo convirtiendo el algoritmo recursivo directamente en iterativo sin cambiar su funcionamiento básico.
A: 2

Q: Que problema se da, y como se puede resolver, cuando se calcula el coeficiente binomial
O: La recursión puede ser infinita y por tanto es necesario organizarla según el esquema iterativo del programa
O: Se repiten muchos cálculos y ello se puede evitar haciendo uso de una estrategia voraz
O: Se repiten muchos cálculos y ello se puede evitar usando programación dinámica
A: 2

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva:
```cpp
unsigned f(unsigned y, unsigned x) {
  // suponemos y >= x
  if (x == 0 || y == x)
    return 1;
  return f(y - 1, x - 1) + f(y - 1, x);
}
```
¿Cuál es la mejor complejidad espacial que se puede conseguir?
O: $O(y^2)$
O: $O(1)$
O: $O(y)$
A: 2

Q: Uno de estos tres problemas no tiene solución eficiente que siga el esquema de programación dinámica:
O: El problema de la mochila discreta.
O: El problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud.
O: El problema de las torres de Hanoi.
A: 2

Q: Un algoritmo recursivo basado en divide y vencerás
O: Nunca tendrá una complejidad exponencial.
O: Será más eficiente cuanto más equitativa sea la división en subproblemas.
O: Las dos anteriores son correctas.
A: 1

Q: De los problemas siguientes, indicad cuál no se puede tratar eficientemente como los otros dos:
O: El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores
O: El problema de cortar un tubo de forma que se obtenga el máximo beneficio posible
O: El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el mínimo de monedas posibles
A: 0

Q: La mejora que en general aporta programación dinámica frente a la solución ingenua se consigue gracias al hecho de que...
O: ... en la solución ingenua se resuelve muchas veces un número relativamente pequeño de subproblemas distintos.
O: ... en la solución ingenua se resuelve pocas veces un número relativamente grande de subproblemas distintos.
O: El número de veces que se resuelven los subproblemas no tiene nada que ver con la eficiencia de los problemas resueltos mediante programación dinámica.
A: 0

Q: La complejidad en el mejor de los casos de un algoritmo de ramificación y poda
O: Puede ser polinómica con el número de decisiones a tomar.
O: Suele ser polinómica con el número de alternativas por cada decisión.
O: Es siempre exponencial con el número de decisiones a tomar.
A: 0

Q: Sea la siguiente relación de recurrencia:$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 8T(n/8) + g(n) & \text{en otro caso} \end{cases}$Si $T(n) \in \Theta(n^2)$, ¿en cuál de estos tres casos nos podemos encontrar?
O: $g(n) = n^2$
O: $g(n) = n$
O: $g(n) = n^3$
A: 2

Q: Queremos aplicar la técnica de memoización a la siguiente función recursiva: 
```cpp
double f(double x) {
  if (x <= 2)
    return x;
  return f(sqrt(x - 1)) + f(sqrt(x - 2));
}
```
¿Cuál sería un buen candidato para el almacén? (La función `sqrt()` obtiene la raíz cuadrada; xMax es el valor de x en la primera llamada.)
O: `vector<double> M(xMax+1)`
O: Ninguna de las otras dos opciones es válida
O: `vector<vector<double>> M(xMax+1, vector<double>(xMax+1))`
A: 1

Q: Cuando se usa un algoritmo voraz para abordar la resolución de un problema de optimización por selección discreta (es decir, un problema para el cual la solución consiste en encontrar un subconjunto del conjunto de elementos que optimiza una determinada función), ¿cuál de estas tres cosas es imposible que ocurra?
O: Que el algoritmo no encuentre ninguna solución.
O: Que la solución no sea óptima.
O: Que se reconsidere la decisión ya tomada anteriormente respecto a la selección de un elemento a la vista de la de la decisión que se debe tomar en el instante actual.
A: 2

Q: ¿Qué diferencia (entre otras) hay entre el algoritmo de Prim y el de Kruskal?
O: El subgrafo que paso a paso va generando el algoritmo de Prim siempre contiene una única componente conexa mientras que el de Kruskal no tiene por qué.
O: Aún siendo el grafo de partida totalmente conexo, el algoritmo de Kruskal garantiza la solución óptima mientras que el de Prim sólo garantiza un subóptimo.
O: El algoritmo de Prim es voraz y el de Kruskal no.
A: 0

Q: La solución ingenua a un problema de optimización, por un lado se basa en obtener soluciones óptimas a problemas parciales mas pequeños, y por otro, estos subproblemas se resuelven más de una vez. Este problema tiene una solución alternativa basada en...
O: Programación dinámica
O: Divide y vencerás
O: Voraz
A: 0

Q: ¿Pertenece $3n^2 + 3$ a $O(n^3)$?
O: Solo para $c=1$ y $n_0 = 5$.
O: No.
O: Sí.
A: 2

Q: Si $f(n) \in O(g(n))$ ¿cuál de estas situaciones no es posible?
O: $f(n) \in \Omega(g(n))$
O: $\lim_{n \to \infty} g(n) / f(n) = 0$
O: $g(n) \in O(f(n))$
A: 1

Q: Sea A un vector de n elementos y supongamos que todos los elementos de A son distintos. Considera el siguiente algoritmo:Nos interesa medir cuantas veces se ejecuta la instrucción nº 3 Entonces el caso mejor se obtiene cuando: ```módulo ordena ( var A es vector de n enteros);
variables i, j, x: es entero
for (i = 2; i<=N; i++) {
	X=A[i];
	A[0]=X;
	j=i-1;
	while ( X<A[j] ) { // (2)
		A[j+1]=A[j]; // (3)
		j = j - 1
	}
	A[j+1]=X;
}
finmódulo
```
O: Los datos vienen ordenados ascendentemente, que se ejecuta exactamente 0 veces
O: Los datos vienen ordenados ascendentemente, que se ejecuta exactamente n^2 veces
O: Los datos vienen dispuestos en orden inverso, que se ejecuta exactamente n^2 veces
O: Los datos vienen dispuestos en orden inverso, que se ejecuta exactamente n-i veces
A: 0

Q: La solución recursiva ingenua (pero correcta) a un problema de optimización llama más de una vez a la función con los mismos parámetros. Una de las siguientes tres afirmaciones es falsa.
O: Se puede mejorar la eficiencia del algoritmo guardando en una tabla el valor devuelto para cada conjunto de parámetros de cada llamada cuando esta se produce por primera vez.
O: Se puede mejorar la eficiencia del algoritmo definiendo de antemano el orden en el que se deben calcular las soluciones a los subproblemas y llenando una tabla en ese orden.
O: Se puede mejorar la eficiencia del algoritmo convirtiendo el algoritmo recursivo directamente en iterativo sin cambiar su funcionamiento básico.
A: 2

Q: El problema de la función compuesta mínima consiste en encontrar a partir de un conjunto de funciones dadas, la secuencia mínima de composiciones de estas que permita transformar un número n en otro m. Se quiere resolver mediante ramificación y poda. ¿Cuál sería la forma más adecuada de representar las posibles soluciones?
O: Mediante un vector de booleanos.
O: Mediante un vector de reales.
O: Este problema no se puede resolver usando ramificación y poda si no se fija una cota superior al número total de aplicaciones de funciones.
A: 0

Q: Dado un problema de optimización, el método voraz...
O: ...garantiza la solución óptima solo para determinados problemas.
O: ...siempre obtiene la solución óptima.
O: ...siempre obtiene una solución factible.
A: 0

Q: Solo una de estas tres relaciones de recurrencia es tal que $T(n) \in \Theta(n)$. ¿Cuál?
O: $T(n) = 1 + 2T(n/2)$ si $n > 1$; $T(1) = 1$
O: $T(n) = 1 + T(n/2)$ si $n > 1$; $T(1) = 1$
O: $T(n) = n + T(n - 1)$ si $n > 1$; $T(1) = 1$
A: 0

Q: Suponiendo la implementación mas eficiente para cada TAD establecer el coste de borrado de los elementos menor en una lista desordenada un árbol binario ordenado y un montículo de mínimos respectivamente
O: O(1),O(n),O(log n),O(1)
O: O(log n),O(n),O(n),O(1)
O: O(n),O(1),O(log n),O(log n)
O: O(1),O(n),O(n),O(log n)
A: 0

Q: Un problema de tamaño n puede transformarse en tiempo $O(n^2)$ en otro de tamaño n-1, por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante, ¿cuál de estas clases de coste temporal asintótico es la más ajustada?
O: $O(n^3)$
O: $O(n^2)$
O: $O(2^n)$
A: 0

Q: Si n es el número de elementos de un vector. La solución de menor coste al problema de encontrar su k-ésimo mínimo tiene la siguiente complejidad:
O: $\Omega(n)$ y $O(n \log n)$
O: $\Omega(n)$ y $O(n^2)$
O: Ninguna de las dos
A: 1

Q: En un problema de optimización, si el dominio de las decisiones es un conjunto infinito,
O: Es probable que a través de programación dinámica se obtenga un algoritmo eficaz que lo solucione.
O: Podremos aplicar el esquema vuelta atrás siempre que se trate de un conjunto infinito numerable.
O: Una estrategia voraz puede ser la única alternativa.
A: 1

Q: Indica cuál es la complejidad en función de n, donde k es una constante (no depende de n), del fragmento siguiente:
```cpp
for (int i = k; i < n - k; i++) {
  A[i] = 0;
  for (int j = i - k; j < i + k; j++)
    A[i] += B[j];
}
```
O: $O(n)$
O: $O(n^2)$
O: $O(n \log n)$
A: 0

Q: De las siguientes afirmaciones marca la que es verdadera
O: En un esquema de vuelta atrás, las cotas pesimistas no tienen sentido si lo que se pretende es obtener todas las soluciones factibles.
O: Las cotas pesimistas no son compatibles con un esquema de vuelta atrás.
O: El esquema de vuelta atrás no es compatible con el uso conjunto de cotas pesimistas y optimistas.
A: 0

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
O: Las demás opciones con verdaderas
O: ... será más eficiente cuanto más equitativa sea la división en subproblema
O: ... nunca tendrá una complejidad exponencial
A: 1

Q: Cual de las siguientes definiciones es cierta:
O: Las cotas de complejidad se emplean cuando para una misma talla se obtienen diferentes complejidades dependiendo de la entrada al problema.
O: Las cotas de complejidad se emplean cuando para diferentes tallas se obtienen diferentes complejidades dependiendo de la entrada al problema.
O: Ninguna de las anteriores
A: 0

Q: Cual seria la función de coste del algoritmo siguiente considera que la medida significativa es la operación * y que el modulo potencia es el calculo de la potencia implementado mediante productos sucesivos Tpotencia(n)=n:
```cpp
{Q} ={n=N, N> 1)
int ejerc6 ( int n ) {
	int i = 1;
int x = 1;
while (i <= n) {
  x = x * potencia(i, i);
  i = i + 1;
}
return x;
}
```
O: $T(n) = 3 + c \cdot n$ siendo c una constante
O: $T(n) \in \sum_{i=1}^{\log n} (i+1)$
O: $T(n) = 3 + \sum_{i=1}^{3}$
O: $T(n) = \sum_{i=1}^{n} (i+1)$
A: 3

Q: Se desea encontrar el camino más corto entre dos ciudades. Para ello se dispone de una tabla con la distancia entre los pares de ciudades en los que hay carreteras o un valor centinela (-1) si no hay, por lo que para ir de la ciudad inicial a la final es posible que haya que pasar por varias ciudades. También se conocen las coordenadas geográficas de cada ciudad y por tanto la distancia en línea recta entre cada par de ciudades. Se pretende acelerar la búsqueda de un algoritmo de ramificación y poda priorizando los nodos vivos (ciudades) que estén a menor distancia geográfica de la ciudad objetivo.
O: El nuevo algoritmo siempre será más rápido.
O: El nuevo algoritmo no garantiza que vaya a ser más rápido para todas las instancias del problema posibles.
O: Esta estrategia no asegura que se obtenga el camino más corto.
A: 1

Q: ¿Para qué sirven las cotas pesimistas en ramificación y poda?
O: Para descartar nodos basándose en la preferencia por algún otro nodo ya completado.
O: Para tener la certeza de que la cota optimista está bien calculada.
O: Para descartar nodos basándose en el beneficio esperado.
A: 2

Q: En una cuadrícula se quiere dibujar el contorno de un cuadrado de n casillas de lado. ¿cuál será la complejidad temporal del mejor algoritmo que pueda existir?
O: $O(n)$
O: $O(n^2)$
O: $O(\sqrt{n})$
A: 0

Q: Se pretende implementar mediante programacion dinamica iterativa la funcion recursiva:
```cpp
unsigned f(unsigned y, unsigned x) { // suponemos y >= x
  if (x == 0 || y == x)
    return 1;
  return f(y - 1, x - 1) + f(y - 1, x);
}
```
¿Cual es la mejor complejidad espacial que se puede conseguir?
O: $O(1)$
O: $O(y^2)$
O: $O(y)$
A: 2

Q: En un algoritmo recursivo, la forma de dividir el problema en subproblemas:
O: Influye en la complejidad espacial del mismo.
O: Influye en su complejidad temporal.
O: No influye en ninguna de sus complejidades.
A: 1

Q: Si para resolver un mismo problema usamos un algoritmo de vuelta atrás y lo modificamos mínimamente para convertirlo en un algoritmo de ramificación y poda, ¿qué cambiamos realmente?
O: Cambiamos la función que damos a la cota pesimista.
O: El algoritmo puede aprovechar mejor las cotas optimistas.
O: La comprobación de las soluciones factibles: en ramificación y poda no es necesario puesto que solo genera nodos factibles.
A: 1

Q: Si $f(n) \in O(g(n))$ ¿cuál de estas situaciones no es posible?
O: $g(n) \in O(f(n))$
O: $\lim_{n \to \infty} \frac{g(n)}{f(n)} = 0$
O: $f(n) \in \Omega(g(n))$
A: 1

Q: Indica cuál de las siguientes afirmaciones sobre el problema de la mochila continua es cierta:
O: El esquema voraz podría no encontrar ninguna solución.
O: Un esquema voraz siempre encuentra alguna solución, aunque no sea óptima.
O: Se puede demostrar que un esquema voraz encuentra siempre la solución óptima.
A: 2

Q: La eficiencia de los algoritmos voraces se basa en el hecho de que...
O: ... con antelación, las posibles decisiones se ordenan de mejor a peor
O: ... antes de tomar una decisión de comprueba si satisface las restricciones del problema
O: ... las decisiones tomadas nunca se reconsideran
A: 2

Q: Con los valores numéricos almacenados en un fichero, queremos construir un heap (montículo). ¿Cuál es la forma más eficiente de proceder?
O: Almacenar esos valores en un vector y después, reorganizar sus elementos para que estén dispuestos en forma de heap.
O: Ambas formas de proceder son equivalentes en cuanto a eficiencia.
O: Almacenar esos valores directamente en un heap que inicialmente está vacío y va creciendo por cada uno de los valores insertados.
A: 0

Q: ¿Cuál de las siguientes jerarquías de complejidades es la correcta?
O: $O(1) \subset O(\lg n) \subset O(\lg \lg n) \subset ...$
O: $... \subset O(n!) \subset O(2^n) \subset O(n^n)$
O: $... \subset O(2^n) \subset O(n!) \subset O(n^n)$
A: 2

Q: Considera el algoritmo descrito a continuacion. Si consideramos como medida significativa el numero de movimientos del vector instrucciones 1 y 3 entonces el algoritmo tiene un coste:
```cpp
for (i = 1; i < N; i++) {
  X = V[i]; // (1)
  Izq = 0;
  Der = i - 1;
  while (Izq <= Der) {
    Medio = (Izq + Der) / 2;
    if (X < V[Medio]) // (2)
      Der = Medio - 1;
    else
      Izq = Medio + 1;
  }
  for (j = i - 1; j >= Izq; j--) {
    V[j + 1] = V[j]; // (3)
  }
  V[Izq] = X;
}
```
O: $\Theta(n^2)$
O: $O(n)$
O: $\Theta(n)$
O: $\Omega(n)$ y $O(n^2)$
A: 3

Q: Dado un vector de tamaño n de números enteros. ¿Con qué complejidad temporal se puede determinar si sus elementos están dispuestos formando un montículo de mínimos?
O: $O(n)$
O: $O(\log n)$
O: $O(1)$
A: 0

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Se pretende resolver mediante un algoritmo de ramificación y poda. ¿Qué ocurre si el subóptimo de partida coincide con la cota optimista del nodo inicial?
O: Que el algoritmo sería incorrecto ya que el subóptimo de partida es en realidad una cota pesimista para el nodo inicial.
O: Que el algoritmo no debería explorar ningún nodo.
O: Que la cota optimista está mal estimada.
A: 1

Q: Cual seria el montículo de mínimos implementado en un vector resultantes después de haber insertado los siguientes elementos en el orden indicado 5,3,8,2,1
O: 0 1 2 3 4 5 5 3 8 2 1 ...
O: 0 1 2 3 4 5 1 3 8 5 2 ...
O: 0 1 2 3 4 5 1 2 8 5 3 ...
O: 0 1 2 3 4 5 1 2 3 5 8 ...
A: 2

Q: Una de estas tres afirmaciones es falsa. ¿Cuál?
O: Un algoritmo voraz puede no encontrar la solución óptima de un problema de selección discreta.
O: El esquema de ramificación y poda no garantiza que la complejidad temporal de resolución de un problema de selección discreta no sea exponencial.
O: Los algoritmos voraces no sirven para resolver problemas de selección discreta.
A: 2

Q: Cuando se calculan los coeficientes binomiales usando la recursión $${n \choose r} = {n-1 \choose r} + {n-1 \choose r-1}$$, con $${n \choose 0} = {n \choose n} = 1$$, qué problemas se da y cómo se puede resolver?
O: Se repiten muchos cálculos y ello se puede evitar haciendo uso de una estrategia voraz.
O: Se repiten muchos cálculos y ello se puede evitar usando programación dinámica.
O: La recursión puede ser infinita y por tanto es necesario organizarla según el esquema iterativo de programación dinámica.
A: 1

Q: El problema de la mochila, ¿puede solucionarse de forma óptima empleando la estrategia de divide y vencerás?:
O: Sólo para el caso de la mochila con fraccionamiento
O: Sólo para el caso de la mochila sin fraccionamiento
O: Si, se puede aplicar para ambos casos.
A: 1

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
O: $(4^{\log_2(n)}) \subseteq O(n^2) \subset O(2^n)$
O: $O(n^2) \subset O(2^{\log_2(n)}) \subset O(2^n)$
O: $O(2^{\log_2(n)}) \subseteq O(n^2) \subset O(n!)$
A: 1

Q: Decidid cuál de estas tres es la cota pesimista más ajustada al valor óptimo de la mochila discreta
O: El valor de la mochila continua correspondiente.
O: El valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor específico de los objetos.
O: El valor de una mochila que contiene todos los objetos aunque se pase del peso máximo permitido.
A: 1

Q: ¿Cuál de los siguientes criterios proveería una cota optimista para el problema de encontrar el camino más corto entre dos ciudades (se supone que el grafo es conexo)?
O: Utilizar la solución (subóptima) que se obtiene al resolver el problema mediante un algoritmo voraz.
O: Calcular la distancia recorrida moviéndose al azar por el grafo hasta llegar (por azar) a la ciudad destino.
O: Calcular la distancia geométrica (en línea recta) entre la ciudad origen y destino.
A: 2

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es menor que el valor de una cota optimista? (entendiendo que ambas cotas se aplican sobre el mismo nodo)
O: En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
O: En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
O: Sí, siempre es así.
A: 1

Q: ¿Cual es la complejidad temporal, en el peor de los casos, del mejor algoritmo que se puede escribir para resolver el problema de la mochila discreta?
O: Polinomica con el numero de objetos a tratar, siempre que se utilice programacion dinamica.
O: Ninguna de las otras dos son ciertas.
O: Exponencial con el numero de objetos a tratar.
A: 2

Q: Se entiende como solución optima al problema del viajante de comercio la que representa el ciclo de Hamilton de menor coste que se puede conseguir un grafo valuado que esquema nos garantiza la resolución optima de ese problema
O: II y III
O: I Aplicando un algoritmo de divide y vencerás basado en las componentes conexas del grafo
O: III aplicando un algoritmo voraz con una función de selección basada en la arista mas corta
O: II aplicando un esquema vuelta atrás back tracking
A: 3

Q: Los algoritmos de programación dinámica hacen uso...
O: de que se puede ahorrar esfuerzo guardando los resultados de esfuerzos anteriores
O: de que la solución óptima se puede construir añadiendo el componente óptimo de los restantes, uno a uno
O: de una estrategia trivial consistente en examinar todas las soluciones posibles
A: 0

Q: Dado el problema de las torres de Hanoi resuelto mediante divide y vencerás, ¿cuál de las siguientes relaciones de recurrencia expresa mejor su complejidad temporal para el caso general, siendo n el número de discos?
O: $T(n) = 2T(n - 1) + n$
O: $T(n) = T(n - 1) + n$
O: $T(n) = 2T(n - 1) + 1$
A: 0

Q: Queremos generar todas las formas distintas de mezclar n substancias de forma que el peso no supere el gramo. Queremos hacer un programa que genere todas las combinaciones posibles
O: No se puede usar Backtracking porque las decisiones no son valores discretos
O: No se puede usar Backtracking porque el número de combinaciones es infinito
O: No hay ningún problema en usar Backtracking
A: 2

Q: Sobre el teorema de reducción:
O: Que se cumpla es condición necesaria para poder aplicar divide y vencerás.
O: Las otras dos opciones son ambas falsas.
O: Que se cumpla es condición necesaria para poder aplicar programación dinámica.
A: 1

Q: A partir de cual de los siguientes recorridos se puede reconstruir un árbol binario completo
O: InOrden
O: PostOrden
O: Las tres respuestas son correctas
O: PreOrden
A: 2

Q: Sea A una matriz cuadrada n x n. Se trata de buscar una permutación de las columnas tal que la suma de los elementos de la diagonal principal se mínima. Indica cuál de las siguientes afirmaciones es falsa:
O: Si se construye una solución al problema basada en el esquema de ramificación y poda, una buena elección de cotas optimistas y pesimistas podría evitar la exploración de todas las permutaciones posibles.
O: La complejidad temporal de la mejor solución posible al problema es $O(n!)$.
O: La complejidad temporal de la mejor solución posible al problema es $O(n^2)$.
A: 2

Q: La complejidad temporal en el mejor de los casos de un algoritmo recursivo
O: Siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo.
O: Las demás opciones son falsas.
O: Coincide con el valor del caso base de la ecuación de recurrencia que expresa la complejidad del algoritmo.
A: 1

Q: Cual de estos tres problemas de optimización no tiene solución voraz óptima
O: mochila discreta
O: mochila continua
O: árbol de recubrimiento de coste mínimo
A: 0

Q: Con respecto a la complejidad espacial de los algoritmos de ordenación Quicksort, Heapsort y Mergesort:
O: Mergesort tiene complejidad espacial lineal con el tamaño del vector a ordenar, la de los otros dos es constante.
O: Mergesort y Heapsort tienen complejidad espacial lineal con el tamaño del vector a ordenar, la de Quicksort es constante.
O: Las complejidad espacial de todos ellos es lineal con el tamaño del vector a ordenar.
A: 0

Q: Sea A un árbol binario ordenado de n nodos, en el que todos sus elementos son distintos entonces la operación de búsqueda de un elemento que no esta en el árbol tendrá un coste
O: $O(\log n)$
O: $\Omega(\log n)$ y $O(n)$
O: $\Theta(\log n)$
O: $\Theta(n)$
A: 2

Q: Resolviendo la ecuación de recurrencia del ejercicio siguiente se obtiene que su función de coste es: 
```
Función F (ent n: entero): entero
variables x, i: entero
Inicio
	si (n>=1) entonces
		retorna 1
	si no
		para i de 1 a n hacer
			x← 1
			mientras x<n hacer
				x← x*2
			finmientras
		finpara
		retorna F(n/2)+F(n/2)
	finsi
fin
```
O: O(n*log^2 n)
O: O(log n)
O: O(2^n)
O: O(n^2)
O: O(n)
A: 0

Q: En cuanto a la complejidad temporal de la siguiente función:
```cpp
int ejemplo(vector<int> &v) {
  int n = v.size();
  int j, i = 2;
  int sum = 0;
  while (n > 0 && i < n) {
    j = i;
    while (v[j] != v[1]) {
      sum += v[j];
      j = j / 2;
    }
    i++;
  }
  return sum;
}
```
O: Las complejidades en el mejor y en el peor de los casos no coinciden.
O: El mejor de los casos se da cuando $n = 0$, su complejidad es constante.
O: Esta función no presenta casos mejor y peor puesto que solo puede haber una instancia para cada una de las posibles talla
A: 0

Q: Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
  if (n < 2)
    return;
  for (int i = 0; i < pow(n, 2); i++)
    cout << "*";
  for (int i = 0; i < 5; i++)
    f(n / 2);
}
```
O: $O(5^{\log n})$
O: $O(n^2 \log n)$
O: $O(n^2)$
A: 0

Q: ¿Cuál es la complejidad temporal de la siguiente función recursiva?
```cpp
unsigned desperdicio(unsigned n) {
  if (n <= 1)
    return 0;
  unsigned sum = desperdicio(n / 2) + desperdicio(n / 2);
  for (unsigned i = 1; i < n - 1; i++)
    for (unsigned j = 1; j <= i; j++)
      sum += i * j;
  return sum;
}
```
O: $O(2^n)$
O: $O(n^2)$
O: $O(n^2 \log n)$
A: 1

Q: El recorrido en profundidad de un grafo G no dirigido ha producido el arbol que se muestra en la figura, en el que cada nodo esta numerado siguiendo el orden de visita del recorrido en profundidad:
```
     1
   / | \
  2  5  7
 /|  |
3 4  6
```
O: Los nodos 1 y 2 pueden ser adyacentes al nodo 4
O: El nodo 2 es adyacente al nodo 3 y el nodo 3 puede ser adyacente al nodo 4
O: El nodo 1 puede ser adyacente al nodo 4 y al nodo 5 puede ser adyacente al nodo 7
O: Los nodos 1 y 3 pueden ser adyacentes al nodo 6
A: 0

Q: En un algoritmo de búsqueda y enumeración, ¿qué podemos decir acerca de la heurística que se utiliza para determinar si un nodo debe expandirse o no?
O: Las otras dos opciones son ambas ciertas.
O: Que puede equivocarse, por eso se le llama heurística.
O: Que también puede usarse como estrategia de búsqueda.
A: 2

Q: Un tubo de n centímetros de largo se puede cortar en segmentos de 1 centímetro, 2 centímetros, etc... Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es la que más ingresos nos producirá. Di cuál de estas tres afirmaciones es FALSA.
O: Hacer una evaluación exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $\Theta(n!)$
O: Es posible evitar hacer la evaluación exhaustiva "de fuerza bruta" guardando, para cada posible longitud j < n el precio más elevado posible que se puede obtener dividiendo el tubo correspondiente
O: Hace una evaluación exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $\Theta(2^n)$
A: 0

Q: Una de las respuestas siguientes es falsa. ¿Cuál es? El problema del viajante de comercio ...
O: ... se puede resolver exactamente usando un algoritmo de búsqueda y enumeración como es el de vuelta atrás o el de ramificación y poda.
O: ... se puede resolver exactamente usando un algoritmo voraz derivado del de Kruskal.
O: ... se puede resolver exactamente usando un algoritmo de programación dinámica.
A: 1

Q: Los algoritmos warshall, floyd y kruskal son ejempls de los siguientes algoritmos
O: Warshall programación dinámica, floyd programación dinámica, kruskal programación dinámica
O: Warshall programación dinámica, floyd algoritmo voraz, kruskal backtracking
O: Warshall programación dinámica, floyd programación dinámica, kruskal algoritmo voraz
O: Warshall algoritmo voraz, floyd programación dinámica, kruskal algoritmo voraz
A: 2

Q: Sea f(n) la solución de $f(n) = 2f(n/2) + n$, $f(1) = 1$
O: $f(n) \in O(n)$
O: $f(n) \in O(n^2)$
O: $f(n) \in O(n \log n)$
A: 2

Q: 
```cpp
int f(int x, int y) {
  if (x <= y)
    return 1;
  return x + f(x - 1, y);
}
```
O: $O(x^2)$
O: $O(1)$
O: $O(x)$
A: 1

Q: Sea un grafo G no dirigido etiquetado con etiquetas positivas y conexo entonces es cierto que el algoritmo de Kruskal
O: Solo puede producir una única solución si todas las etiquetas tienen valores distintos
O: Kruskal puede producir una única solución si todas las etiquetas tienen valores distintos
O: Puede producir distintas soluciones si todas las etiquetas tienen valores distintos
O: Solo puede producir una única solución independientemente de los valores de las etiquetas
O: El numero de soluciones que puede generar Kruskal es imprevisible en cualquier caso
A: 0

Q: Si $f \notin O(g_1)$ y $f \in O(g_2)$ entonces siempre se cumplirá:
O: $f \in \Omega(\min(g_1,g_2))$
O: $f \in \Omega(g_1 + g_2)$
O: $f \notin O(\max(g_1, g_2))$
A: 0

Q: Supongamos que queremos hacer una copia de seguridad de nuestro ficheros mas importantes y para ello solo disponemos de un DVD+R grabable de 4.7Gb según esto tenemos n ficheros con distintos tamaños respectivamente y además nuestro DVD tiene capacidad máxima T se cumple que T< t1+t2+t3+...+tnCon respecto al problema anterior cual de las afirmaciones es cierta
O: para optimizar la utilización del espacio del DVD utilizaría un esquema de ramificación y poda
O: para optimizar la utilización del espacio del DVD utilizaría un esquema de backtracking
O: para optimizar la utilización del espacio del DVD utilizaría un esquema de divide y vencerás
O: para optimizar la utilización del espacio del DVD utilizaría un esquema de voraz
A: 1

Q: Que algoritmo es menos costoso para obtener el camino minimo entre todos los pares de vertices de un grafo
O: Aplicar sucesivamente Dijkstra en este caso tiene igual cota superior de coste que aplicar Floyd
O: Calcularía la matriz de cierre transitivo
O: Dijkstra es mas eficiente puesto que tiene menor coste
O: Kruskal es mas adecuado para lograr este objetivo
O: Floyd tiene menor cota superior de coste que Dijkstra en este caso
A: 0

Q: El problema del cambio consiste en formar una cantidad dineraria M utilizando el menor número posible de monedas a escoger de entre las disponibles. ¿Qué estrategia resulta ser la más eficiente para garantizar la solución óptima?
O: Un algoritmo Voraz.
O: Programación Dinámica.
O: Divide y vencerás.
A: 1

Q: ¿Cuál de estas expresiones es falsa?
O: $n + n \log n \in \Theta(n)$
O: $n + n \log n \in \Omega(n)$
O: $2n^2 + 3n + 1 \in O(n^3)$
A: 2

Q: Un problema de tamaño n puede transformarse en tiempo $O(n^2)$ en otro de tamaño n-1. Por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante, ¿cuál de estas clases de coste temporal asintótico es la más ajustada?
O: $O(2^n)$
O: $O(n^3)$
O: $O(n^2)$
A: 1

Q: En el método voraz ...
O: ... el dominio de las decisiones sólo pueden ser conjuntos discretos o discretizables.
O: ... es habitual preparar los datos para disminuir el coste temporal de la función que determina cuál es la siguiente decisión a tomar.
O: ... siempre se encuentra solución pero puede que no sea la óptima.
A: 1

Q: Indica cuál de los siguientes conjuntos es el conjunto $O(f)$:
O: $\{g : \mathbb{N} \to \mathbb{R}^+ \mid \exists c > 0, \exists n_0 \in \mathbb{N}, \forall n > n_0, g(n) < c f(n)\}$
O: $\{g : \mathbb{N} \to \mathbb{R}^+ \mid \exists c > 0, \exists n_0 \in \mathbb{N} : \forall n > n_0, g(n) > c f(n)\}$
O: $\{g : \mathbb{N} \to \mathbb{R}^+ \mid \exists c, d > 0, \exists n_0 \in \mathbb{N} : \forall n > n_0, c f(n) \leq g(n) \leq d f(n)\}$
A: 0

Q: La complejidad temporal del algoritmo Mergesort cuando se aplica a un vector de tamaño n es... (selecciona la más ajustada)
O: ... $\Omega(n)$ y $O(n^2)$.
O: ... $\Theta(n \cdot \log(n))$.
O: ... $\Omega(n \cdot \log(n))$ y $O(n^2)$.
A: 1

Q: Un algoritm recursivo basado en el esquema divide y vencerás...
O: ... será más eficiente cuanto más equitativa sea la división en subproblemas
O: Las demás opciones son verdaderas
O: ... nunca tendrá una complejidad exponencial
A: 0

Q: Al resolver el problema del viajante de comercio con Backtracking, cual de estas es una buena cota pesimista?
O: se ordenan las aristas restante de menor a mayor distancia y se calcula la suma de las n ciudades
O: se resuelve el problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido
O: se multiplica n por la distancia de la arista más corta que nos queda por considerar
A: 1

Q: Un problema de tamaño $n$ puede transformarse en tiempo $O(1)$ en siete de tamaño $\frac{n}{7}$; por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante.¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
O: $O(n^2)$
O: $O(n)$
O: $O(n \log n)$
A: 2

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva:
```cpp
int f(int x, int y) {
  if (x <= y)
    return 1;
  return x + f(x - 1, y);
}
```
¿Cuál es la mejor complejidad temporal que se puede conseguir?
O: $O(y)$
O: $O(x)$
O: $O(x \cdot y)$
A: 1

Q: Las siguientes funciones calculan el valor de la potencia n-ésima de dos. ¿Cuál es más eficiente en cuanto a coste temporal?
```cpp
unsigned long pot2_1(unsigned n) {
  if (n == 0)
    return 1;
  if (n % 2 == 0)
    return pot2_1(n / 2) * pot2_1(n / 2);
  else
    return 2 * pot2_1(n / 2) * pot2_1(n / 2);
}
```
```cpp
unsigned long pot2_2(unsigned n) {
  if (n == 0)
    return 1;
  unsigned long aux = pot2_2(n / 2);
  if (n % 2 == 0)
    return aux * aux;
  else
    return 2 * aux * aux;
}
```
O: La primera, `pot2_1(n)`, es más eficiente que la otra.
O: La segunda, `pot2_2(n)`, es más eficiente que la otra.
O: Las dos funciones son equivalentes en cuanto a coste temporal.
A: 1

Q: La función $\Gamma$ de un número semiEntero positivo (un número es semiEntero si al restarle 0.5 es entero) se define como 
```cpp
double gamma(double n) {
  if (n == 0.5)
    return sqrt(PI);
  return n * gamma(n - 1);
}
```
¿Se puede calcular usando programación dinámica iterativa?
O: No, ya que el índice del almacén sería un número real y no entero.
O: Sí.
O: No, ya que no podríamos almacenar los resultados intermedios en el almacén.
A: 1

Q: ¿Cuál de los siguientes algoritmos de ordenación necesita un espacio de almacenamiento adicional al vector que se ordena con complejidad O(n)?
O: Mergesort.
O: Quicksort.
O: Bubblesort.
A: 0

Q: ¿Cuál de los siguientes pares de problemas son equivalentes en cuanto al tipo de solución (óptima, factible, etc.) aportada por el método voraz?
O: El fontanero diligente y la asignación de tareas.
O: El fontanero diligente y el problema del cambio.
O: El fontanero diligente y la mochila continua.
A: 2

Q: En el esquema de vuelta atrás el orden en el que se van asignando los distintos valores a las componentes del vector que contendrá la solución...
O: ...es irrelevante si no se utilizan mecanismos de poda basados en la mejor solución hasta el momento.
O: Las otras dos anteriores son ciertas.
O: ...puede ser relevante si se utilizan mecanismos de poda basados en estimaciones optimistas.
A: 1

Q: Tenemos un vector ordenado de tamaño $n_o$ y un vector desordenado de tamaño $n_d$, queremos obtener un vector ordenado con todos los elementos ¿Que sera mas rapido?
O: Insertar los elementos del vector desordenado (uno a uno) en el vector ordenado.
O: Ordenar el desordenado y luego mezclar las listas.
O: Depende de si $n_o > n_d$ o no
A: 1

Q: ¿Como se veria afectada la solucion voraz al problema de la asignacion de tareas en el caso de que se incorporaran restricciones que contemplen que ciertas tareas no pueden ser adjudicadas a ciertos trabajadores?
O: La solucion factible ya no estaria garantizada, es decir, pudiera ser que el algoritmo no llegue a solucion alguna
O: Habria que replantearse el criterio de seleccion para comenzar por aquellos trabajadores con mas restricciones en cuanto a las tareas que no pueden realizar para asegurar, al menos, una solucion factible
O: Ya no se garantizaria la solucion optima pero si una factible.
A: 0

Q: Las relaciones de recurrencia...
O: sirven para reducir el coste temporal de una solución cuando es prohibitivo
O: aparecen sólo cuando la solución sea del tipo divide y vencerás
O: expresan recursivamente el coste temporal de un algoritmo
A: 2

Q: El problema del alfarero (solución discreta con valores y tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cual es el valor máximo de los objetos que puede fabricar teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Para ello se escribe la siguiente función siguiendo la técnica de divide y vencerás:
```cpp
int potter(const vector<int> &v, const vector<int> &m, const vector<int> &t,
           int T, int k) {
  if (k == 0)
    return 0;
  int max_earnings = -1;
  for (int c = 0; c <= m[k - 1]; c++) {
    int earnings = 0;
    if (T >= c * t[k - 1])
      // ==> Falta una línea <= =
      max_earnings = max(max_earnings, earnings);
  }
  return max_earnings;
}
```
O: `earnings = c * v[k-1] + potter(v, m, t, k-1, T - c * t[k-1]);`
O: `earnings = potter(v, m, t, k-1, T);`
O: `earnings = potter(v, m, t, k-1, T - c * t[k-1]);`
A: 0

Q: Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
  if (n < 2)
    return;
  for (int i = 0; i < pow(n, 2); i++)
    cout << "*";
  for (int i = 0; i < 5; i++)
    f(n / 2);
}
```
O: $\Theta(n^2)$
O: $\Theta(n^2 \log n)$
O: $\Theta(5^{\log n})$
A: 2

Q: Los algoritmos Dijkstra, Floyd, Warshall y Kruskal resuelven respectivamente
O: Camino mínimo entre todos los vértices, camino mínimo de un vértice al resto, existencia de caminos entre todos los vértices, clausura transitiva
O: Camino mínimo de un vértice al resto, existencia de caminos mínimos, existencia de caminos entre todos los vértices, árbol de expansión mínimo
O: Camino mínimo de un vértice al resto, camino mínimo entre todos los vértices, existencia de caminos entre todos los vértices, árbol de expansión mínimo
O: Camino mínimo entre todos los vértices, camino mínimo de un vértice al resto, existencia de camino de un vértice al resto, árbol de expansión mínimo
A: 2

Q: Que ventaja tiene un esquema de ramificación y poda frente a un vuelta atrás
O: Que no tiene un coste exponencial
O: Que se exploran todos los nodos del árbol de búsqueda de soluciones
O: Que simplifica el código
O: Que tiene un coste menor
A: 3

Q: Sea A un árbol binario ordenado equilibrad de n elementos en el que todos sus elementos son distintos, entonces la operación de búsqueda de un elemento que no esta en el árbol tendrá un coste
O: Θ(n)
O: O(log n)
O: Ω(log n) y O(n)
O: Θ(log n)
A: 1

Q: En el esquema de ramificación y poda, ¿qué estructura es la más adecuada si queremos realizar una exploración por niveles?
O: Pila.
O: Cola de prioridad.
O: Cola.
A: 2

Q: Si $f \in \Omega(g_1)$ y $f \in \Omega(g_2)$ entonces
O: $f \notin \Omega(\min(g_1, g_2))$
O: $f \in \Omega(g_1 + g_2)$
O: $f \in \Omega(g_1 \cdot g_2)$
A: 1

Q: Los algoritmos de ordenacion quicksort y mergesort
O: tienen el mismo coste temporal asintotico en el caso peor
O: tienen el mismo coste temporal asintotico en el caso mejor
O: tienen el mismo coste temporal en los dos casos
A: 1

Q: De las expresiones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos.
O: Si $f \in \Theta(g)$ entonces $O(f) = O(g)$.
O: Si $f \in O(g)$ entonces $g \notin O(f)$.
O: Si $f \notin \Omega(g)$ entonces $O(f) = \Omega(g)$.
A: 0

Q: Los algoritmos de programación dinámica hacen uso ...
O: ... de que la solución óptima se puede construir añadiendo a la solución el elemento óptimo de los elementos restantes, uno a uno.
O: ... de que se puede ahorrar cálculos guardando resultados anteriores en un almacén.
O: ... de una estrategia trivial consistente en examinar todas las soluciones posibles.
A: 1

Q: Si un problema de optimización lo es para una función que toma valores continuos...
O: El uso de memoria de la programación dinámica iterativa y de la programación dinámica recursiva es el mismo independientemente de si el dominio es discreto o continuo.
O: La programación dinámica recursiva puede resultar mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
O: La programación dinámica iterativa siempre es mucho más eficiente que la programación dinámica recursiva en cuanto al uso de memoria.
A: 1

Q: La serie denominada tribonacci se define de la siguiente manera: T(0)=T(1)=1, T(2)=2, y T(n)=T(n-3)+T(n-2)+T(n-1) para n>3. Solo una de las afirmaciones siguientes es cierta. ¿Cuál es?
O: Un algoritmo de programación dinámica iterativa permite calcular el valor de T(n) en tiempo $\Theta(n)$.
O: Un algoritmo de programación dinámica iterativa para calcular T(n) tendría un coste espacial $\Theta(n)$ y este coste no se podría reducir a $\Theta(1)$.
O: Un algoritmo recursivo con memoización para calcular T(n) para a un n grande tendría una complejidad prohibitiva.
A: 0

Q: Se desea ordenar una lista enlazada de n elementos adaptando el algoritmo Mergesort. En este caso, al tratarse de una lista, la complejidad temporal asintótica de realizar la división en subproblemas resulta ser lineal con el tamaño de esa lista. ¿Cuál sería entonces el coste temporal de realizar dicha ordenación?
O: $\Theta(n \log n)$
O: Ninguna de las otras dos opciones es cierta.
O: $\Theta(n^2)$
A: 0

Q: ¿Por que se emplean funciones de coste para expresar el coste de una algoritmo?
O: Para poder expresar el coste de los algoritmos con mayor exactitud
O: Para que la expresión del coste del algoritmo sea válida para cualquier entrada al mismo
O: Para poder expresar el coste de un algoritmo mediante una expresión matemática
A: 1

Q: ¿Cuál sería la complejidad temporal de la siguiente función tras aplicar programación dinámica?
```cpp
double f(int n, int m) {
  if (n <= 1)
    return 1;
  return m * f(n - 1, m) * f(n - 2, m);
}
```
O: $\Theta(n^2)$
O: $\Theta(n \cdot m)$
O: $\Theta(n)$
A: 2

Q: Sea $f(n)$ la solución de la relación de recurrencia $f(n) = 2f(n-1)+1$; $f(1) = 1$. Indicad cuál de estas tres expresiones es cierta:
O: $f(n) \in \Theta(n)$
O: $f(n) \in \Theta(2^n)$
O: $f(n) \in \Theta(n^2)$
A: 1

Q: El valor que se obtiene con el método voraz para el problema de la mochila discreta es ...
O: ... un valor inferior al valor óptimo que a veces puede ser igual a este.
O: ... un valor inferior al valor óptimo, pero que nunca coincide con este.
O: ... un valor superior al valor óptimo.
A: 0

Q: Calcular la complejidad del siguiente fragmento de codigo:
```cpp
for (i = 1; i <= n; i++)
  for (j = 1; j <= 10000; j++)
    for (k = n - 1; k <= n; k++)
      cout << i << j << k << endl;
```
O: $O(n^2)$
O: $O(n^3)$
O: $O(2^n)$
O: $O(n)$
O: $O(n \cdot \log n)$
A: 3

Q: ¿Cuál es la complejidad temporal en el caso mejor del algoritmo que, dado un vector, nos dice cuál de sus elementos quedaría en la posición k si lo ordenáramos por orden descendente de valor?
O: $O(\log n)$
O: $O(n)$
O: $O(n \log n)$
A: 1

Q: ¿Se puede resolver mediante ramificación y poda un problema de selección discreta en el que cada una de las n decisiones se toman de un conjunto finito diferente?
O: No. Las decisiones deben ser todas de la misma naturaleza.
O: Sí, pero sólo si las decisiones son todas binarias.
O: Sí, siempre.
A: 2

Q: La complejidad del siguiente bucle es: 
```
for (i=1; i<=N; i++) {
	if (T[i] == x)
		Aux=i;
}
```
O: IV I y II son correctas
O: V ninguna de las anteriores
O: I Constante desde el punto de vista del numero de comparaciones
O: III Varia en función de la ordenación del vector
O: II Constante desde el punto de vista del numero de asignaciones
A: 1

Q: ¿Cuál de estas tres expresiones es falsa?
O: $2n^3 - 10n^2 + 1 \in O(n^3)$
O: $n + n \sqrt{n} \in \Omega(n)$
O: $n + n \sqrt{n} \in \Theta(n)$
A: 2

Q: Sea $g(n) = \sum_{i=0}^{K} a_i n^i$. Di cuál de las siguientes afirmaciones es falsa:
O: Las otras dos afirmaciones son ambas falsas.
O: $g(n) \in \Theta(n^K)$
O: $g(n) \in \Omega(n^K)$
A: 0

Q: Si $f(n) \in O(n^2)$, ¿podemos decir siempre que $f(n) \in O(n^3)$?
O: No, ya que $n^2 \in O(n^3)$
O: Si ya que $n^2 \in O(n^3)$
O: Sólo para valores bajos de
A: 1

Q: Para que sirven las cotas pesimistas en RyP
O: Para descartar nodos basándose en el beneficio esperado
O: Para tener la certeza de que la cota optimista está bien calculada
O: Para descartar nodos basándose en la preferencia por algún otro nodo ya completado
A: 0

Q: La complejidad temporal (o coste temporal asintótico) en el mejor de los casos...
O: Las otras dos opciones son ambas verdaderas.
O: ... es una función de la talla, o tamaño del problema, que tiene que estar definida para todos los posibles valores de ésta
O: ... es el tiempo que tarda el algoritmo en resolver la talla más pequeña que se le puede presentar.
A: 1

Q: ¿Cuál es el coste de monticulizar (heapify) un vector de tamaño N?
O: $O(N)$ y $\Omega(1)$
O: $O(N \log N)$ y $\Omega(N)$
O: $\Theta(N)$
A: 2

Q: Que estructura de datos es mas eficiente para almacenar los nodos vivos al implementar un algoritmo de ramificación y poda
O: Una lista
O: Un árbol binario ordenado
O: Un árbol balanceado
O: Una cola de prioridad
A: 3

Q: Si consideramos como medida significativa el numero de comparaciones con respecto a las variables Min y Max siendo n el numero total de elementos a tratar. Entonces el caso mejor se obtiene
O: Cuando los datos vienen ordenados ascendentemente que hay n comparaciones
O: Cuando los datos dispuestos en orden inverso que hay n comparaciones
O: Cuando los datos vienen dispuesto en orden inverso que hay 2n comparaciones
O: Cuando los datos vienen ordenado ascendentemente que hay 2n comparaciones
A: 1

Q: La versión de Quicksort que utiliza como pivote la mediana del vector...
O: ... se comporta mejor cuando el algoritmo ya está ordenado
O: ... El hecho de que el vector estuviera previamente ordenado o no, no influye en la complejidad temporal de este algoritmo
O: ... se comparta peor cuando el algoritmo ya está ordenado
A: 1

Q: Se dispone de un conjunto de n valores numéricos dispuestos en un vector sin orden pre-establecido. Se desea escribir una función que reciba ese vector y un valor k ($n/2 \leq k \leq n$) y que devuelva los k valores más pequeños dispuestos en otro vector de manera ordenada. ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
O: $O(kn)$
O: Ninguna de las otras dos opciones es cierta.
O: $O(k \log n)$
A: 2

Q: Cual es el objetivo de los rebalanceos en un árbol AVL
O: Que la búsqueda de los elementos en el árbol se mantenga constante
O: Que la diferencia máxima entre sus dos subárboles sea 1
O: Que todos los subarboles tengan la misma altura
O: Que si un nodo del ultimo nivel esta vacío los siguientes en ese nivel también lo estén
A: 1

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Utilizando la técnica programación dinámica iterativa se pretende conocer únicamente la ganancia máxima que podría obtener el alfarero. ¿Cuál es la mejor complejidad espacial y temporal que se puede conseguir?
O: Espacial $\Theta(n)$ y temporal $\Theta(n \cdot T \cdot \max_{i=0}^{n-1} m_i)$.
O: $\Theta(n \cdot T)$, tanto espacial como temporal.
O: Espacial $\Theta(T)$ y temporal $\Theta(n \cdot T \cdot \max_{i=0}^{n-1} m_i)$.
A: 2

Q: Supongamos que una solución recursiva a un problema de optimización muestra estas dos características: por un lado, se basa en obtener soluciones óptimas a problemas parciales más pequeños, y por otro, estos subproblemas se resuelven más de una vez durante el proceso recursivo. Este problema es candidato a tener una solución alternativa basada en
O: un algoritmo de programación dinámica.
O: un algoritmo voraz.
O: un algoritmo del estilo de divide y vencerás.
A: 0

Q: Haciendo uso de la función Merge del algoritmo Mergesort se quiere mezclar k vectores ordenados de n elementos cada uno y obtener un único vector de kn elementos. Para ello primero se mezclan los dos primeros vectores, luego el resultado se mezcla con el tercero y a su vez, este resultado se mezcla con el cuarto y así hasta llegar al k-ésimo. ¿Cuál sería la complejidad del algoritmo?
O: $\Theta(n \cdot k^2)$
O: $\Theta(n \cdot k)$
O: $\Theta(n^2 \cdot k)$
A: 1

Q: Los algoritmos de programación dinámica hacen uso
O: De que se puede ahorrar esfuerzo guardando los resultados de esfuerzos anteriores.
O: De una estrategia trivial consistente en examinar todas las soluciones posibles.
O: De que la solución óptima se puede construir añadiendo el componente óptimo de los restantes, uno a uno.
A: 0

Q: El uso de funciones de cota en ramificación y poda...
O: ...garantiza que el algoritmo va a ser más eficiente ante cualquier instancia del problema.
O: ...transforma en polinómicas complejidades que antes eran exponenciales.
O: ...puede reducir el número de instancias del problema que pertenecen al caso peor.
A: 2

Q: Considerad la función siguiente:
```cpp
int M(int i, int f) {
  if (i == f)
    return i;
  else {
    e = v[M(i, (i + f) / 2)];
    f = v[M((i + f) / 2 + 1, f)];
    if (e < f)
      return e;
    else
      return f;
  }
}
```
Si la talla del problema viene dada por $n = f - i + 1$, ¿cuál es el coste temporal asintótico en el supuesto de que $n$ sea una potencia de 2?
O: $O(n)$.
O: $O(n^2)$.
O: $O(n \log(n))$.
A: 0

Q: ¿Qué hace la siguiente función?
```cpp
void f(vector<int> &A) {
  priority_queue<int> pq;
  for (int i = A.size() - 1; i >= 0; i--) {
    pq.push(A[i]);
  }
  A.clear();
  while (!pq.empty()) {
    A.push_back(pq.top());
    pq.pop();
  }
}
```
O: Invierte el vector A (el último elemento quedará el primero)
O: Nada, deja el vector como estaba
O: Ordena el vector A
A: 2

Q: Una función recursiva es
O: III una función que llama a otra y esta llama a la primera
O: I una función que se llama a si misma
O: Todas son correctas
O: II una función que llama a otro numero indeterminado de veces
O: IV I y III son correctas
A: 4

Q: Pertenece $3n^2 + 3$ a $O(n^3)$?
O: Solo para c = 1 y n_0 = 5.
O: No.
O: Sí.
A: 2

Q: Disponemos de dos cadenas de longitudes m y n. Si resolvemos el problema de la distancia de edición mediante programación dinámica, ¿De qué tamaño debemos definir la matriz que necesitaremos?
O: $(m-1) \times (n-1)$
O: $m \times n$
O: $(m+1) \times (n+1)$
A: 2

Q: Se pretende aplicar la técnica memoización a la siguiente función recursiva:
```cpp
int f(int x, int y) {
  if (x <= y)
    return 1;
  return x + f(x - 1, y);
}
```
En el caso más desfavorable, ¿qué complejidades temporal y espacial cabe esperar de la función resultante?
O: $O(x-y)$, tanto temporal como espacial.
O: Temporal $O(x-y)$ y espacial $O(1)$
O: Ninguna de las otras dos opciones es correcta
A: 0

Q: Cual es el coste espacial asintotico del siguiente algoritmo:
```cpp
int f(int n) {
  int a = 1, r = 0;
  for (int i = 0; i < n; i++) {
    r = a + r;
    a = 2 * r;
  }
}
```
O: $O(n)$
O: $O(\log(n))$
O: $O(1)$
A: 2

Q: ¿Cuál de estos problemas tiene una solución eficiente utilizando programación dinámica?
O: El problemas del cambio.
O: La mochila discreta sin restricciones adicionales.
O: El problema de la asignación de tareas.
A: 0

Q: ¿Como se vería afectada la solución voraz al problema de la asignación de tareas en el caso de que se incorporaran restricciones que contemplen que ciertas tareas no pueden ser adjudicadas a ciertos trabajadores?
O: La solución factible ya no estaría garantizada, es decir, pudiera ser que el algoritmo o llegue a solución alguna
O: Habría que replantearse el criterio de selecciones
O: Ya no se garantizaría la solución óptima pero sí una factible
A: 0

Q: Que diferencia (entre otras) hay entre el algoritmo de Prim y el de Kruskal?
O: El subgrafo que paso a paso va generando el algoritmo de prim siempre contiene una única componente conexa.
O: Aun siendo el grafo de partida totalmente conexo, el algoritmo de Kruskal garantiza la solución optima mientras que el de prim solo garantiza un suboptimo.
O: El algoritmo de Prim es voraz y el de Kruskal no.
A: 0

Q: Un grafo no dirigido tiene 200 arcos podemos entonces deducir que
O: Ninguna de las anteriores
O: posee menos de 20 vertices
O: posee mas de 20 vertices y siempre es conexo
O: posee mas de 20 vertices
A: 3

Q: Estudiad la relación de recurrencia: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ pT(n/q) + g(n) & \text{en otro caso} \end{cases}$ (donde p y q son enteros mayores que 1). Di cuál de los siguientes esquemas algorítmicos produce de manera natural relaciones de recurrencia así.
O: Divide y vencerás.
O: Programación dinámica.
O: Ramificación y poda.
A: 0

Q: Tenemos un conjunto de n enteros positivos y queremos encontrar el subconjunto de tamaño m y de suma mínima.
O: Para encontrar la solución habría que probar con todas las combinaciones posibles de m enteros, con lo que la técnica de ramificación y poda no aporta nada con respecto a vuelta atrás.
O: Lo más adecuado sería usar una técnica de ramificación y poda, aunque en el peor caso el coste temporal asintótico (o complejidad temporal) sería exponencial.
O: Una técnica voraz daría una solución óptima.
A: 2

Q: Considera la función siguiente que es un algoritmo típico de búsquedaSupongamos que x esta en el vector y que todos los elementos son distintos. En este caso, el numero medio de comparaciones con la variable x es: 
```
Función pertenece (ent L: vector de enteros, ent x:entero):entero
variables: i, aux: entero
Inicio
	aux← 0
	para i de 0 a n-1 hacer
		si L[i]==x entonces
			aux← i
		finsi
	finpara
retorna aux
Fin
```
O: n
O: (n+1)/2
O: n/2
O: 1
A: 0

Q: ¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, una solución voraz (greedy) que es óptima?
O: El árbol de cobertura de coste mínimo de un grafo conexo.
O: El problema de la mochila discreta.
O: El problema de la mochila continua o con fraccionamiento.
A: 1

Q: Que tiene que valer k en la relacion de recurrencia $T(n) = 1$ si $n < 1$; $n^k + 2T(n/2)$ si $n > 1$ para que $T(n) = n \log(n)$?
O: 0
O: $\log(n)$
O: 1
A: 2

Q: De las siguientes afirmaciones marca la que es verdadera.
O: En un esquema de vuelta atrás, las cotas pesimistas no tienen sentido si lo que se pretende es obtener todas las soluciones factibles.
O: El esquema de vuelta atrás no es compatible con el uso conjunto de cotas pesimistas y optimistas.
O: Las cotas pesimistas no son compatibles con un esquema de vuelta atrás.
A: 0

Q: Indica cuál es la complejidad, en función de n (n≥0), del fragmento siguiente:
```cpp
int f(int n) {
  if (n == 0)
    return n;
  return f(n / 2) * f(n / 2);
}
```
O: $\Theta(\log n)$
O: $\Theta(n)$
O: $\Theta(n \log n)$
A: 1

Q: La mejor solución que se conoce para el problema de la mochila continua sigue el esquema...
O: ...voraz.
O: ...ramificación y poda.
O: ...divide y vencerás.
A: 2

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia?
```f(n) = n(n-1) + f(n-1) // si n>0
f(0) = 1 // si n=0
```
O: $f(n) \in \Theta(n^3)$
O: $f(n) \in \Theta(n^2)$
O: Ninguna de las otras dos opciones es cierta.
A: 0

Q: Se pretende obtener la complejidad temporal en el caso más desfavorable de la siguiente función.
```cpp
int exa(vector<int> &v) {
  int i, sum = 0, n = v.size();
  if (n > 0) {
    int j = n;
    while (sum < 100 and j != 0) {
      j = j / 2;
      sum = 0;
      for (i = j; i < n; i++)
        sum += v[i];
    }
    return j;
  } else
    return -1;
}
```
O: $C_s(n)=\sum^{\log(n+1)}_{k=1}(n-n/2^k)\in O(n\log n)$
O: $C_s(n)=\sum^{\log n}_{j=1}\sum^{j}_{i=1}(1/2)^i \in O(n\log n)$
O: $C_s(n)=\sum^{n/2}_{j=0}(1/2\sum^{n}_{i=j}1) \in O(n\log n)$
A: 0

Q: ¿Cuándo utilizaremos Programación Dinámica en lugar de Divide y Vencerás?
O: Cuando se incrementa la eficacia
O: Cuando se incrementa la eficiencia
O: Cuando se reduce el coste espacial.
A: 1

Q: Un árbol binario ordenado se caracteriza porque
O: Se construye desde la raíz hasta las hojas y no existe ninguna relacion entre los datos
O: Se construye desde la raíz hasta las hojas y existe una relacion de orden entre los datos
O: Se construye desde la raíz hasta las hojas y existe una relacion exclusivamente jerárquica entre los datos
O: Se construye desde las hojas a la raíz y existe una relacion jerárquica entre los datos
O: Se construye desde las hojas a la raíz y existe una relacion de orden entre los datos
A: 1

Q: En la solución al problema de la mochila continua, ¿por qué es conveniente la ordenación previa de los objetos?
O: Porque si no se hace no es posible garantizar que la toma de decisiones siga un criterio voraz
O: Para reducir la complejidad temporal en la toma de cada decisión de $O(n)$ a $O(1)$, donde n es el numero de objetos a considerar
O: Para reducir la complejidad temporal en la toma de cada decisión de $O(n^2)$ a $O(n\log n)$, donde n es el numero de objetos a considerar
A: 1

Q: Los algoritmos de programación dinámica hacen uso...
O: ... de que se puede ahorrar cálculos guardando resultados anteriores en un almacén
O: ... de una estrategia trivial consistente en examinar todas las soluciones posibles
O: ... de que la solución óptima se puede construir añadiendo a la solución el elemento óptimo de los elementos restantes, uno a uno.
A: 0

Q: En la solución al problema de la mochila continua, ¿por qué es conveniente la ordenación previa de los objetos?
O: Para reducir la complejidad temporal en la toma de cada decisión de $O(n)$ a $O(1)$, donde n es el numero de objetos a considerar
O: Para reducir la complejidad temporal en la toma de cada decisión de $O(n^2)$ a $O(n \log n)$, donde n es el numero de objetos a considerar
O: Porque si no se hace no es posible garantizar que la toma de decisiones siga un criterio voraz
A: 0

Q: ¿Qué hace la siguiente función? 
```cpp
void f(vector<int> &A) {
  priority_queue<int> pq;
  for (auto i : A)
    pq.push(A[i]);
  A.clear();
  while (!pq.empty()) {
    A.push_back(pq.top());
    pq.pop();
  }
}
```
O: Invierte el vector A (el último elemento quedará el primero).
O: Nada, deja el vector A como estaba.
O: Ordena el vector A.
A: 2

Q: Indica cuál es la complejidad de la función siguiente:
```cpp
unsigned sum(const mat &A) {
  // A es una matriz cuadrada
  unsigned d = A.n_rows();
  unsigned a = 0;
  for (unsigned i = 0; i < d; i++)
    for (unsigned j = 0; j < d; j++)
      a += A(i, j);
  return a;
}
```
O: $O(n^2)$
O: $O(n)$
O: $O(n \log n)$
A: 1

Q: Di cuál de estos tres algoritmos no es un algoritmo de "divide y vencerás":
O: Quicksort.
O: Mergesort.
O: El algoritmo de Prim.
A: 2

Q: Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
  if (n < 1)
    return;
  for (int i = 0; i < n; i++)
    for (int j = 0; j < n; j++)
      for (int k = 0; k < n; k++)
        cout << "*";
  for (int i = 0; i < 8; i++)
    f(n / 2);
}
```
O: $\Theta(n^3 \log n)$
O: $\Theta(n^3)$
O: $\Theta(n^2 \log n)$
A: 0

Q: Si estamos trabajando con un lenguaje de programacion no recursivo
O: Ninguna de las anteriores es correcta
O: Podríamos simular la recursividad mediante colas
O: No podríamos implementar ningún algoritmo recursivo
O: Podríamos simular la recursividad mediante pilas
O: No existen lenguajes de programación no recursivos
A: 3

Q: La complejidad temporal en el mejor de los casos de un algoritmo recursivo...
O: ... coincide con el valor del caso base de la ecuación de recurrencia que expresa la complejidad temporal del algoritmo.
O: Las demás opciones son falsas.
O: ... siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo.
A: 1

Q: ¿Qué tienen en común los algoritmos de ordenación Quicksort y Mergesort?
O: El número de llamadas recursivas que hacen en el mejor de los casos.
O: La complejidad temporal de la combinación de las soluciones parciales.
O: La complejidad temporal de la división en subproblemas.
A: 2

Q: ¿Que mecanismo se usa para acelerar el algoritmo de Prim?
O: El TAD "Union-find"
O: Mantener para cada vertice su "padre" mas cercano
O: Mantener una lista de los arcos ordenados segun su peso.
A: 1

Q: La complejidad en el mejor de los casos de un algoritmo de ramificación y poda...
O: ... puede ser polinómica con el número de decisiones a tomar.
O: ... suele ser polinómica con el número de alternativas por cada decisión.
O: ... es siempre exponencial con el número de decisiones a tomar.
A: 0

Q: En un problema de optimización, si el dominio de las decisiones es un conjunto finito,
O: una estrategia voraz puede ser la única alternativa.
O: podremos aplicar el esquema de vuelta atrás siempre que se trate de un conjunto infinito numerable.
O: es probable que a través de programación dinámica se obtenga un algoritmo eficaz que lo solucione.
A: 0

Q: Utilizaremos una estructura de cola en aquellas aplicaciones que requieran un tratamiento en los que los datos
O: debamos procesarlos en el mismo orden en el que se obtienen y no puedan repetirse
O: debamos procesarlos en el mismo orden en el que se obtiene y puedan repetirse
O: debamos procesarlos en orden inverso a como se obtienen y no puedan repetirse
O: se inserten y extraigan por un único punto y deben ser ordenados
O: debamos procesarlos en orden inverso a como se obtienen y puedan repetirse
A: 1

Q: Queremos resolver por ramificacion y poda el problema de la mochila discreta.Si resolvemos el mismo problema de la forma voraz pero sin ordenar previamente los objetos por valor/peso, obtendremos
O: Una cota pesimista
O: Nada que podamos utilizar
O: Una cota optimista
A: 0

Q: En un programa con dos bucles anidados, cada uno de los cuáles hace n iteraciones tarda:
O: $O(n^2)$
O: $O(n)$
O: $O(2^n)$
A: 0

Q: Para resolver la versión general del problema de la mochila con n objetos y carga máxima W , hemos escrito un algoritmo de divide y vencerás que, sucesivamente, divide el problema en dos subproblemas; cada uno de ellos toma la mitad de los objetos y la mitad de la carga máxima de la mochila. El caso base ocurre cuando solo hay un objeto que se añade a la solución si cabe en la fracción de carga máxima que corresponde a ese subproblema, y si no cabe se descarta. Asumiendo que n y W son potencias exactas de 2, ¿qué podemos decir de esta solución?
O: Que, aunque con los resultados de los subproblemas se puede componer la solución del problema original, esta formulación no mejora la solución estudiada en clase.
O: Que no cumple el teorema de reducción.
O: Que con los resultados de los subproblemas no siempre se puede componer la solución del problema original.
A: 2

Q: ¿Cuál de las siguientes formulaciones expresa mejor el número de llamadas recursivas que hace Quicksort en el mejor de los casos?
O: $\sum_{i=0}^{n} \log n$
O: $\sum_{i=0}^{\log n} 1$
O: $\sum_{i=0}^{\log n} 2^i$
A: 2

Q: Supongamos que obtenemos de teclado una secuencia ordenada de datos la cual vamos almacenando en una determinada estructura de datos entonces conociendo de antemano que sobre esta estructura vas a realizar muchas operaciones de búsqueda que estructura de almacenamiento erigirías
O: Una lista enlazada dinámicamente
O: Un vector
O: Una cola enlazada dinamicamente
O: Un árbol binario ordenado o árbol de búsqueda
O: Un grafo
A: 1

Q: Se desea encontrar el camino más corto entre dos ciudades. Para ello se dispone de una tabla con la distancia entre los pares de ciudades en los que hay carreteras o un valor centinela (por ejemplo, -1) si no hay por lo que para ir de la ciudad inicial a la final es posible que haya que pasar por varias ciudades. También se conocen las coordenadas geográficas de cada ciudad y por tanto la distancia geométrica (en línea recta) entre cada par de ciudades. Se pretende acelerar la búsqueda de un algoritmo de ramificación y poda priorizando los nodos vivos (ciudades) que estén a menor distancia geográfica de la ciudad objetivo
O: El nuevo algoritmo siempre será más rápido.
O: Esta estrategia no asegura que se obtenga el camino más corto.
O: El nuevo algoritmo no garantiza que vaya a ser más rápido para todas las instancias del problema posibles.
A: 2

Q: La versión de Quicksort que utiliza como pivote la mediana del vector...
O: ... es más eficiente si el vector ya está ordenado
O: ... no presenta caso mejor y peor distinto para instancia del mismo tamaño
O: ... es la versión con mejor complejidad en el mejor de los casos.
A: 1

Q: Sea A un árbol binario de profundidad k con n nodos donde n = 2^k-1 este datos nos permite saber entre otras cosas que
O: III existen en el árbol todos lo nodos de nivel k
O: I el árbol es complejo
O: IV I, II y III conjuntamente
O: II el árbol es equilibrado
A: 2

Q: El recorrido en profundidad de un grafo G no dirigido ha producido el árbol que se muestra en el que cada nodo esta numerad siguiendo el orden de visita del recorrido en profundidad
```
     1
    /|\
   2 6 7
  /   
 3   
/ \
4 5
```
O: El nodo 6 es adyacente al nodo 4
O: Se trata de un grafo fuertemente conexo
O: El nodo 1 solo puede ser adyacente a los nodos 2,6 y 7
O: El nodo 2 puede ser adyacente al nodo 5 y el nodo 4 puede ser adyacente al nodo 1
O: El nodo 6 y 7 no son adyacente y el nodo 5 y el nodo 7 si lo son
A: 3

Q: ¿Cuál de estos conceptos pertenece a la misma categoría que divide y vencerás, vuelta atrás o ramificación y poda?
O: programación dinámica.
O: memoización.
O: cota optimista.
A: 0

Q: Se pretende resolver el problema del viajante de comercio (travelling salesman problem) mediante el esquema de vuelta atrás. ¿Cuál de los siguientes valores se espera que se comporte mejor como cota optimista para un nodo?
O: La suma de los pesos de las aristas que completan la solución paso a paso visitando el vértice más cercano al último visitado.
O: La suma de los pesos de las k aristas restantes más cortas, donde k es el número de ciudades que quedan por visitar.
O: El valor que se obtiene de multiplicar k por el peso de la arista más corta de entre las restantes, donde k es el número de ciudades que quedan por visitar.
A: 1

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
O: $\log(n^3) \not\in \Theta(\log_3(n))$
O: $\Theta(\log^2(n)) = \Theta(\log^3(n))$
O: $\Theta(\log_2(n)) = \Theta(\log_3(n))$
A: 2

Q: Se pretende resolver la versión general del problema del encaminamiento óptimo mediante la técnica "divide y vencerás", ¿se podría obtener la mejor disposición de las puertas?
O: No, ya que no se cumple la propiedad "subestructura óptima".
O: No, ya que no cumple el teorema de reducción.
O: Sí, pero a costa de una complejidad temporal prohibitiva.
A: 0

Q: Complejidad de 
```cpp
void f(int n, int arr[]) {
  int i = 0, j = 0;
  for (; i < n; ++i)
    while (j < n && arr[i] < arr[j])
      j++;
}
```
O: $O(n^2)$
O: $O(n \log n)$
O: $O(n)$
A: 2

Q: Una de estas afirmaciones es falsa. ¿Cuál es?
O: El algoritmo de Prim va construyendo un bosque de árboles que va uniendo hasta que acaba con un árbol de recubrimiento de coste mínimo.
O: El algoritmo de Kruskal se puede acelerar notablemente si los vértices se organizan en una estructura union-find.
O: El algoritmo de Prim se puede acelerar notablemente si se guarda, para cada vértice no visitado, los datos de la arista de mínimo peso que lo une a un vértice visitado.
A: 0

Q: En cuanto a la posibilidad de aplicar la técnica de programación dinámica iterativa para resolver un problema:
O: No necesariamente ha de conocerse de antemano todos los posibles subproblemas, pero sí debe saberse, dados dos de ellos cualesquiera, cuál es más pequeño.
O: Se debe conocer de antemano todos los posibles subproblemas pero no necesariamente se debe disponer de una ordenación entre todos ellos según tamaño.
O: Se debe conocer de antemano todos los posibles subproblemas y además, se debe disponer de una ordenación entre todos ellos según tamaño.
A: 2

Q: Al resolver el problema del viajante de comercio mediante vuelta atrás, ¿cuál de estas cotas optimistas se espera que pode mejor el árbol de búsqueda?
O: Se resuelve el resto del problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido.
O: Se ordenan las aristas restantes de menor a mayor distancia y se calcula la suma de las k aristas más cortas, donde k es el número de saltos que nos quedan por dar.
O: Se multiplica k por la distancia de la arista más corta que nos queda por considerar, donde k es el número de saltos que nos quedan por dar.
A: 1

Q: ¿Cuál es la diferencia principal entre una solución de vuelta atrás y una solución de ramificación y poda para el problema de la mochila?
O: El orden de exploración de las soluciones.
O: El coste asintótico en el caso peor.
O: El hecho de que la solución de ramificación y poda puede empezar con una solución subóptima voraz y backtracking no.
A: 0

Q: Dado un problema de optimización ¿cuándo se puede aplicar el método de vuelta atrás?
O: No solo es condición necesaria que el dominio de las decisiones sea discreto o discretizable, además debe cumplirse que se puedan emplear mecanismos de poda basados en la mejor solución hasta el momento.
O: Es condición necesaria (aunque no suficiente) que el dominio de las decisiones sea discreto o discretizable.
O: Es condición necesaria y suficiente que el dominio de las decisiones sea discreto o discretizable.
A: 1

Q: Tratandose de un esquema general para resolver problemas de minimizacion ¿que falta en el hueco? `Solution BB(Problem p) if(????????????)`
O: `n.optimistic_b() >= pb`
O: `n.pesimistic_b() <= pb`
O: `n.optimistic_b() <= pb`
A: 2

Q: ¿Qué complejidad se obtiene a partir de la relación de recurrencia $T(n) = 8T(n/2) + n^3$ con $T(1) = O(1)$?
O: $O(n \log n)$
O: $O(n^3 \log n)$
O: $O(n^3)$
A: 1

Q: ¿Qué nos proporciona la media aritmética entre el coste temporal asintótico (o complejidad temporal) en el peor caso y el coste temporal asintótico en el mejor caso?
O: En general, nada de interés.
O: El coste temporal asintótico en el caso medio.
O: El coste temporal promedio.
A: 2

Q: ¿Cuál es el caso peor del algoritmo de ordenación Quicksort que toma el primer elemento como pivote?
O: Cuando el elemento pivote queda siempre en medio.
O: Cuando el elemento pivote queda siempre en uno de los dos extremos.
O: Cuando debemos hundir el pivote hasta el fondo del montículo.
A: 1

Q: El problema de la moneda consiste a formar una suma M con el número mínimo de monedas tomadas (con repetición) de un conjunto C donde hay una cantidad suficientemente grande de monedas con cada posible valor facial $C = \{c_1, c_2, \ldots, c_k\}$, con $c_1 = 1$. ¿Cuál de estas afirmaciones sobre un algoritmo recursivo de la forma $n_{opt}(M) = 1 + \min_{1 \leq i \leq |C|} n_{opt}(M - c_i)$; $n_{opt}(0) = 0$; $n_{opt}(x) = \infty$ para $x < 0$ es falsa?
O: Dependiendo de cuáles sean los valores faciales y la suma, puede ser que el algoritmo recursivo no encuentre solución.
O: Encuentra siempre la solución óptima.
O: Tiene un coste temporal prohibitivo, ya que puede calcular $n_{opt}(x)$ para el mismo valor de x más de una vez.
A: 0

Q: Si $f1(n) \in{ Ο(g1(n))}$ y $f2(n) \in{ Ο(g2(n))}$ entonces:
O: $f1(n)+f2(n) \in{ Ο(maximo(g1(n),g2(n)))}$
O: $f1(n)+f2(n) \in{ Ο (g1(n)+g2(n))}$
O: Ambas son correctas
A: 2

Q: Si resolvemos un problema de optimización mediante el método de la vuelta atrás, ¿se puede usar, además de una cota optimista, una cota pesimista para reducir el número de soluciones exploradas?
O: No, porque las podas las determina la cota optimista, y lo hace independientemente de cuál sea el valor de la mejor solución en curso.
O: No. En el método de la vuelta atrás siempre es necesario visitar las hojas para actualizar la mejor solución en curso.
O: Sí. Aunque las cotas pesimistas no se hayan explicado en clase hasta llegar al tema de ramificación y poda, no hay ninguna razón que impida su uso en el método de la vuelta de atrás.
A: 2

Q: Que algoritmo es menos costoso para obtener el camino mínimo entre todos los pares de vértices de un grafo
O: Floyd tiene menor cota superior de coste que Dijkstra en este caso
O: Dijkstra es mas eficiente, puesto que tiene menor coste
O: Aplicar sucesivamente Dijkstra en este caso tiene igual cota superior de coste que aplicar Floyd
O: Calcular la matriz de cierre transitivo
O: Kruskal es el mas adecuado para lograr este objetivo
A: 2

Q: Un programa con dos bucles anidados, el primero hace n iteraciones y el segundo la mitad...
O: $O(n \log(n))$
O: $O(n\sqrt{n})$
O: $O(n^2)$
A: 2

Q: Dado un problema de minimización resuelto mediante un esquema de ramificación y poda, ¿qué ocurre si la cota optimista resulta ser un valor excesivamente pequeño?
O: Que se podría explorar menos nodos de los necesarios.
O: Que se podría explorar más nodos de los necesarios.
O: Que se podría podar el nodo que conduce a la solución óptima.
A: 2

Q: Con respecto a los algoritmos estudiados durante el curso que encuentran el árbol de recubrimiento de mínimo coste, de las afirmaciones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos.
O: El algoritmo de Kruskal va construyendo un bosque de árboles que va uniendo hasta que acaba con un árbol de recubrimiento de coste mínimo.
O: La complejidad temporal del algoritmo de Prim es cúbica con respecto al número de vértices del grafo.
O: El algoritmo de Prim se puede acelerar notablemente si los vértices se organizan en una estructura union-find.
A: 0

Q: Un problema de tamaño n puede transformarse en tiempo $O(n^2)$ en otro de tamaño n - 1. Por otro lado, la solución al problema cuando la talla es 1 requiere tiempo constante. ¿cuál de estas clases de coste temporal asintótico es la más ajustada?
O: $O(n^3)$
O: $O(2^n)$
O: $O(n^2)$
A: 0

Q: Para que la complejidad de un algoritmo presenta caso mejor y peor distintos...
O: ... es condicion necesaria que existan instancias distintas del problema con el mismo tamaño
O: es condicion suficiente que existan instancias distintas del problema con el mismo tamaño
O: ... es condicion necesaria y suficiente que existan instancias distintas del problema con el mismo tamaño
A: 0

Q: El recorrido en profundidad de un grafo G no dirigido ha producido el arbol que se muestra en la figura, en el que cada nodo esta numerado siguiendo el orden de visita del recorrido en profundidad: 
```
    1
   / \
  2   6
 / \   \
3   4   7
   /
  5
```
O: El nodo 2 puede ser adyacente al nodo 5, y el nodo 4 puede ser adyacente al nodo 1
O: El nodo 6 y 7 no son adyacentes y el nodo 5 y el nodo 7 si lo son
O: El nodo 1 solo puede ser adyacente a los nodos 2,6 y 7
O: El nodo 6 es adyacente al nodo 4
A: 0

Q: Se pretende borrar todos los elementos de un vector cuyo valor es un número par. Si el tamaño del vector es n, ¿con qué coste temporal asintótico se podría realizar esa operación?
O: $O(n)$
O: $O(n^2)$
O: Ninguna de las otras dos opciones es la correcta.
A: 0

Q: Supongamos que queremos hacer una copia de seguridad de nuestro ficheros mas importantes y para ello solo disponemos de un DVD+R grabable de 4.7Gb según esto tenemos n ficheros con distintos tamaños respectivamente y además nuestro DVD tiene capacidad máxima T se cumple que T< t1+t2+t3+...+tn
O: Para maximizar el numero de ficheros en DVD utilizaría un esquema de voraz
O: Para maximizar el numero de ficheros en DVD utilizaría un esquema de divide y vencerás
O: Para maximizar el numero de ficheros en DVD utilizaría un esquema backtracking
O: Para maximizar el numero de ficheros en DVD utilizaría un esquema de ramificación y poda
A: 0

Q: La siguiente relación de recurrencia expresa la complejidad de un algoritmo recursivo, donde g(n) es una función polinómica:$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 2T(n/2) + g(n) & \text{en otro caso} \end{cases}$Di cuál de las siguientes afirmaciones es falsa:
O: Si $g(n) \in O(1)$ la relación de recurrencia representa la complejidad temporal del algoritmo de búsqueda dicotómica.
O: Si $g(n) \in O(n^2)$ la relación de recurrencia representa la complejidad temporal del algoritmo de búsqueda por inserción.
O: Si $g(n) \in O(n)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación mergesort.
A: 1

Q: El problema del cambio es el de formar una suma M con el número mínimo de monedas tomadas (con repetición) de un conjunto C en el que el valor facial de la moneda de tipo i es $c_i$. ¿Cuál de las siguientes afirmaciones es falsa?
O: Una versión (memoizada) de la siguiente recursión da la solución óptima en caso de que exista: $n(M) = 1 + \min_{1 \leq i \leq |C|} n(M - c_i)$; $n(0) = 0$; $n(x) = \infty$ para $x < 0$
O: La solución voraz consistente en coger siempre la moneda de valor facial más grande de cuyo valor es menor que la cantidad M así: $n(M) = 1 + n(M - c^*)$ donde $c^* = \max\{c \in C \mid c \leq M\}$ puede no encontrar solución para cualquier M y C.
O: La solución voraz consistente en coger siempre la moneda de valor facial más grande de cuyo valor es menor que la cantidad M así: $n(M) = 1 + n(M - c^*)$ donde $c^* = \max\{c \in C \mid c \leq M\}$ encuentra siempre la solución óptima para cualquier M y C si existe dicha solución.
A: 2

Q: ¿Cuál es la complejidad temporal de la siguiente función recursiva?
```cpp
unsigned desperdicio(unsigned n) {
  if (n <= 1)
    return 0;
  unsigned sum = desperdicio(n / 2) + desperdicio(n / 2);
  for (unsigned i = 1; i <= n - 1; i++)
    for (unsigned j = 1; j <= i; j++)
      sum += 1;
  return sum;
}
```
O: Θ(n^2)
O: Θ(2^n)
O: Θ(n^2 log n)
A: 0

Q: Cuando tenemos un algoritmo backtracking
O: Cuando en un problema tenemos una cantidad de datos demasiad grande asi podemos hacer llamadas recursivas con una cantidad de datos mas pequeña
O: Ninguna de las anteriores son correctas
O: Las dos anteriores son correctas
O: Cuando debamos probar todas las combinaciones posibles para encontrar la solucion de un problema
A: 3

Q: La mejora que en general aporta la programación dinámica frente a la solución ingenua se consigue gracias al hecho de que...
O: ...en la solución ingenua se resuelve pocas veces un número relativamente grande de subproblemas distintos.
O: ...el número de veces que se resuelven los subproblemas no tiene nada que ver con la eficiencia de los problemas resueltos mediante programación dinámica.
O: ...en la solución ingenua se resuelve muchas veces un número relativamente pequeño de subproblemas distintos.
A: 2

Q: Si dos algoritmos tienen la misma complejidad asintótica:
O: No necesitan exactamente el mismo tiempo para su ejecución.
O: Necesitan exactamente el mismo tiempo para su ejecución.
O: Ninguna de las anteriores
A: 0

Q: La costa de un país tiene n núcleos de población, todos unidos por una línea costera de tren. La industria de cada núcleo de población $j$ produce $T_j$ toneladas de productos para la exportación y se encuentra en el kilómetro $k_j$ de la línea de tren. Las exportaciones son básicas para su economía y debe realizarse por mar ya que ha roto relaciones con los países con los que linda por tierra. El gobierno ha decidido promover el transporte marítimo y ha presupuestado la cantidad necesaria para construir p puertos de manera que se minimice el tráfico por la línea de tren. El tráfico es $\sum_{j=1}^{n} T_j |k_j - k_{s(j)}|$ donde $s(j)$ es el puerto de salida más cercano al núcleo $j$ ¿Es posible resolver el problema mediante una técnica de programación dinámica?
O: No. Debe resolverse usando una técnica de búsqueda y enumeración (vuelta atrás, ramificación y poda) ya que el problema no tiene subestructura óptima.
O: Sí. El problema goza de subestructura óptima: podemos resolver el problema asumiendo que conocemos la solución para las m primeras ciudades y para p - 1 puertos, determinar la posición óptima para que el puerto p sirva a las n - m ciudades restantes, y buscar la valor óptimo de m.
O: No, pero el problema tiene una solución voraz exacta que consiste en empezar por asignar puerto a todos los núcleos de población e ir quitando uno a uno los puertos de manera que el tráfico que resulte de quitarlos aumente lo mínimo posible.
A: 1

Q: Si el coste temporal de un algoritmo es T(n), ¿cuál de las siguientes situaciones es imposible?
O: $T(n) \in \Omega(n)$ y $T(n) \in \Theta(n^2)$
O: $T(n) \in O(n)$ y $T(n) \in \Theta(n)$
O: $T(n) \in \Theta(n)$ y $T(n) \in \Omega(n^2)$
A: 2

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
O: $O(n^2) \subset O(2^{\log_2 n})$
O: $n + n \log_2 n \in \Omega(n + n \log_2 n)$
O: $\Omega(n^2) \subset \Omega(n)$
A: 0

Q: La complejidad de la función TB es: 
```
función TB (A: vector[λ]; iz , de : N) : N 
var n,i:N; 
	n=iz-de+1 
	opcion 
		(n < 1) : devuelve ( 0 ) ; 
		(n = 1) : devuelve ( 1 ) ; 
		(n > 1) : si (A[iz] = A[de]) entonces 
				devuelve (TB( A, iz + 1, de - 1 ) + 1); 
			sino 
				devuelve (TB( A, iz + 1, de - 1 )) ; 
			finsi ; 
	fopcion 
fin
```
O: Θ (n)
O: Θ (n · lg n)
O: Θ (n^2 · lg n)
A: 0

Q: ¿Cuál de estos tres problemas de optimización no tiene una solución voraz que sea óptima?
O: El árbol de cobertura de coste mínimo de un grafo conexo.
O: El problema de la mochila discreta.
O: El problema de la mochila continua o con fraccionamiento.
A: 1

Q: Sea $f(n) = 2f(n/2) + 1$, $f(1) = 1$
O: $f(n) \in O(n \log(n))$
O: $f(n) \in O(n)$
O: $f(n) \in O(n^2)$
A: 1

Q: Existen dos algoritmos que para ordenar un vector de n elementos, buscan el máximo de esos n elementos, lo intercambian con el n-ésimo elemento para ponerlo al final, y luego ordenan, usando el mismo algoritmo, el vector de las primeras n - 1 componentes. ¿Cuál de las afirmaciones siguientes es cierta?
O: Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por burbuja o bubblesort; el primero tiene un coste temporal $O(n \cdot \log(n))$ y el segundo, $O(n^2)$.
O: Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por selección; el primero tiene un coste temporal $O(n \cdot \log(n))$ y el segundo, $O(n^2)$.
O: Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por selección; el primero tiene un coste temporal $O(n)$ y el segundo, $O(n^2)$.
A: 1

Q: La estrategia de RyP genera las soluciones posibles mediante...
O: un recorrido en profundidad del árbol que representa el espacio de soluciones
O: un recorrido guiado por estimaciones de las mejores ramas del árbol que representa el espacio de soluciones
O: un recorrido en anchura del árbol que representa el espacio de soluciones
A: 1

Q: $f(n) = \sqrt{n} + 3f(n/3)$
O: $f(n) \in O(n)$
O: $f(n) \in O(\sqrt{n} \log n)$
O: $f(n) \in O(n^3)$
A: 0

Q: De las siguientes situaciones, o bien dos son posibles y una no lo es, o bien al contrario, solo una es posible y las otras dos no lo son. Marca la que, en este sentido, es diferente a las demás.
O: $f(n) \in O(n)$ y $f(n) \in \Omega(n^2)$.
O: $f(n) \in O(n)$ y $f(n) \in \Omega(1)$.
O: $f(n) \in O(n)$ y $f(n) \in O(n^2)$.
A: 0

Q: Tenemos una lista ordenada de tamaño $n_o$ y una lista desordenada de tamaño $n_d$, queremos obtener una lista ordenada con todos los elementos, ¿Cual seria la complejidad de insertar uno a uno todos los elementos de la lista desordenada en la ordenada?
O: $O(n_o \times n_d + n_d^2)$
O: $O(n_d \times n_o)$
O: $O(n_d \log n_o)$
A: 0

Q: Cual es la complejidad de la función pertenece de un dato, en un árbol binario ordenado
O: $\Omega(1)$ y $O(n)$
O: $\Theta(\log n)$
O: $\Omega(1)$ y $O(n^2)$
O: Ninguna de las anteriores
A: 0

Q: Un problema de tamaño n puede transformarse en $O(n)$ en siete de tamaño n/7, por otro lado la solución al problema cuando la talla es 1 requiere tiempo constante ¿qué cota es más ajustada?
O: $O(n \log n)$
O: $O(n)$
O: $O(n^2)$
A: 0

Q: Dado un problema de optimización cualquiera, ¿la estrategia de vuelta atrás garantiza la solución óptima?
O: Es condición necesaria que el dominio de las decisiones sea discreto o discretizable y que el número de decisiones a tomar esté acotado.
O: Sí, siempre que el dominio de las decisiones sea discreto o discretizable y además se empleen mecanismos de poda basados en la mejor solución hasta el momento.
O: Sí, puesto que ese método analiza todas las posibilidades.
A: 0

Q: La programación dinámica, para resolver un problema, aplica la estrategia...
O: Se resuelven los problemas más pequeños y, combinando las soluciones, se obtienen las soluciones de problemas sucesivamente más grandes hasta llegar al problema original.
O: Se descompone el problema a resolver en subproblemas más pequeños, que se resuelven independientemente para finalmente combinar las soluciones de los subproblemas para obtener la solución del problema original.
O: Ninguna de las anteriores
A: 0

Q: La siguiente relacion de recurrencia expresa la complejidad de un algoritmo recursivo, donde g(n) es una funcion polinomica Cual es la definicion correcta de $\Omega(f)$
O: $\Omega(g) = \{f: \mathbb{N} \to \mathbb{R} \mid g(n) \leq cf(n)\}$
O: $\Omega(g) = \{f: \mathbb{N} \to \mathbb{R} \mid f(n) \leq cg(n)\}$
O: $O(g) = \{f: \mathbb{N} \to \mathbb{R} \mid g(n) \leq cf(n)\}$
A: 1

Q: La solución óptima al problema de encontrar el árbol de recubrimiento de coste mínimo par un grafo no dirigido, conexo y ponderado ...
O: ...puede construirlo tanto vértice a vértice como arista a arista
O: ...debe construirlo vértice a vértice: arista a arista no puede ser
O: ...debe construirlo arista a arista: vértice a vértice no puede ser
A: 0

Q: Indicad cuál de estas tres expresiones es falsa.
O: Θ(n / 2) = Θ(n)
O: Θ(n) ⊆ Θ(n^2)
O: Θ(n) ⊆ Θ(n)
A: 1

Q: ¿Con que algoritmo de ordenación clásico se corresponde el pseudocodigo del siguiente ejemplo?: 
```
módulo ordena ( var A es vector de n enteros);
variables i, j, x: es entero
for (i = 2; i<=N; i++) {
	X=A[i];
	A[0]=X;
	j=i-1;
	while ( X<A[j] ) { // (2)
		A[j+1]=A[j]; // (3) 
		j = j – 1
	}
	A[j+1]=X;
}
finmódulo
```
O: Ordenación por el método de la burbuja
O: Ordenación por el método de selección directa
O: Ordenación por el método de inserción directa
O: Ordenación por el método de inserción binaria
A: 2

Q: Un algoritmo recursivo basado en el esquema divide y vencerás ...
O: Las dos anteriores son verdaderas.
O: ... nunca tendrá un coste temporal asintótico exponencial.
O: ... alcanza su máxima eficiencia cuando el problema de tamaño n se divide en a problemas de tamaño n/a.
A: 2

Q: Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
  if (n < 2)
    return;
  for (int i = 0; i < pow(n, 2); i++)
    cout << "*";
  f(n - 2);
}
```
O: $\Theta(n^2 \log n)$
O: $\Theta(n^2)$
O: $\Theta(n^3)$
A: 2

Q: La complejidad en el mejor de los casos...
O: Las dos anteriores son ciertas
O: es una función de la talla, o tamaño del problema, que tiene que estar definida para todos los posibles valores de esta
O: es el tiempo que tarda el algoritmo en resolver la talla mas pequeña que se le puede presentar
A: 1

Q: El uso de funciones de cota en ramificación y poda...
O: ... transforma en polinómicas complejidades que antes eran exponenciales.
O: ... puede reducir el número de instancias del problema que pertenecen al caso peor.
O: ... garantiza que el algoritmo va a ser más eficiente ante cualquier instancia del problema.
A: 1

Q: Cuando la descomposición de los problemas da lugar a subproblemas de tamaño similar, ¿qué esquema promete ser más apropiado?
O: Programación dinámica
O: El metodo voraz
O: Divide y vencerás, siempre que se garantice que los problema no son del mismo tamaño
A: 0

Q: ¿Cuál es el coste temporal asintótico de la siguiente función?
```cpp
int f(int n) {
  int count = 0;
  for (int i = n; i > 0; i /= 2)
    for (int j = 0; j < 2 * i; j++)
      count += 1;
  return count;
}
```
O: $O(n)$
O: $O(n \log n)$
O: $O(n^2)$
A: 0

Q: Dado un problema de optimización, el método voraz...
O: garantiza la solución óptima sólo para determinados problemas
O: Siempre obtiene una solución factible
O: Siempre obtiene una solución óptima
A: 0

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
O: $\Omega(n^2) \subset \Omega(n^3)$
O: $\Theta(n^2) \subset \Theta(n^3)$
O: $O(n^2) \subset O(n^3)$
A: 2

Q: De los problemas siguientes, indicad cual no se puede tratar eficientemente como los otros dos:
O: El problema de cortar un tubo de forma que se obtenga el maximo beneficio posible.
O: El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores.
O: El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el minimo de monedas posibles.
A: 1

Q: Dado el algoritmo anterior y considerando como medida significativa el numero de comparaciones con respecto a la variable Min y Max. Entonces el numero de comparaciones medias viene determinado por la siguiente funcion
O: Tmed(n) = (log n)/2
O: Tmed(n) = (3/2)n
O: Tmed(n) = E^n (1/i -2(1+1i))
O: Tmed(n) = E^n (1/i+2(1-1/i))
A: 1

Q: Que tiene que valer b en la relacion de recurrencia $T(n) = 1$ si $n < 1$; $1+bT(n-1)$ si $n > 1$ para que $T(n) = 2^n$
O: 1
O: 2
O: 0
A: 1

Q: Supongamos que una solución recursiva a un problema de optimización muestra estas dos características: por un lado, se basa en obtener soluciones óptimas a problemas parciales más pequeños, y por otro, estos subproblemas se resuelven más de una vez durante el proceso recursivo. Este problema es candidato a tener una solución alternativa basada en ...
O: ... un algoritmo voraz.
O: ... un algoritmo de programación dinámica.
O: ... un algoritmo del estilo de divide y vencerás.
A: 1

Q: La complejidad temporal en el mejor de los casos...
O: ... es el tiempo que tarda el algoritmo en resolver el problema de tamaño o talla más pequeña que se le puede presentar.
O: Las dos opciones son ciertas.
O: ... es una función del tamaño o talla del problema que tiene que estar definida para todos los posibles valores de está.
A: 2

Q: ¿Qué tienen en común el algoritmo que obtiene el k-ésimo elemento más pequeño de un vector (estudiado en clase) y el algoritmo de ordenación Quicksort?
O: El número de llamadas recursivas que se hacen.
O: La combinación de las soluciones a los subproblemas.
O: La división del problema en subproblemas.
A: 2

Q: En los algoritmos de ramificación y poda...
O: Una cota optimista es necesariamente un valor insuperable, de no ser así se podría podar el nodo que conduce a la solución óptima.
O: Una cota pesimista es el valor que a lo sumo alcanza cualquier nodo factible que no es el óptimo.
O: Una cota optimista es necesariamente un valor alcanzable, de no ser así no está garantizando que se encuentre la solución óptima.
A: 0

Q: Decidid cuál de estas tres estrategias proveería la cota pesimista más ajustada al valor óptimo de la mochila discreta:
O: Completar las decisiones restantes basándose en la mejor solución voraz que pueda encontrarse para los restantes objetos y espacio disponible de la mochila.
O: Asumir que ya no se van a coger más objetos.
O: El valor de una mochila que contiene todos los objetos aunque se pase del peso máximo permitido.
A: 2

Q: ¿Cuál de los siguientes algoritmos de ordenación tiene menor complejidad?
O: Burbuja
O: Inserción directa
O: Mergesort
A: 2

Q: En cuanto a la complejidad temporal de la siguiente función, ¿cuál de las siguientes formulaciones expresa mejor su complejidad en el peor de los casos?
```cpp
int f(vector<int> &v) {
  int n = v.size(), i = 2, k = 0;
  while (i < n) {
    int j = i;
    while (v[j] != v[1]) {
      k++;
      j = j / 2;
    }
    i = i + 2;
  }
  return k;
}
```
O: $$c_s(n) = \sum_{k=1}^{\lfloor \frac{n-1}{2} \rfloor} \log_2 2k \in O(n \log n)$$
O: $$c_s(n) = \sum_{k=1}^{\lfloor \frac{n-1}{2} \rfloor} \log_2 2k^2 \in O(\log^2 n)$$
O: Las otras dos opciones son ambas falsas.
A: 0

Q: Dadas las siguientes funciones: //Precondicion: $0 <= i < v.size()$; $i < j <= v.size()$ Se quiere reducir la complejidad temporal usando programacion dinamica iterativa, cual seria la complejidad espacial
O: cuadratica
O: cubica
O: exponencial
A: 0

Q: ¿Para cuál de estos problemas de optimización existe una solución voraz?
O: El árbol de recubrimiento mínimo para un grafo no dirigido con pesos.
O: El problema de la mochila discreta.
O: El problema de la asignación de coste mínimo de n tareas a n trabajadores cuando el coste de asignar la tarea i al trabajador j, $c_{ij}$ está tabulado en una matriz.
A: 0

Q: El algoritmo que se describe a continuación calcula:
```
Función Ejercicio (ent A:ArbolBinarioGeneral):entero
variables Izq,Der: ArbolBinarioGeneral
inicio
	si NO A.Vacio entonces
		A.HijoIzq(Izq); A.HijoDer(Der);
		retorna(ejercicio(izq)+ejercicio(der)+1)
	si no
		retorna (0)
	finsi
fin
```
O: El nivel en el que se encuentra (hijo izquierdo + hijo derecho + 1) del árbol A
O: Cuantos niveles distintos tiene el árbol A
O: Ninguna de las anteriores
O: El numero de veces que aparece el hijo izquierdo y el derecho en el árbol A
O: El grado del árbol A
A: 2

Q: Marca la CORRECTA
O: $O(n^2) \subset O(2^{\log(n)}) \subset O(2^n)$
O: $O(n^2) \subset O(2^{\log(n)}) \subset O(2^n)$
O: $O(2^{\log(n)}) \subset O(n^2) \subset O(2^n)$
A: 2

Q: Si $f(n) \in O(n^2)$, ¿podemos decir siempre que $f(n) \in O(n^3)$?
O: Sí ya que $n^2 \in O(n^3)$.
O: No, ya que $n^2 \notin O(n^3)$.
O: Solo para valores bajos de n.
A: 0

Q: Cuando se usa un algoritmo voraz para abordar la resolución de un problema de optimización por selección directa (es decir, un problema para el cual la solución consiste en encontrar un subconjunto del conjunto de elementos que optimiza una determinada función) ¿Cuál de estas tres cosas es imposible que ocurra?
O: Que la solución no sea la óptima.
O: Que el algoritmo no encuentre ninguna solución.
O: Que se reconsidere la decisión ya tomada anteriormente respecto a la selección de un elemento a la vista de la decisión que se debe tomar en el instante actual.
A: 2

Q: Los algoritmos de programación dinámica hacen uso de...
O: que se puede ahorrar cálculos guardando resultados anteriores en un almacén
O: una estrategia trivial consistente en examinar todas las posibles soluciones
O: que la solución óptima se puede construir añadiendo a la solución el elemento óptimo de los elementos restante, uno a uno
A: 0

Q: Tenemos un conjunto de n enteros positivos y queremos encontrar el subconjunto de tamaño m de suma mínima.
O: Para encontrar la solución habría que probar con todas las combinaciones posibles de m enteros, con lo que la técnica de ramificación y poda no aporta nada con respecto a vuelta atrás.
O: Una técnica voraz daría una solución óptima.
O: Lo más adecuado sería usar una técnica de ramificación y poda, aunque en el peor caso el coste temporal asintótico (o complejidad temporal) sería exponencial.
A: 1

Q: Si queremos implementar una cola dinámica utilizando un único puntero entonces alguna de las siguientes alternativas consigue complejidad de todas las operaciones de TAD Cola sean constantes
O: si, cuando el puntero indique el final de la cola
O: no, siempre habrá alguna opción con complejidad lineal
O: si, utilizando una lista circular donde el puntero indica el frente de la cola y el sucesor de este fuese el elemento del final
O: si, utilizando una lista circular donde el puntero indica el final de la cola y el sucesor de este fuese el elemento del frente
A: 3

Q: Dada la solución recursiva al problema de encontrar el k-ésimo mínimo de un vector. Cada llamada recursiva, ¿cuántas nuevas llamadas recursivas genera?
O: una o ninguna
O: dos o ninguna
O: una o dos
A: 0

Q: Los algoritmos directos de ordenación, respecto de los indirectos:
O: Presentan una mayor complejidad temporal y sus tiempos de ejecución absolutos son mayores.
O: Presentan una menor complejidad temporal y sus tiempos de ejecución absolutos son menores.
O: Presentan una mayor complejidad temporal si bien sus tiempos de ejecución absolutos son menores.
A: 0

Q: Podemos detectar todos los vertices involucrados en ciclos dentro de un grafo dirigido inspeccionando el resultad de
O: algoritmo Prim
O: algoritmo Warshall
O: algoritmo Floyd
O: algoritmo Dijkstra
A: 1

Q: Calcula el numero de veces que se realiza la operación de escritura en la siguiente función siendo n el numero de elementos de la lista:
```cpp
Void imprime(Lista L) {
  DatosLista x;
  Lista Aux;
  Aux = L;
  while (!L.Vacia()) {
    x = L.Primero();
    cout << x;
    Aux.Resto();
    Imprime(Aux);
  }
}
```
O: n
O: n+1
O: 2n + 1
O: n-1
O: Ninguna de las anteriores
A: 0

Q: El esquema voraz...
O: Puede que no encuentre una solución pero si lo hace se garantiza que es la óptima.
O: Garantiza encontrar una solución a cualquier problema, aunque puede que no sea óptima.
O: Las otras dos opciones son ambas falsas.
A: 2

Q: La complejidad temporal en el mejor de los casos de un algoritmo recursivo...
O: ... coincide con el valor del caso base de la ecuación de la recurrencia que expresa la complejidad temporal del algoritmo
O: Las demás opciones son falsas
O: ... siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo
A: 1

Q: Un problema de tamaño $n$ puede transformarse en tiempo $O(\frac{n}{2})$ en nueve de tamaño $\frac{n}{3}$; por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante. ¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
O: $O(n \log n)$
O: $O(n^2 \log n)$
O: $O(n^2)$
A: 1

Q: Las soluciones factibles a un problema de optimización deben cumplir dos restricciones y queremos resolver el problema mediante vuelta atrás o ramificación y poda. ¿Cuál de las siguientes afirmaciones es cierta?
O: La cota optimista usada para podar nunca se puede basar en la relajación de ninguna de las restricciones que deben cumplir las soluciones factibles.
O: La cota optimista usada para podar se debe basar en relajar ambas restricciones simultáneamente.
O: La cota optimista usada para podar se puede basar en relajar una cualquiera de las dos restricciones.
A: 2

Q: Dado un problema de maximización resuelto mediante un esquema de ramificación y poda, ¿qué ocurre si la cota optimista resulta ser un valor excesivamente elevado?
O: Que se podría explorar menos nodos de los necesarios.
O: Que se podría explorar más nodos de los necesarios.
O: Que se podría podar el nodo que conduce a la solución óptima.
A: 1

Q: Se pretende implementar mediante programación dinámica iterativa la siguiente función recursiva:
```cpp
int f(int m, int n, int p, int *v) {
  if (n < 0)
    return 0;
  int aux = 0;
  if (v[n] <= m)
    aux = p + f(m - v[n], n - 1, p, v);
  return aux + f(m, n - 1, p, v);
}
```
¿Cuál sería la complejidad temporal del algoritmo iterativo?
O: $\Theta(m)$
O: $\Theta(m \cdot n)$
O: Ninguna de las otras dos opciones es la correcta.
A: 1

Q: La solución de programación dinámica iterativa del problema de la mochila discreta ...
O: ... calcula menos veces el valor de la mochila que la correspondiente solución de programación dinámica recursiva.
O: ... tiene la restricción de que los pesos de los objetos tienen que ser números discretos o discretizables.
O: ... tiene la restricción de que los valores de los objetos tienen que ser números discretos o discretizables.
A: 1

Q: Un fontanero tiene una jornada de Q cuartos de hora (es así como se organiza la agenda) y tiene C clientes. El trabajo del cliente i tarda qi cuartos de hora y el fontanero le cobra un precio pi. Es posible que no pueda atender todos los clientes en la jornada, que nunca puede alargar. Este problema tiene una solución bien conocida que permite elegir qué clientes visitar para que la suma cobrada al final de la jornada sea la máxima. ¿Qué podemos decir de esta solución?
O: Que la organización de la agenda en cuartos de hora permite obtener una solución de complejidad temporal $\Theta(QC)$ y complejidad espacial $\Theta(Q)$.
O: Que se ha de implementar forzosamente con un algoritmo de búsqueda y enumeración como el de vuelta atrás.
O: Que no se puede implementar con una solución de "divide y vencerás" con memoización.
A: 0

Q: Di cuál de estos tres algoritmos no es un algoritmo de divide y vencerás
O: Mergesort.
O: Algoritmo de Prim.
O: Quicksort.
A: 1

Q: La función test() procesa una lista de n elementos y devuelve un real. La definición de la función es recursiva. Primero descompone la lista en dos sublistas de la misma longitud usando un segmento de código que tiene una complejidad lineal con la longitud de la lista, y después envía una de las dos sublistas a test() para que la procese, hace una serie de operaciones, con el resultado y el retorno, de coste temporal constante. ¿Cuál es el coste temporal asintótico de la función test() en función de n?
O: $\Theta(n)$
O: $\Theta(n \log n)$
O: $\Theta(\log n)$
A: 2

Q: Una empresa tiene M referencias en su stock. Cada referencia $j \in [1,M]$ tiene un peso $p_j$ y un valor $v_j$ y dispone de $n_j$ unidades en su stock. Dispone de un solo camión en el que puede cargar como máximo un peso P. Indicad cuál de las tres funciones siguientes representa una posible solución voraz aproximada al problema de cargar el camión de manera que se transporte un valor máximo.
O: ```cpp
int f(const vector<int> &p, const vector<int> &v, const vector<int> &n, int P,
      int k) {
  if (k == 0 || P == 0)
    return 0;
  int num_objs = min(P / p[k - 1], n[k - 1]);
  return num_objs * v[k - 1] + f(p, v, n, P - num_objs * p[k - 1], k - 1);
}
```
O: ```cpp
int f(const vector<int> &p, const vector<int> &v, const vector<int> &n, int P,
      int k) {
  if (k == 0 || P == 0)
    return 0;
  int gain = 0;
  for (int num_objs = 0; num_objs <= n[k - 1]; num_objs++)
    gain = max(gain, f(p, v, n, P - num_objs * p[k - 1], k - 1));
  return gain;
}
```
O: ```cpp
int f(const vector<int> &p, const vector<int> &v, const vector<int> &n, int P,
      int k) {
  if (k == 0 || P == 0)
    return 0;
  int gain = 0;
  for (int num_objs = 0; num_objs <= 1; num_objs++)
    gain = max(gain, f(p, v, n, P - num_objs * p[k - 1], k - 1));
  return gain;
}
```
A: 0

Q: Cual seria la función de coste del algoritmo anterior en el caso medio
O: $T(N) = 3 + \sum_{i=1}^{\log N} 2$
O: $T(N) = 3 + c \cdot N$ siendo c una constante
O: $T(N) = 2 + \sum_{i=1}^{N} 3$
O: $T(N) = 3+ \sum_{j=1}^{N} 2$
A: 0

Q: De los problemas siguientes, indicad cuál no se puede tratar eficientemente como los otros dos:
O: El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el mínimo de monedas posibles.
O: El problema de cortar un tubo de forma que se obtenga el máximo beneficio posible.
O: El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores.
A: 2

Q: Si $$\lim_{n \to \infty} \left(\frac{f(n)}{n^2}\right) = 3$$, ¿cuál de estas afirmaciones es cierta?
O: $f(n) \in \Omega(n^3)$
O: $f(n) \in \Theta(n^3)$
O: Las otras dos opciones son ambas falsas.
A: 2

Q: Los algoritmos de Warshall, Prim y floyd son ejemplos de los siguientes esquemas algoritmicos
O: Warshall programación dinámica, Prim algoritmo voraz , Floyd algoritmo voraz
O: Warshall programación dinámica, Prim programación dinámica, Floyd algoritmo voraz
O: Warshall Algoritmo voraz, Prim programación dinámica, Floyd algoritmo voraz
O: Warshall: programación dinámica, Prim algoritmo voraz, Floyd programación dinámica
A: 3

Q: ¿Cual es la mejor complejidad espacial que se puede conseguir
O: $O(1)$
O: $O(y^2)$
O: $O(y)$
A: 2

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la posición central...
O: ...no presenta caso mejor y peor para instancias del mismo tamaño.
O: ...se comporta peor cuando el vector ya está ordenado.
O: ...se comporta mejor cuando el vector ya está ordenado.
A: 2

Q: El esquema de vuelta atrás...
O: Se puede aplicar a cualquier tipo de problema aunque el coste temporal es elevado.
O: Garantiza que encuentra la solución óptima a cualquier problema de selección discreta.
O: Las otras dos opciones son ambas verdaderas.
A: 2

Q: En el esquema de vuelta atrás, los mecanismos de poda basados en la mejor solución hasta el momento...
O: ... garantizan que no se va a explorar nunca todo el espacio de soluciones posibles.
O: ... pueden eliminar soluciones parciales que son factibles.
O: Las otras dos opciones son correctas.
A: 1

Q: Que algoritmo es mas rápido, quicksort o mergesort?
O: el mergesort es siempre más rápido
O: como su nombre indica, el quicksort
O: son los dos igual de rápidos: $O(n \log(n))$
A: 2

Q: Cuál es la complejidad temporal en función del tamaño del problema (n) de multiplicar dos matrices cuadradas?
O: $O(n^{3/2})$
O: $O(n^2)$
O: $O(n^3)$
A: 0

Q: En el siguiente problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n ¿Que deberia ir en lugar de XXXXXX? `void fill(price m[]) +cutrod(XXXXXX)`
O: `n-i, m, p`
O: `n-m[n], m, p`
O: `n, m[n]-1, p`
A: 0

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva:
```cpp
float f(unsigned x, int y) {
  if (y < 0)
    return 0;
  float A = 0.0;
  if (v1[y] <= x)
    A = v2[y] + f(x - v1[y], y - 1);
  float B = f(x, y - 1);
  return min(A, 2 + B);
}
```
¿Cuál es la mejor complejidad temporal que se puede conseguir?
O: $O(y)$
O: $O(x)$
O: $O(x \cdot y)$
A: 2

Q: Se desea encontrar el camino más corto entre dos ciudades. Para ello se dispone de una tabla con la distancia entre los pares de ciudades en los que hay carreteras o un valor centinela (por ejemplo, -1) si no hay, por lo que para ir de la ciudad inicial a la final es posible que haya que pasar por varias ciudades. Como también se conocen las coordenadas geográficas de cada ciudad se quiere usar la distancia geográfica (en línea recta) entre cada par de ciudades como cota para limitar la búsqueda en un algoritmo de vuelta atrás. ¿Qué tipo de cota sería?
O: Una cota pesimista.
O: Una cota optimista.
O: No se trataría de ninguna poda puesto que es posible que esa heurística no encuentre una solución factible.
A: 1

Q: ¿Cuál de las siguientes formulaciones expresa mejor la complejidad temporal, en función del parámetro n, de la siguiente función? (asumimos que n es potencia exacta de 2)
```cpp
int f(int n) {
  int k = 0;
  for (int i = 2; i <= n; i *= 2)
    for (int j = i; j > 0; j -= 2)
      k++;
  return k;
}
```
O: $\sum_{p=2}^{n/2} \frac{(p - 1)}{2}$
O: $\sum_{p=1}^{\log n} 2 \cdot (p - 1)$
O: $\sum_{p=1}^{\log n} 2^{p-1}$
A: 2

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición...
O: ...no presenta caso mejor y peor para instancias del mismo tamaño.
O: ...se comporta peor cuando el vector ya está ordenado.
O: ...se comporta mejor cuando el vector ya está ordenado.
A: 1

Q: Si $\lim_{n \to \infty} \frac{g(n)}{f(n)}$ resulta ser una constante positiva no nula, cuál de las siguientes expresiones NO puede darse?
O: $f(n) \in \Omega(g(n))$ y $g(n) \in \Omega(f(n))$
O: $g(n) \notin \Theta(f(n))$
O: $f(n) \in \Theta(g(n))$
A: 1

Q: Cuando se usa un algoritmo voraz para abordar la resolución de un problema de optimización por selección discreta (es decir, un problema para el cual la solución consiste en encontrar un subconjunto del conjunto de elementos que optimiza una determinada función), ¿cuál de estas tres cosas es imposible que ocurra?
O: Que la solución no sea la óptima.
O: Que el algoritmo no encuentre ninguna solución.
O: Que se reconsidere la decisión ya tomada anteriormente respecto a la selección de un elemento a la vista de la decisión que se debe tomar en un instante.
A: 2

Q: Una de las afirmaciones siguientes es cierta y las otras dos falsas. Indicad cuál es la falsa.
O: $O(n^n) \subset O(n!)$
O: La complejidad temporal de Quicksort es $O(n^2)$ y $\Omega(n \log n)$
O: $O(3^n) \subset O(2^n)$
A: 1

Q: Sea un problema de optimización por selección discreta, con restricciones, en el que se deben tomar n decisiones booleanas para optimizar un indicador, y se abordará mediante un método de búsqueda y enumeración (vuelta atrás, ramificación y poda). ¿Cuál de las siguientes afirmaciones es correcta?
O: La complejidad temporal será como mucho $O(n \cdot \log(n))$ porque en general basta con ordenar adecuadamente las decisiones para convertir cualquier problema de este tipo en un problema de complejidad temporal lineal.
O: Puede haber problemas para los que la complejidad será exponencial o peor; ninguna estrategia de poda puede garantizar que esto no va a ocurrir.
O: La complejidad temporal en el peor caso será $O(n^2)$ ya que se toman n decisiones binarias.
A: 1

Q: De las expresiones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos.
O: Si f no está en $\Omega(g)$ entonces $O(f)$ es igual a $\Omega(g)$
O: Si f está en $\Theta(g)$ entonces $O(f)$ es igual a $O(g)$
O: Si f está en $O(g)$ entonces g no está en $O(f)$
A: 1

Q: Si $f(n) \in O(n^3)$, ¿puede pasar que $f(n) \in O(n^2)$?
O: Solo para valores bajos de n.
O: Es perfectamente posible, ya que $O(n^2) \subset O(n^3)$.
O: No, porque $n^3$ "no incrementa" $O(n^2)$.
A: 1

Q: ¿En ramificación y poda, tiene sentido utilizar la cota optimista de los nodos como criterio para ordenar la lista de nodos vivos?
O: Sí, aunque no es una garantía de que sea una buena estrategia de búsqueda.
O: Sí, en el caso de que se ordene la lista de nodos vivos, siempre debe hacerse según el criterio de la cota optimista.
O: No, la cota optimista solo se utiliza para determinar si una n-tupla es prometedora.
A: 0

Q: $f(n) = 5n+5$ ¿ $f(n)$ pertenece a $O(n)$?
O: Si. El valor de c es 5 y el valor mínimo de n_0 es de 3
O: Si. El valor de c es 9 y el valor mínimo de n_0 es de 1
O: Si. El valor de c es 6 y el valor mínimo de n_0 es de 5
A: 2

Q: El coste temporal del algoritmo de ordenación por inserción es
O: $O(n \log n)$
O: $O(n^2)$
O: $O(n)$
A: 1

Q: De los algoritmos vistos en clase, cual se corresponde con el siguiente:
```cpp
for (i = 1; i <= n; i++) {
  X = V[i];
  Izq = 0;
  Der = i - 1;
  while (Izq <= Der) {
    Medio = (Izq + Der) / 2;
    if (X < V[Medio])
      Der = Medio - 1;
    else
      Izq = Medio + 1;
  }
  for (j = i - 1; j >= Izq; j--) {
    V[j + 1] = V[j];
  }
  V[Izq] = X;
}
```
O: Ordenación mediante el algoritmo de Quicksort
O: Ordenación mediante el algoritmo de selección directa
O: Ordenación mediante el algoritmo de inserción binaria
O: Ordenación mediante el algoritmo de la burbuja
A: 2

Q: Cual de las siguientes relaciones de recurrencia es la del algoritmo mergesort
O: $T(n) = n + 2T(n/2)$ para $n > 1$
O: $T(n) = n + T(n/2)$ para $n > 1$
O: $T(n) = n + T(n-1)$ para $n > 1$
A: 0

Q: Considera el siguiente algoritmo: Nos interesa medir cuantas veces se ejecuta nº 3 entonces el caso mejor se obtiene cuando
O: Cuando los datos vienen dispuestos en orden inverso, que se ejecuta del orden de $n^2$ veces
O: Cuando los datos vienen ordenados ascendentemente, que se ejecuta del orden de $n^2$ veces
O: Cuando los datos vienen ordenados ascendentemente, que se ejecuta del orden de n veces
O: Cuando los datos vienen ordenados ascendentemente, que se ejecuta 0 veces.
A: 3

Q: Cual de los siguientes recorridos sobre un montículo de máximos nos garantiza la obtención de sus elementos ordenados de manera descendente
O: Ninguna
O: InOrden
O: PostOrden
O: PreOrden
A: 0

Q: En ausencia de cotas optimistas y pesimistas, la estrategia de vuelta atrás...
O: ...no se puede usar para resolver problemas de optimización.
O: ...debe recorrer siempre todo el árbol.
O: ...no recorre todo el árbol si hay manera de descartar subárboles que representan conjuntos de soluciones no factibles.
A: 2

Q: Queremos resolver por vuelta atras el problema de las n reinas. El usar una buena cota optimista permitiria:
O: Muy probablemente, hacer que el programa vaya mas lento.
O: Muy probablemente, resolver el problema de forma mas rapida.
O: No es aplicable ese tipo de podas a este problema.
A: 2

Q: En una carrera de coches por el desierto uno de los principales problemas es el abastecimiento de gasolina. Un participante dispone de un mapa que le indica las distancias entre las gasolineras que hay en la ruta y cree que, parándose a repostar el menor número de veces posible, podrá ganar. Para ayudarle hay que diseñar un algoritmo que le sugiera en qué gasolineras debe hacerlo. Hay que tener en cuenta que hay una única ruta posible. De entre las estrategias que se citan, ¿cuál sería la eficiente para resolver el problema?
O: Programación dinámica.
O: Algoritmo voraz.
O: Ramificación y poda.
A: 1

Q: Cuando se resuelve el problema de la mochila discreta usando la estrategia de vuelta atrás, ¿puede ocurrir que se tarde menos en encontrar la solución óptima si se prueba primero a meter cada objeto antes de no meterlo?
O: Sí, pero solo si se usan cotas optimistas para podar el árbol de búsqueda.
O: Sí, tanto si se usan cotas optimistas para podar el árbol de búsqueda como si no.
O: No, ya que en cualquier caso se deben explorar todas las soluciones factibles.
A: 0

Q: Un informático quiere subir a una montaña y para ello decide que tras cada paso, el siguiente debe tomarlo en la dirección de máxima pendiente hacia arriba. Además, entenderá que ha alcanzado la cima cuando llegue a un punto en el que no haya ninguna dirección que sea cuesta arriba. ¿qué tipo de algoritmo está usando nuestro informático?
O: un algoritmo voraz.
O: un algoritmo de programación dinámica
O: un algoritmo divide y vencerás.
A: 0

Q: Si para resolver un mismo problema usamos un algoritmo de vuelta atrás y lo modificamos mínimamente para convertirlo en un algoritmo de ramificación y poda, ¿qué cambiamos realmente?
O: Cambiamos la función que damos a la cota pesimista.
O: La comprobación de las soluciones factibles: en ramificación y poda no es necesario puesto que sólo genere nodos factibles.
O: El algoritmo puede aprovechar mejor las cotas optimistas.
A: 2

Q: Dado el algoritmo de búsqueda binaria, supongamos que, en vez de dividir la lista de elementos en dos mitades del mismo tamaño, la dividamos en dos partes de tamaños 1/3 y 2/3. El coste de este algoritmo:
O: Es el mismo que el del original
O: Es mayor que el del original
O: Es menor que el del original
A: 1

Q: ¿Cuál es la relación de recurrencia que representa la complejidad en el peor caso del algoritmo de búsqueda del k-ésimo elemento más pequeño de un vector (estudiado en clase).
O: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n/2)+n & \text{en otro caso} \end{cases}$
O: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n/2)+n & \text{en otro caso} \end{cases}$
O: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n-1)+n & \text{en otro caso} \end{cases}$
A: 2

Q: Sea G un grafo dirigido y A+ la matriz de cierre transitivo entonces
O: Si A+[i,i] = 1 para algún valor de i significa que G es fuertemente conexo
O: Si A+[i,i] = 1 para algún valor de i G tiene al menos un ciclo partiendo de i
O: Si A+[i,i] = 1 para algún para todo i significa que G es fuertemente conexo
O: Si A+[i,i] = 1 para algún valor de i existe un ciclo hamiltoniano partiendo de i
A: 1

Q: Tengo que sumar una larga lista de n cantidades diferentes y se me ha ocurrido que una manera de ganar tiempo es la siguiente estrategia recursiva: parto la lista en dos sublistas iguales, calculo su suma por separado usando la misma técnica y luego sumo las dos cantidades. Cuando al partir una lista me quedo con una cantidad sólo, la suma es esa cantidad, y si me quedan cero cantidades, la suma es cero. ¿Gano tiempo, es decir, hago menos sumas?
O: No, en este caso el coste temporal es $\Theta(n \cdot \log(n))$.
O: No, ya que la complejidad temporal del método propuesto es la misma que la de sumar una a una las cantidades.
O: Sí, ya que en este caso el coste temporal se reduce a $\Theta(\log(n))$.
A: 1

Q: Dada una solución recursiva a un problema ¿Cómo podemos evitar la resolución de los mismos subproblemas muchas veces?
O: Resolver los subproblemas de mayor a menor y guardar su resultado en una tabla, inicializándola con los problemas pequeños.
O: Resolver los subproblemas de menor a mayor y guardar su resultado en una tabla, inicializándola con los problemas pequeños.
O: Resolver los subproblemas de mayor a menor y guardar su resultado en una tabla, inicializándola con los problemas más grandes.
A: 1

Q: ¿Cuál es la relación de recurrencia que representa la complejidad en el peor caso del algoritmo de búsqueda del k-ésimo elemento más pequeño de un vector (estudiado en clase).
O: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n/2)+1 & \text{en otro caso} \end{cases}$
O: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n/2)+n & \text{en otro caso} \end{cases}$
O: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n-1)+n & \text{en otro caso} \end{cases}$
A: 2

Q: Un fontanero tiene una jornada de Q cuartos de hora (es así como se organiza la agenda) y tiene C clientes. El trabajo del cliente i tarda $q_i$ cuartos de hora y el fontanero le cobra un precio $p_i$. Es posible que no pueda atender a todos los clientes en la jornada, que nunca puede de alargar. Este problema tiene una solución bien conocida que permite elegir qué clientes visitar para que la suma cobrada al final de la jornada sea la máxima. ¿Qué podemos decir de esta solución?
O: Que se ha de implementar forzosamente con un algoritmo de búsqueda y enumeración como el de vuelta atrás.
O: Que la organización de la agenda en cuartos de hora permite obtener una solución de complejidad temporal $\Theta(QC)$ y complejidad espacial $\Theta(Q)$.
O: Que no se puede implementar con una solución de "divide y vencerás" con memoización.
A: 1

Q: La solucion Optima al problema de encontrar el arbol de recubrimiento de coste minimo para un grafo no dirigido, conexo y ponderado
O: ... se construye haciendo crecer varios arboles que al final acaban injertados en un unico arbol.
O: ... puede construir un unico arbol que va creciendo o bien construir un bosque de arboles que al final se injenan en un unico arbol
O: ... se construye haciendo crecer un unico arbol.
A: 1

Q: ¿Cual de estas tres estrategias voraces obtiene un mejor valor para la mochila discreta?
O: Meter primero los elementos de mayor valor específico o valor por unidad de peso
O: Meter primero los elementos de mayor valor
O: Meter primero los elementos de menor peso
A: 0

Q: El coste temporal asintótico de insertar un elemento en un vector ordenado de forma que continúe ordenado es
O: $O(n)$
O: $O(\log n)$
O: $O(n^2)$
A: 0

Q: ¿Cual de los siguientes pares de problemas son equivalentes en cuanto al tipo de solución(óptima, factible, etc) aportada por el método voraz?
O: El fontanero diligente y mochila continua
O: El fontanero diligente y el problema del cambio
O: El fontanero diligente y asignación de tareas
A: 0

Q: Decid cual de estas tres es la cota optimista mas ajustada al valor optimo de la mochila discreta:
O: el valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor especifico de los objetos
O: el valor de una mochila que contiene todos los objetos aunque se pase del peso maximo
O: el valor de la mochila continua correspondiente
A: 2

Q: Se desea obtener todas las permutaciones de una lista compuesta por n elementos. ¿Qué esquema es el más adecuado?
O: Ramificación y poda, puesto que con buenas funciones de cota es más eficiente que vuelta atrás.
O: Divide y vencerás, puesto que la división en sublistas se podría hacer en tiempo constante.
O: Vuelta atrás, es el esquema más eficiente para este problema.
A: 2

Q: ¿Para cuál de estos problemas de optimización se conoce una solución voraz?
O: El problema de la asignación de coste mínimo de n tareas a n trabajadores cuando el coste de asignar la tarea i al trabajador j, $c_{ij}$ está tabulado en una matriz.
O: El árbol de recubrimiento mínimo para un grafo no dirigido con pesos.
O: El problema de la mochila discreta.
A: 1

Q: Los algoritmos de vuelta atrás que hacen uso de cotas optimistas generan las soluciones posibles al problema mediante...
O: ...un recorrido guiado por una cola de prioridad de donde se extraen primero los nodos que representan los subárboles más prometedores del espacio de soluciones.
O: ...un recorrido guiado por estimaciones de las mejores ramas del árbol que representa el espacio de soluciones.
O: ...un recorrido en profundidad del árbol que representa el espacio de soluciones.
A: 2

Q: ¿Qué complejidad se obtiene a partir de la relación de recurrencia $T(n) = 9T(n/3) + n^3$ con $T(1) = O(1)$?
O: $O(n^3 \log n)$
O: $O(n \log n)$
O: $O(n^3)$
A: 2

Q: Di cuál de estos resultados de coste temporal asintótico es falsa:
O: La ordenación de un vector usando el algoritmo Quicksort requiere en el peor caso un tiempo en $O(n^2)$
O: La ordenación de un vector usando el algoritmo Mergesort requiere en el peor caso un tiempo en $O(n^2)$
O: La búsqueda binaria en un vector ordenado requiere en el peor caso un tiempo en $O(\log n)$
A: 1

Q: En la solucion al problema de la mochila continua ¿por que es conveniente la ordenacion previa de los objetos?
O: Para reducir la complejidad temporal en la toma de cada decision: de $O(n^2)$ a $O(n \log n)$, donde n es el numero de objetos a considerar.
O: Porque si no se hace no es posible garantizar que la toma de decisiones siga un criterio voraz
O: Para reducir la complejidad temporal en la toma de cada decision: de $O(n)$ a $O(1)$, donde n es el numero de objetos a considerar.
A: 2

Q: Si n es el número de elementos del vector, el coste del algoritmo Mergesort es:
O: $O(n^2)$ y $\Omega(n \log n)$
O: $\Theta(n \log n)$
O: $\Theta(n^2)$
A: 1

Q: Decid cuál de estas tres es la cota pesimista más ajustada al valor óptimo de la mochila discreta:
O: El valor de una mochila que contiene todos los objetos restantes aunque se pase del peso máximo permitido.
O: El valor de la mochila continua correspondiente.
O: El valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor específico de los objetos.
A: 2

Q: Cual de estas tres estrategias voraces obtiene un mejor valor para la mochila discreta
O: Meter primero los elementos de menor peso
O: Meter primero los elementos de mayor valor
O: Meter primero los elementos de mayor valor específico o valor por unidad de peso
A: 2

Q: Se dispone de un conjunto de n valores numéricos dispuestos en forma de montículo y se desea obtener el valor de la suma de todos los que al menos tienen un hijo (es decir, no son nodos hoja). ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
O: $O(\log n)$
O: $O(n \log n)$
O: $O(n)$
A: 2

Q: Con respecto al esquema Divide y venderás, ¿es cierta la siguiente afirmación?
O: Sí, siempre, en divide y vencerás la complejidad temporal depende únicamente del tamaño de los problemas
O: No, nunca, pues que también hay que añadir el coste de la división en subproblemas y la posterior combinación
O: No tiene porqué, la complejidad no depende únicamente del tamaño resultante de los subproblemas
A: 2

Q: Cuando la descomposición recursiva de un problema da lugar a subproblemas de tamaño similar, ¿qué esquema promete ser más apropiado?
O: Programación dinámica.
O: Divide y vencerás, siempre que se garantice que los subproblemas no son del mismo tamaño.
O: Voraz.
A: 0

Q: Cuando se usan cotas pesimistas para hacer podas en algoritmos de optimización basados en búsqueda y enumeración (por ejemplo, vuelta atrás o ramificación y poda)...
O: ...siempre se obtienen cuando se visitan las hojas del árbol de búsqueda.
O: ...se pueden obtener sin visitar necesariamente las hojas del árbol de búsqueda.
O: ...es posible que no encontremos la solución óptima.
A: 1

Q: ¿Cuál de las siguientes formulaciones expresa mejor la complejidad temporal, en función del parámetro n, de la siguiente función? (asumimos que n es potencia exacta de 2)
```cpp
int f(int n) {
  int k = 0;
  for (int i = 2; i <= n; i *= 2)
    for (int j = i; j > 0; j -= 2)
      k++;
  return k;
}
```
O: $\sum_{p=1}^{\log n} 2 \cdot (p - 1)$
O: $\sum_{p=1}^{\log n} 2^{(p - 1)}$
O: $\sum_{p=2}^{n/2} \frac{(p - 1)}{2}$
A: 1

Q: Tenemos un vector ordenado y queremos comprobar si contiene un elemento dado ¿Cual sera la complejidad temporal mas ajustada para hacerlo?
O: El tamaño del vector
O: Constante con el tamaño del vector
O: El logaritmo del tamaño del vector
A: 2

Q: En RyP
O: cada nodo tiene su propia cota pesimista, la optimista sin embargo, es común a todos los nodos
O: cada nodo tiene su propia cota optimista, la pesimista sin embargo, es común a todos los nodos
O: cada nodo tiene su propia cota optimista y pesimista
A: 2

Q: Se desea obtener todas las permutaciones de una lista compuesta por n elementos. ¿Que esquema es el mas adecuado?
O: divide y venceras, puesto que la division en sublistas se podria hacer en tiempo constante
O: vuelta atras, es el esquema mas eficiente para este problema
O: ramificacion y poda, puesto que con buenas funciones de cota es mas eficiente que vuelta atras
A: 1

Q: Una empresa de transportes dispone de M vehículos para repartir N paquetes, todos al mismo destino. Cada paquete i tiene un peso $P_i$ y se tiene que entregar antes de que transcurra un tiempo $TP_i$. Por otro lado, cada vehículo j puede transportar una carga máxima $C_j$, tarda un tiempo $TV_j$ para llegar al destino y consume una cantidad $L_j$ de litros de combustible, independientemente de la carga que transporta. Imaginad un algoritmo de vuelta atrás que obtenga la manera en que se tienen que transportar los objetos (en qué vehículo j tiene que ir cada objeto i) para que el consumo sea el mínimo. ¿Cuál sería una buena cota optimista?
O: La solución voraz del problema de cargar cada paquete en el camión de menor consumo donde cada paquete llega a tiempo, sin tener en cuenta si el camión se sobrecarga o no.
O: Ambas son cotas optimistas válidas.
O: La solución voraz del problema de cargar cada paquete en el camión de menor consumo, sin sobrecargarlo, sin tener en cuenta si el paquete llega a tiempo o no.
A: 1

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Si T no es muy grande con respecto a n ¿Cuál de los siguientes esquemas algorítmicos resultaría más eficiente para resolverlo?
O: Vuelta atrás.
O: Un algoritmo voraz.
O: Programación dinámica.
A: 2

Q: Si ante un problema de decisión existe un criterio de selección voraz entonces...
O: la solución óptima está garantizada
O: Ninguna de las otras dos es cierta
O: al menos una solución factible está garantizada
A: 1

Q: Sea A un array ordenado de n enteros que se vuelca en un árbol binario ordenado, y sea x un entero a buscar dentro del árbol binario. Entonces, la complejidad de ese algoritmo de búsqueda es:
O: Depende del algoritmo de volcado. Sera lineal si A se vuelca de forma lineal, y logarítmica si se sigue un algoritmo puro de back tracking para localizar el elemento x dentro del árbol.
O: Depende del algoritmo de volcado del array. Sera lineal A si se vuelca de forma lineal, y logarítmica si se sigue una estrategia divide y vencerás, tomando como pivote A[N/2].
O: Es independiente del algoritmo de volcado del array. Siempre es logarítmica, pues en una búsqueda de ABO siempre tenemos una ecuación de recurrencia de la forma T(n)=(n/2)+1;T(1)=O(1), que al resolverla nos proporciona una complejidad logarítmica.
O: Depende del algoritmo de volcado. Si empieza desde el final será logarítmica y si empieza desde el principio será lineal.
A: 1

Q: En un algoritmo de ramificación y poda, si la lista de nodos vivos no está ordenada de forma apropiada...
O: ...podría ocurrir que se exploren nodos de forma innecesaria.
O: ...podría ocurrir que se pode el nodo que conduce a la solución óptima.
O: ...podría ocurrir que se descarten nodos factibles.
A: 0

Q: Un problema de tamaño n puede transformarse en tiempo $O(n^2)$ en nueve de tamaño n/3, por otro lado la solución al problema cuando la talla es 1 requiere un tiempo constante, ¿cuál de estas clases de coste temporal asintótico es la más ajustada?
O: $O(n \log n)$
O: $O(n^2 \log n)$
O: $O(n^2)$
A: 1

Q: Si $f \notin O(g_1)$ y $f \in O(g_2)$ entonces NO siempre se cumplira
O: $f \in O(\max(g_1,g_2))$
O: $f \in \Omega(g_1+g_2)$
O: $f \in \Omega(\min(g_1,g_2))$
A: 1

Q: La complejidad temporal en el mejor de los casos de un algoritmo recursivo
O: coincide con el valor del caso base de la ecuación de recurrencia
O: Las demás son falsas
O: siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo
A: 1

Q: Sea un vector de n elementos y supongamos que todos los elementos de a son distintos, considera el siguiente algoritmo. Si consideramos como medida significativa el numero de comparaciones con respecto de los elementos del vector, entonces el algoritmo tiene una complejidad:
```
función Ordena (ent/sal a:vector): nada
	variables: i,j,temp: entero
	inicio
		para i de 0 a n-2 hacer
			para j de n-1 a i+1 incr-1 hacer
				si a[j-1]>a[j] entonces
					temp← a[j]
					a[j]← a[j-1]
					a[j-1]← temp
				finsi
			finpara
		finpara
	fin
```
O: $\Omega(n)$ y $O(n^2)$
O: $\Theta(n^2)$
O: $\Omega(1)$ y $O(n^2)$
O: $\Theta(n)$
A: 1

Q: ¿Cuál de los siguientes algoritmos proveería una cota pesimista para el problema de encontrar el camino más corto entre dos ciudades (se supone que el grafo es conexo)?
O: Calcular la distancia geométrica (en línea recta) entre la ciudad origen y destino.
O: Calcular la distancia recorrida moviéndose al azar por el grafo hasta llegar (por azar) a la ciudad destino.
O: Para todas las ciudades que son alcanzables en un paso desde la ciudad inicial, sumar la distancia a dicha ciudad y la distancia geométrica hasta la ciudad destino.
A: 1

Q: ¿Qué complejidad tiene la siguiente función?
```cpp
void f(vector<int> &A) {
  priority_queue<int> pq(begin(A), end(A));
  A.clear();
  while (!pq.empty()) {
    A.push_back(pq.top());
    pq.pop();
  }
}
```
Suponed que la cola de prioridad está implementada como un heap y que n = A.size(). `priority_queue<int> pq(begin(A), end(A))` construye un heap a partir de los datos que hay en el vector A.
O: $\Theta(n^2)$
O: $\Theta(n)$
O: $\Theta(n \log n)$
A: 2

Q: Marca la falsa
O: $n + n \log(n) \in \Omega(n)$
O: $2n^2 + 3n + 1 \in O(n^3)$
O: $n + n \log(n) \in \Theta(n)$
A: 2

Q: El problema de la moneda consiste en formar una suma M con el número mínimo de monedas tomadas (con repetición) de un conjunto C donde hay una cantidad suficientemente grande de monedas con cada posible valor facial $C = \{c_1, c_2, \ldots, c_k\}$, con $c_1 = 1$. ¿Cuál de estas afirmaciones sobre un algoritmo recursivo de la forma $nOPT(M) = 1 + \min nOPT(M-c_i)$; $nOPT(0) = 0$; $nOPT(x) = \infty$ para $x < 0$ es falsa?
O: Tiene un coste temporal prohibitivo, ya que puede calcular $nOPT(x)$ para el mismo valor de x más de una vez.
O: Dependiendo de cuáles sean los valores faciales y la suma, puede ser que el algoritmo recursivo no encuentre solución.
O: Encuentra siempre la solución óptima.
A: 1

Q: La versión de Quicksort que utiliza como pivote la mediana del vector...
O: ... no presenta caso mejor y peor distintos para instancias del mismo tamaño.
O: ... es más eficiente si el vector ya está ordenado.
O: ... es la versión con mejor complejidad en el mejor de los casos.
A: 0

Q: Un grafo es una estructura formada por el par (V, E) donde
O: V es el conjunto de vértices y E es una matriz
O: V es el conjunto de vértices del grafo y E un conjunto de arcos
O: Todas las anteriores son correctas
O: V es el conjunto de vértices y E un conjunto de arcos
O: V es un vector y E es una lista de vértices adyacentes
A: 2

Q: Utilizaremos una estructura de cola en aquellas aplicaciones que requieran un tratamiento en el que los datos
O: debamos procesarlos en orden inverso a como se obtienen y puedan repetirse
O: debamos procesarlos en el mismo orden en el que se obtienen y no puedan repetirse
O: se insertan y se extraigan por un único punto, y deban estar ordenados
O: debamos procesarlos en el mismo orden en el que se obtienen y puedan repetirse
A: 3

Q: Si $f(n) \in \Omega(g(n))$ entonces:
O: $\exists c, n_0 \in \mathbb{R}^+ : f(n) \geq c \cdot g(n) \forall n \geq n_0$
O: $\exists c, n_0 \in \mathbb{R}^+ : f(n) \geq c \cdot g(n) \forall n$
O: $\exists c, n_0 \in \mathbb{R}^+ : f(n) \leq c \cdot g(n) \forall n \geq n_0$
A: 0

Q: De las siguientes tres afirmaciones, una es cierta y dos falsas, o bien una es falsa y dos son ciertas. Marca la que en ese sentido es diferente a las otras dos.
O: Ramificación y poda sirve para resolver problemas que vuelta atrás no puede.
O: Ramificación y poda siempre es más eficiente que vuelta atrás.
O: Ramificación y poda resuelve el mismo tipo de problemas que vuelta atrás.
A: 0

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
O: ... Las dos anteriores son ciertas.
O: ... será más eficiente cuanto más equitativa sea la división en subproblemas.
O: ... nunca tendrá una complejidad exponencial.
A: 1

Q: Dadas las siguiente ecuaciones de recurrencia determinar el orden al que pertenecen cada una de ellas: $T_1(n)=2T_1(n/2)+c_1$, $T_2(n)=T_2(n-1) + n + c_2$, $T_3(n) = cT_3(n-1)+c_3$, $T_4(n) = T_4(n-1)+c_4$
O: $T_1(n) \in O(n)$, $T_2(n) \in O(n^2)$, $T_3(n) \in O(c^n)$ y $T_4(n) \in O(n)$
O: $T_1(n) \in O(n)$, $T_2(n) \in O(n)$, $T_3(n) \in O(n^2)$ y $T_4(n) \in O(n^2)$
O: $T_1(n) \in O(\log n)$, $T_2(n) \in O(2^n)$, $T_3(n) \in O(c^n)$ y $T_4(n) \in O(n)$
O: $T_1(n) \in O(\log n)$, $T_2(n) \in O(n^2)$, $T_3(n) \in O(n)$ y $T_4(n) \in O(n)$
A: 0

Q: En los algoritmos de ramificación y poda...
O: Una cota pesimista es el valor que a lo sumo alcanza cualquier nodo factible que no es el óptimo.
O: Una cota optimista es necesariamente un valor insuperable, de no ser así se podría podar el nodo que conduce a la solución óptima.
O: Una cota optimista es necesariamente un valor alcanzable, de no ser así no está garantizado que se encuentre la solución óptima.
A: 1

Q: ¿Qué nos proporciona la media entre el coste temporal asintótico (o complejidad temporal) en el peor caso y el coste temporal asintótico en el mejor caso?
O: El coste temporal asintótico en el caso medio.
O: El coste temporal promedio.
O: Nada de interés.
A: 2

Q: Indica cual es la complejidad, en función de n, del fragmento siguiente:
```cpp
int a = 0;
for (int i = 0; i < n; i++)
  for (int j = i; j > 0; j /= 2)
    a += a[i][j];
```
O: O(n log n)
O: O(n)
O: O(n^2)
A: 0

Q: Marca la FALSA
O: $\Theta(n/2) = \Theta(n)$
O: $\Theta(n) \subset \Theta(n^2)$
O: $\Theta(n) \subset O(n)$
A: 1

Q: ¿Cuál es la complejidad, en función de n, del siguiente fragmento: (suponed que A está definido como `vector<int>A(n)` y `sort()` es la función de ordenación de la librería estándar de C++, que tiene la mejor complejidad, temporal y espacial, posible para un algoritmo de ordenación de propósito general.)
```cpp
std::sort(begin(A), end(A));
int acc = 0;
for (auto i : A)
  acc += i;
```
O: $\Theta(n \log n)$
O: $\Theta(n^2)$
O: $\Theta(n)$
A: 0

Q: Tenemos un "superprocesador" que tiene una instrucción que permite la ordenación de 100 elementos en un tiempo constante. Para este superprocesador, adaptamos el algoritmo Mergesort de forma que cada vez que queremos ordenar menos de 100 elementos, en lugar de hacer las llamadas recursivas, llama a esta instrucción. ¿cuál sería la complejidad de este algoritmo?
O: $O(n \cdot \log(n))$
O: $O(n)$
O: $O(1)$
A: 0

Q: La complejidad de la función A2 es: 
```
Funcion A2 (n, a: entero):entero; 
Var r: entero; fvar 
	si (a² > n) devuelve 0 
	sino 
		r:= A2(n, 2a); 
		opción 
			n < a²: devuelve r; 
			n ≥ a² : devuelve r + a; 
		fopción 
	fsi 
fin
```
O: $O(\sqrt{n} · a)$
O: $O( \sqrt{n} / a)$
O: $O( n / \sqrt{a} )$
A: 1

Q: Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
  if (n < 1)
    return;
  for (int i = 0; i < n; i++)
    for (int j = 0; j < n; j++)
      for (int k = 0; k < n; k++)
        cout << "*";
  for (int i = 0; i < 8; i++)
    f(n / 2);
}
```
O: $\Theta(n^2 \log n)$
O: $\Theta(n^3 )$
O: $\Theta(n^3 \log n)$
A: 2

Q: Para que la complejidad de un algoritmo presenta caso mejor y peor distintos...
O: ... es condición necesaria y suficiente que existan instancias distintas del problema con el mismo tamaño
O: ... es condición suficiente que existan instancias distintas del problema con el mismo tamaño
O: ... es condición necesaria que existan instancia distintas del problema con el mismo tamaño
A: 2

Q: El coste asociado a la siguiente ecuación de recurrencia es: $f(n) = \begin{cases} 1 & n \leq 1 \\ n + f(\frac{n}{2}) + f(\frac{n}{2}) & n > 1 \end{cases}$
O: Θ(n lg n^2)
O: Θ(n^2 lg n)
O: Θ(n lg n)
A: 2

Q: Se pretende calcular el valor $2^n$, $n \in \mathbb{N}$, haciendo una transcripción literal de la expresión $$2^n = 1 + \sum_{i=0}^{n-1} \prod_{j=1}^i 2$$. ¿Cuál sería la complejidad temporal asintótica, en función de n, del algoritmo resultante?
O: $O(2^n)$
O: $O(n^2)$
O: $O(n)$
A: 1

Q: Indica cuál es la complejidad, en función de $n$, del fragmento siguiente:
```cpp
for (int i = n; i > 0; i /= 2)
  for (int j = n; j > 0; j /= 2)
    a += A[i][j];
```
O: $O(\log^2(n))$
O: $O(n \log(n))$
O: $O(n^2)$
A: 0

Q: Dada la suma de la recurrencia:$T(n) = \begin{cases} 1 & n = 0 \\ \sum_{k=0}^{n-1} T(k) & n > 0 \end{cases}$¿cuál de las siguientes afirmaciones es cierta?
O: $T(n) \in \Theta(n^2)$
O: $T(n) \in \Theta(2^n)$
O: $T(n) \in \Theta(n!)$
A: 1

Q: Sea G un grafo no dirigido valuado con etiquetas positivas y conexo entonces los algoritmos Prim y kruskal aplicados sobre el grafo G
O: Darían el mismo resultado independientemente de como fueran las etiquetas del grafo G
O: Darían el mismo resultado si todas las etiquetas del grafo G fueran distintas
O: Siempre obtendrían resultados distintos
O: Darían el mismo resultado solo si hubiera etiquetas con el mismo valor en el grafo G
A: 1

Q: ¿Qué obtenemos con la siguiente declaración de C++: `priority_queue<nodo> pq;` ?
O: Un heap o montículo de mínimos.
O: Un heap o montículo sin orden establecido ya que no se ha definido la función de comparación.
O: Un heap o montículo de máximos.
A: 2

Q: Una de las siguientes afirmaciones es falsa. ¿Cuál?
O: $O(2^n) = O(3^n)$
O: $O(n \log n) \subseteq O(n^2)$
O: $O(n^2 + 2n + 1) = O(n^2)$
A: 0

Q: Queremos resolver mediante vuelta atrás el problema de las 8 reinas (colocar 8 reinas en un tablero de ajedrez de manera que no se maten mutuamente). Una buena cota optimista permitiría:
O: Muy probablemente, resolver el problema de forma más rápida.
O: No es aplicable este tipo de podas a este problema.
O: Muy probablemente, explorar menos nodos.
A: 2

Q: Un programa con dos bucles anidados uno dentro del otro, El primero hace $n$ iteraciones aproximadamente y el segundo la mitad, tarda un tiempo
O: $O(n \log{n})$
O: $O(n^2)$
O: $O(n \sqrt{n})$
A: 1

Q: La eficiencia de los algoritmos voraces se basa en...
O: ...el hecho de que las decisiones tomadas no se reconsideran.
O: ...el hecho de que, con antelación, las posibles decisiones se ordenan de mejor a peor.
O: ...en el esquema voraz no se puede hablar de eficiencia puesto que a menudo no resuelve el problema.
A: 0

Q: Un tubo de n centímetros de largo se puede cortar en segmentos de 1 ctm., 2 ctm, etc. Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es la que más ingresos nos producirá. Se quiere resolver el problema mediante vuelta atrás ¿cuál sería la forma más adecuada de representar las posibles soluciones?
O: Una tabla que indique, para cada posición donde se va a cortar, cada uno de los posibles valores acumulados.
O: Un vector de booleanos.
O: Un par de enteros que indiquen los cortes realizados y el valor acumulado.
A: 1

Q: La solución recursiva ingenua a un determinado problema de optimización muestra estas dos características: por un lado, se basa en obtener soluciones óptimas a problemas parciales más pequeños y por otro, estos subproblemas se resuelven más de una vez durante el proceso recursivo. Este problema es candidato a tener una solución alternativa basada en...
O: Un algoritmo del estilo de divide y vencerás.
O: Un algoritmo voraz.
O: Un algoritmo de programación dinámica.
A: 2

Q: El coste temporal del algoritmo de ordenación por inserción es
O: $O(n \log(n))$
O: $O(n^2)$
O: $O(n)$
A: 1

Q: ¿Cuál de estos problemas tiene una solución eficiente utilizando programación dinámica?
O: El problema del cambio.
O: La mochila discreta con pesos y valores reales positivos.
O: El problema de la asignación de tareas.
A: 2

Q: ¿Qué esquema algorítmico utiliza el algoritmos de ordenación Quicksort?
O: Divide y Vencerás
O: Programación Dinámica
O: Backtracking
A: 0

Q: Se pretende calcular el valor $2^n$, $n \in \mathbb{N}$, haciendo una transcripción literal de la expresión de la imagen. ¿Cuál sería la complejidad temporal asintótica, en función de n, del algoritmo resultante? $$2^n = 1 + \sum_{i=0}^{n-1} \prod_{j=1}^{i} 2$$
O: $O(n)$
O: $O(2^n)$
O: $O(n^2)$
A: 2

Q: Sea n el numero de elementos que contienen los vectores w y v, ¿cual es la complejidad temporal asintotica en funcion de n asumiendo que la llamada inicial i toma valor n? `float f(vector<float> &w, vector<unsigned> &v)`
O: $\Omega(n)$ y $O(n^2)$
O: $\Omega(n)$ y $O(2^n)$
O: $\Theta(2^n)$
A: 0

Q: Los algoritmos de ordenación Quicksort y Mergesort tienen en común...
O: Que ordenan el vector sin usar espacio adicional
O: Que aplican la estrategia divide y vencerás
O: Que se ejecutan en tiempo $O(n)$
A: 1

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Utilizando una técnica de divide y vencerás, ¿se podría saber cuál es la ganancia máxima que podría alcanzar el alfarero?
O: No, ya que no se cumple la propiedad "subestructura óptima".
O: No, ya que no es posible descomponer el problema en subproblemas.
O: Sí, pero a costa de una complejidad temporal prohibitiva.
A: 2

Q: ¿El tiempo de ejecución de un algoritmo depende de la talla del problema?
O: Sí, siempre
O: No, nunca
O: No necesariamente
A: 2

Q: El problema del alfarero (solución discreta con valores y tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{R}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$? Se pretende resolverlo mediante ramificación y poda. Las siguientes funciones tratan de estimar una ganancia aproximada para la parte del nodo aún sin completar. ¿cuál es la mejor para usarla como parte de la cota optimista?
O: ```cpp
double optimistic(const vector<int> &m, const vector<double> &v,
                  const vector<double> &t, double T, size_t from) {
  double gain = 0.0;
  for (size_t i = from; i < m.size() && T > 0; i++) {
    for (int j = 1; j <= m[i]; j++) {
      if (t[i] < T) {
        gain += v[i];
        T -= t[i];
      }
    }
  }
  return gain;
}
```
O: ```cpp
double optimistic(const vector<int> &m, const vector<double> &v,
                  const vector<double> &t, double T, size_t from) {
  double gain = 0.0;
  for (size_t i = from; i < m.size() && T > 0; i++) {
    for (int j = 1; j <= m[i]; j++) {
      gain += v[i];
      T -= t[i];
    }
  }
  return gain;
}
```
O: ```cpp
double optimistic(const vector<int> &m, const vector<double> &v,
                  const vector<double> &t, double T, size_t from) {
  double gain = 0.0;
  for (size_t i = from; i < m.size() && T > 0; i++) {
    double num_objs = min(T / t[i], double(m[i]));
    gain += num_objs * v[i];
    T -= num_objs * t[i];
  }
  return gain;
}
```
A: 2

Q: ¿Qué esquema de programación es el adecuado para resolver el problema del k-ésimo mínimo en un vector?
O: Programación Dinámica
O: Divide y Vencerás
O: Ninguno de los dos
A: 1

Q: Con respecto al parámetro n, ¿Cuál sería la complejidad temporal de la siguiente función si se aplicara memoización?
```cpp
long f(unsigned n) {
  if (n <= 1)
    return 1;
  return n * f(n - 2);
}
```
O: logarítmica
O: constante
O: lineal
A: 2

Q: Un tubo de n centimetros de largo se puede cortar en segmentos de 1 centimetro, 2 centimetros, etc. Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es la que mas ingresos nos producira. Di cual de estas tres afirmaciones es falsa
O: Es posible evitar hacer la evaluacion exhaustiva "de fuerza bruta" guardando, para cada posible longitud $j < n$ el precio mas elevado posible que se puede obtener dividiendo el tubo correspondiente.
O: Hacer una evaluacion exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $\Theta(2^n)$.
O: Hacer una evaluacion exhaustiva de "fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $\Theta(n!)$.
A: 2

Q: En un algoritmo de optimización resuelto mediante ramificación y poda ¿Podría encontrarse la solución óptima sin haber alcanzado nunca un nodo hoja?
O: Sí, esto puede ocurrir incluso si no se hace uso de cotas pesimistas.
O: Sí, pero esto solo podría ocurrir si se hace uso de cotas pesimistas.
O: No, los nodos hojas son los nodos completados y por lo tanto hay que visitar al menos uno de ellos para almacenarlo como la mejor solución hasta el momento.
A: 1

Q: Sea v un vector de N elementos y supongamos que todos los elementos de v son distintos Considera el algoritmo siguiente Si tomamos como medida significativa el numero de comparaciones con elementos del vector(instrucción 2) entonces el algoritmo tiene un coste: 
```
for (i=1; i<N; i++) {
	X=V[i]; // (1)
	Izq=0;
	Der=i-1;
	while (Izq <= Der) {
		Medio = (Izq+Der)/2;
		if (X<V[Medio]) // (2)
			Der=Medio-1;
		else
			Izq = Medio +1;
	}
	for(j=i-1; j>=Izq; j--) {
		V[j+1] = V[j]; // (3)
	}
	V[Izq]=X;
}
```
O: Θ(n*log(n))
O: O(log(n))
O: Θ(n)
O: Ω(log(n)) y O(n)
A: 0

Q: Sea G=(V,E) un grafo no dirigido donde Card(E) = Card()-1 cual de las siguientes afirmaciones es cierta
O: G es conexo, pero si se suprime una arista cualquiera deja de serl
O: G es un arbol
O: Dos vértices cualesquiera de G están conectados por un único camino simple
O: Si G es conexo entonces G es acíclico
A: 3

Q: ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
int ejemplo(vector<int> &v) {
  int n = v.size();
  int j, i = 2;
  int sum = 0;
  while (n > 0 && i < n) {
    j = i;
    while (v[j] != v[1]) {
      sum += v[j];
      j = j / 2;
    }
    i++;
  }
  return sum;
}
```
O: $\Theta(n \log n)$
O: $\Theta(n^2)$
O: $\Omega(n)$
A: 0

Q: Una de estas tres situaciones no es posible. ¿Cuál es?
O: $f(n) \in O(n)$ y $f(n) \in \Omega(1)$
O: $f(n) \in \Omega(n^2)$ y $f(n) \in O(n)$
O: $f(n) \in O(n)$ y $f(n) \in O(n^2)$
A: 1

Q: Cual de las siguientes características es fundamental en los algoritmos ávidos
O: Se generan todas las secuencias de decisiones de forma sistemática y organizada
O: Nos garantizan la obtención de la solución optima del problema
O: Nunca se vuelve a reconsiderar una decisión ya tomada
O: Se combinan las soluciones parciales para obtener la solución parcial
A: 2

Q: Su ecuación de recurrencia es:
```
Función F (ent n: entero): entero
	variables x, i: entero
	Inicio
	si (n>=1) entonces
		retorna 1
	si no
		para i de 1 a n hacer
			x← 1
			mientras x<n hacer
				x← x*2
			finmientras
		finpara
		retorna F(n/2)+F(n/2)
	finsi
fin
```
O: $2 \cdot T(n/2) + n \cdot \log n$
O: $2 \cdot T(n-1) + 1$
O: $2 \cdot T(n/2) + 1$
O: $2 \cdot T(n-1) + n$
O: $2 \cdot T(n/2) + 1$
A: 0

Q: ¿Pertenece $3n^2 + 3$ a $O(n^3)$?
O: Solo para $c = 1$ y $n_0 = 5$
O: Sí
O: No
A: 1

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? $f(n) = \begin{cases} 1 + f(n/b) & \text{si } n > 1 \\ 1 & \text{si } n = 1 \end{cases}$, con $b \in \mathbb{N}$, $b > 1$
A: 0
O: Depende del valor de $b$
O: $f(n) \in \Theta(\log n)$
O: $f(n) \in \Theta(n)$

Q: El uso de funciones de cota en ramificación y poda...
A: 0
O: ...transforma en polinómicas complejidades que antes eran exponenciales
O: ...puede reducir el número de instancias del problema que pertenecen al caso peor
O: ...garantiza que el algoritmo va a ser más eficiente ante cualquier instancia del problema

Q: Si un problema de optimización lo es para una función que toma valores continuos...
A: 0
O: Divide y vencerás puede resultar más eficiente que la programación dinámica iterativa en cuanto al uso de memoria
O: La programación dinámica iterativa siempre es mucho más eficiente que divide y vencerás en cuanto al uso de memoria
O: El uso de memoria de la programación dinámica iterativa y de divide y vencerás es el mismo independientemente de si el dominio es discreto o continuo

Q: La solución voraz al problema de la mochila con objetos no fraccionables:
A: 0
O: Siempre encuentra la solución óptima al problema
O: No siempre encuentra la solución óptima al problema, pero sí una muy buena aproximación, a partir de la cual se puede obtener el óptimo en tiempo constante
O: No siempre encuentra la solución óptima al problema, pero puede emplearse como cota pesimista en algoritmos de búsqueda y enumeración

Q: El algoritmo de ordenación Quicksort divide el problema en dos subproblemas. ¿Cuál es la complejidad temporal asintótica de realizar esa división?
A: 0
O: $O(\log n)$
O: $O(n)$
O: $O(n \log n)$

Q: ¿Cuál es la complejidad temporal asintótica de la función $f$? (en la primera llamada, el parámetro $i$ toma valor $n-1$; el tamaño de los vectores $w$ y $v$ es $n$)
```cpp
float f(vector<float> &w, vector<unsigned> &v, unsigned P, int i) {
  float S1 = 0, S2;
  if (i >= 0) {
    if (w[i] <= P)
      S1 = v[i] + f(w, v, P - w[i], i - 1);
    S2 = f(w, v, P, i - 1);
    return max(S1, S2);
  }
  return 0;
}
```
A: 0
O: $\Omega(n)$ y $O(n^2)$
O: $\Omega(n)$ y $O(2^n)$
O: $\Theta(2^n)$

Q: Dada la siguiente función:
```cpp
void f(vector<int> &v) {
  int i = 1, n = v.size();
  bool swaped = true;
  while (swaped) {
    swaped = false;
    for (int j = n - 1; j >= i; j--)
      if (v[j] < v[j - 1]) {
        swap(v[j], v[j - 1]);
        swaped = true;
      }
    i++;
  }
}
```
De las siguientes afirmaciones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A: 0
O: El peor de los casos ocurre cuando el primer elemento del vector es estrictamente mayor que los restantes sin importar el orden de los demás
O: La complejidad temporal en el peor de los casos viene dada por la expresión $\sum_{i=1}^{n}(n-i)$
O: La complejidad temporal en el mejor de los casos ocurre cuando el vector está vacío

Q: Disponemos de dos algoritmos que queremos comparar. Hemos calculado la función de complejidad del algoritmo A contando operaciones elementales, y del algoritmo B contando pasos de programa. ¿Podemos comparar ambas funciones para decidir qué algoritmo es mejor?
A: 0
O: No, porque al contar operaciones elementales, podríamos obtener una complejidad asintótica mayor que si contamos pasos de programa.
O: Sí, pero solo podremos comparar sus clases de notación asintótica
O: Sí, ambos métodos son totalmente equivalentes. El mejor algoritmo será aquel con la menor función

Q: Tenemos un vector ordenado y queremos comprobar si contiene un elemento dado. ¿Cuál sería la complejidad temporal más ajustada para hacerlo?
A: 0
O: El tamaño del vector
O: El logaritmo del tamaño del vector
O: Constante con el tamaño del vector

Q: En la resolución mediante ramificación y poda del problema del camino de coste mínimo, obtenemos para un nodo determinado, una cota pesimista parcial estrictamente menor que su cota optimista. ¿Qué quiere decir esto?
A: 0
O: Que el nodo debe expandirse
O: Que el nodo no debe expandirse
O: Que hay un error en alguna de las dos cotas

Q: ¿Qué expresión refleja mejor la complejidad asintótica respecto a $n$ del siguiente fragmento de código?
```cpp
int k = 0;
for (int a = 1; a < n; a *= 2)
  for (int b = 0; b < a; b += 1)
    k++;
```
A: 0
O: $\sum_{a=1}^{\log n} 2^a$
O: $\sum_{a=1}^{n-1} \sum_{b=0}^{a-1} 1$
O: $\sum_{a=1}^{n-1} \frac{n}{2}$

Q: ¿Se puede reducir el coste temporal de un algoritmo recursivo almacenando los resultados devueltos por las llamadas recursivas?
A: 0
O: No, ello no reduce el coste temporal ya que las llamadas recursivas se deben realizar de cualquier manera
O: No, solo se puede reducir el coste convirtiendo el algoritmo recursivo en iterativo
O: Sí, si se repiten llamadas a la función con los mismos argumentos

Q: Resolviendo el problema de la composición de funciones mediante Ramificación y Poda, declaramos el nodo y la cola de prioridad como sigue:
```cpp
using Node = tuple<short, int>;
priority_queue<Node> pq;
```
Cada nodo contiene, en este orden, el número de veces que se ha aplicado una función y el resultado obtenido. ¿Qué se puede afirmar sobre el orden en el que se extraen los nodos de la cola de prioridad?
A: 0
O: No podemos afirmar nada, pues no hemos definido ningún criterio para la ordenación de la cola
O: Que se extraerán en un orden que permite encontrar pronto la solución óptima
O: Que se extraerán en un orden que dificulta encontrar pronto la solución óptima

Q: Dada la versión general del problema del camino de coste mínimo, ¿cuál de las estrategias siguientes proveería de una cota optimista para ramificación y poda?
A: 0
O: Suponer que solo nos vamos a mover en tres direcciones (como en el caso restringido).
O: Suponer que ya no se van a realizar más movimientos.
O: Las otras dos estrategias son ambas válidas.

Q: Queremos utilizar el algoritmo heapsort para ordenar un vector de manera descendente (de mayor a menor). ¿Cómo serían las complejidades temporales asintóticas de construir el heap en estos dos supuestos: (1) el vector que recibe está ordenado ascendente; (2) el vector que recibe está ordenado descendente?
A: 0
O: Iguales
O: La del primer supuesto mayor que la del segundo
O: La del segundo supuesto mayor que la del primero

Q: Queremos resolver el problema general del camino de coste mínimo. Supón que estamos usando una función $f$ como cota optimista y funciona correctamente. ¿Qué pasaría si, en el fuente, multiplicamos esta función por $1,1$. Marca la falsa.
A: 0
O: Podría perderse la solución óptima pero la que obtendríamos no se alejaría mucho de ella
O: El programa terminaría más rápido
O: Seguiría funcionando bien pero sería más lento

Q: Si $f \in \Omega(g_1)$ y $f \in \Omega(g_2)$ entonces siempre se cumplirá: de las siguientes conclusiones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A: 0
O: $f \in \Omega(\min(g_1, g_2))$
O: $f \in \Omega(g_1 \cdot g_2)$
O: $f \in \Omega(g_1 + g_2)$

Q: ¿Qué estructura de datos se suele utilizar para almacenar el árbol de búsqueda completo en un algoritmo de ramificación y poda?
A: 0
O: Una cola de prioridad
O: Ninguna, no se almacena
O: Un árbol cuya aridad depende del problema

Q: En clase vimos una demostración que justificaba que el esquema voraz es adecuado para resolver el problema de la mochila continua (con fraccionamiento). Entre otros posibles motivos ¿Por qué esa misma demostración no sirve para el problema de la mochila discreta seleccionando objetos de la misma manera?
A: 0
O: Las otras dos opciones son ambas ciertas.
O: Porque no hay garantía de que la solución esté formada por una secuencia compuesta únicamente de unos y, a continuación, otra secuencia compuesta únicamente de ceros
O: Porque no hay garantía de que la mochila se llene

Q: Dada la solución por programación dinámica recursiva de la versión restringida del problema del camino de coste mínimo, en general, ¿cuántas veces se llega al caso base de la recursión (la casilla inicial)?
A: 0
O: Solo una
O: Un valor que es $O(2^n)$, donde $n$ es el tamaño del mapa
O: Un valor que es $O(n)$, donde $n$ es el tamaño del mapa

Q: ¿Garantiza la estrategia de divide y vencerás una solución de complejidad temporal polinómica a cualquier problema?
A: 0
O: No, la complejidad temporal puede ser incluso peor que cualquier función polinómica
O: Sí, en cualquier caso
O: Sí, pero siempre que la complejidad temporal conjunta de las operaciones de descomposición del problema y la combinación de las soluciones sea polinómica

Q: ¿Cuál de estas estrategias para calcular el $n$-ésimo elemento de la serie de Fibonacci ($f(n) = f(n-1) + f(n-2)$, $f(1) = f(2) = 1$) es más eficiente?
A: 0
O: La estrategia divide y vencerás
O: Para este problema, las dos estrategias citadas serían similares en cuanto a eficiencia
O: Programación dinámica

Q: Queremos resolver la versión general del problema del camino de coste mínimo por ramificación y poda. Para ello se usa una estrategia que consiste en priorizar las expansiones de los nodos que contienen un camino explorado de menor coste. ¿Qué podemos decir del algoritmo resultante?
A: 0
O: Que la primera hoja a la que se llegue es la solución del problema y por lo tanto ya no será necesario explorar más nodos de la lista de nodos vivos, aunque no esté vacía.
O: Que el recorrido en el árbol de búsqueda será equivalente a un recorrido por niveles, por lo que no es necesario utilizar una cola de prioridad.
O: Las otras dos opciones son ambas ciertas.

Q: Si comparamos la cota pesimista y la optimista de un mismo nodo. ¿Qué podríamos saber?
A: 0
O: Si el nodo debe ser descartado
O: El intervalo en el que se encuentra la mejor solución que se puede obtener con ese nodo
O: Si el nodo es prometedor

Q: Cuando se usa un algoritmo voraz para abordar la resolución de un problema de optimización por selección discreta (es decir, un problema para el cual la solución consiste en encontrar un subconjunto del conjunto de elementos que optimiza una determinada función), ¿cuál de estas tres cosas es imposible que ocurra?
A: 0
O: Que se reconsidere la decisión ya tomada anteriormente respecto a la selección de un elemento a la vista de la decisión que se debe tomar en un instante
O: Que el algoritmo no encuentre ninguna solución
O: Que la solución no sea la óptima

Q: ¿Qué tienen en común el algoritmo que obtiene el $k$-ésimo elemento más pequeño de un vector (estudiado en clase) y el algoritmo de ordenación Quicksort?
A: 0
O: La combinación de las soluciones a los subproblemas
O: La división del problema en subproblemas
O: El número de llamadas recursivas que se hacen

Q: Cuando se resuelve el problema de la mochila discreta usando la estrategia de vuelta atrás, ¿puede ocurrir que se tarde menos en encontrar la solución óptima si se prueba primero a meter cada objeto antes de no meterlo?
A: 0
O: Sí, pero solo si se usan cotas optimistas para podar el árbol de búsqueda
O: Sí, tanto si se usan cotas optimistas para podar el árbol de búsqueda como si no
O: No, ya que en cualquier caso se deben explorar todas las soluciones factibles

Q: ¿Cuál es la relación de recurrencia asociada a la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
  if (n == 0)
    return 1;
  return 2 * f(n - 1);
}
```
A: 0
O: $T(n) = 1 + 2 \cdot T(n-1)$; $T(0) = 1$
O: $T(n) = 2 \cdot T(n-1)$; $T(0) = 1$
O: $T(n) = 1 + T(n-1)$; $T(0) = 1$

Q: El siguiente programa resuelve el problema de cortar un tubo de longitud $n$ en segmentos de longitud entera entre 1 y $n$ de manera que se maximice el precio de acuerdo con una tabla $p$ que da el precio para cada longitud, pero falta un trozo. ¿Qué debería ir en lugar de XXXXXXX?
```cpp
int tube_cut(const vector<int> &p, const int n) {
  if (n == 0)
    return 0;
  int q = numeric_limits<int>::lowest();
  for (int i = 1; i <= n; i++)
    q = max(q, p[i] + tube_cut(XXXXXXX));
  return q;
}
```
A: 0
O: p,n-1
O: p,n-i
O: p,i

Q: Usando la técnica de programación dinámica con ahorro de memoria ¿podría acelerarse el programa usando tres vectores en vez de dos?
A: 0
O: Sí, pero sería a expensas de usar más memoria
O: Sí, pero la complejidad temporal seguiría siendo la misma
O: No

Q: En un problema de minimización mediante Vuelta Atrás, empleamos una cota optimista que es mucho mayor que la mejor solución que podría alcanzarse desde un nodo determinado. Como consecuencia:
A: 0
O: Es posible que no encontremos el óptimo
O: El programa será más lento que con otra cota optimista
O: Dicha decisión tendrá un impacto mínimo en el tiempo de ejecución del programa, puesto que es más importante elegir una buena cota pesimista inicial

Q: Un problema tiene subestructura óptima cuando...
A: 0
O: ...su solución se puede construir eficientemente a partir de soluciones de subproblemas suyos
O: ...es posible escribir una solución voraz para el problema
O: ...es posible dividir su tamaño de forma equitativa para construir cada uno de los subproblemas

Q: En el esquema de vuelta atrás, el orden en el que se van asignando los distintos valores a las componentes del vector que contendrá la solución...
A: 0
O: ...es irrelevante si no se utilizan mecanismos de poda basados en la mejor solución hasta el momento
O: ...puede ser relevante si se utilizan mecanismos de poda basados en estimaciones optimistas
O: Las otras dos opciones son ambas ciertas

Q: En la solución de ramificación y poda del problema del camino de coste mínimo, ¿para qué puede resultar útil la técnica de poda con memoria?
A: 0
O: Para obtener cotas pesimistas
O: Para evitar la formación de ciclos
O: Para ambas cosas

Q: En un algoritmo de ramificación y poda se puede usar una cota optimista para estimar el coste restante desde el nodo actual hasta el objetivo. ¿Qué propiedad debe cumplir esta cota para asegurar que siempre se encontrará la solución óptima?
A: 0
O: Nunca sobreestimar el coste real
O: Debe disminuir a medida que se acerca al objetivo
O: Las dos anteriores son ciertas

Q: ¿Cuál es la mejor complejidad temporal y espacial, en función de $n$, que se puede obtener en la solución de programación dinámica para el problema (visto en clase) de cortar un tubo de longitud $n$ en segmentos de longitud entera entre 1 y $n$ de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud?
A: 0
O: Temporal $\Theta(n^2)$ y espacial $\Theta(n)$
O: Temporal y espacial $\Theta(n)$
O: Temporal y espacial $\Theta(n^2)$

Q: En un algoritmo de ramificación y poda, el orden escogido para priorizar los nodos en la lista de nodos vivos...
A: 0
O: ...nunca afecta al tiempo necesario para encontrar la solución óptima
O: ...determina la complejidad temporal en el peor de los casos del algoritmo
O: ...puede influir en el número de nodos que se descartan sin llegar a expandirlos

Q: Queremos resolver la versión general del problema del camino de coste mínimo mediante ramificación y poda. Para obtener la cota optimista de un nodo cualquiera procedemos así: calculamos el número de casillas que quedan, por la diagonal derecha–abajo, hasta llegar a una pared del mapa. A ese valor le sumamos el número de casillas que podrían quedar desde esa pared hasta la salida utilizando únicamente movimientos del tipo abajo o derecha, según corresponda (distancia de Chebishev). ¿Qué podemos decir acerca de la cota optimista que se obtendría?
A: 0
O: Que solo será una cota optimista válida si se asegura que todas las casillas tengan un coste mínimo de 1.
O: Que solo será una cota optimista válida si se asegura que todas las casillas tengan un coste mínimo de 0.
O: Que solo será una cota optimista válida si las casillas contienen valores reales mayores que 0.0.

Q: ¿Cuál de los siguientes algoritmos de ordenación funciona más rápido para ordenar vectores muy grandes que ya están casi ordenados?
A: 0
O: Quicksort empleando el primer elemento como pivote
O: Heapsort
O: Ambos por igual

Q: ¿A qué esquema de entre los estudiados pertenece la siguiente función?
```cpp
void g(vector<unsigned> &v, unsigned j) {
  if (j == v.size())
    return;
  for (unsigned i = j; i < v.size(); i++) {
    swap(v[j], v[i]);
    g(v, j + 1);
    swap(v[j], v[i]);
  }
}
```
A: 0
O: Programación dinámica
O: Ramificación y poda
O: Vuelta atrás

Q: En general ¿cuál de los siguientes problemas tiene solución eficiente utilizando alguno de los esquemas algorítmicos estudiados durante el curso?
A: 0
O: La mochila discreta (0/1) sin restricciones adicionales
O: La mochila discreta (0/1) con pesos discretos
O: La mochila discreta (0/1) con valores discretos

Q: Si $f(n) \in \Theta(2^n)$, ¿podemos decir siempre que $f(n) \in O(n!)$?
A: 0
O: Sí, ya que $2^n \in O(n!)$
O: Sí, ya que $2^n \in \Omega(n!)$
O: No, ya que $2^n \notin O(n!)$

Q: Dada la versión general del problema del camino de coste mínimo, ¿cuál de las estrategias siguientes proveería de una cota optimista para ramificación y poda?
A: 0
O: Tomar la dificultad del camino parcial (hasta el nodo en cuestión) y sumarle la dificultad del camino que, desde el nodo en cuestión, se completa siguiendo un algoritmo voraz que solo toma los movimientos de la versión restringida
O: Tomar la dificultad del camino parcial (hasta el nodo en cuestión) y nada más
O: Las otras dos estrategias son ambas válidas.

Q: En cuanto al cálculo de la complejidad temporal en función de $n$ de la siguiente función:
```cpp
void f(unsigned n) {
  if (n > 1) {
    for (unsigned i = 0; i < 4; i++)
      f(n / 2);
  }
}
```
De las siguientes afirmaciones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A: 0
O: El tamaño del problema viene dado por el valor que toma $n$
O: El mejor de los casos ocurre cuando $n = 0$ y su complejidad temporal está en $\Omega(1)$
O: La complejidad temporal asintótica está en $\Theta(n^2)$

Q: Dada la versión general del problema mcp, en cuanto al valor de una cota pesimista de un nodo cualquiera... de las siguientes afirmaciones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A: 0
O: ...debe corresponder con la dificultad de un camino completado, es decir, que comienza en $(0,0)$ y termina en $(n-1,m-1)$
O: ...debe ser inferior al de una cota optimista de cualquier otro nodo
O: ...debe ser superior al de una cota optimista de cualquier otro nodo

Q: Sobre estas dos alternativas para la programación dinámica: recursiva con memoización, e iterativa, podemos afirmar lo siguiente:
A: 0
O: Ambas calculan siempre todos los valores del almacén
O: Según el problema, la iterativa puede calcular menos valores del almacén que la recursiva
O: Según el problema, la recursiva puede calcular menos valores del almacén que la iterativa

Q: De las siguientes tres afirmaciones, una es cierta y dos falsas, o bien una es falsa y dos son ciertas. Marca la que en ese sentido es diferente a las otras dos.
A: 0
O: El problema de la mochila continua no se puede resolver de forma análoga a como se resuelve el problema de la mochila discreta
O: El problema de la mochila continua no se puede resolver mediante la técnica de ramificación y poda pues se podría producir un número infinito de ramas
O: El problema de la mochila discreta no se puede resolver mediante la técnica de divide y vencerás

Q: ¿Cuál de las siguiente técnicas NO resuelve la versión general del problema del camino de coste mínimo? (según lo visto en clase)
A: 0
O: Ramificación y poda
O: Programación dinámica
O: Vuelta atrás

Q: Dados dos vectores ordenados de $n$ elementos, ¿cuál es el coste del mejor algoritmo que se puede escribir para obtener un vector ordenado que contenga todos los elementos de los dos vectores?
A: 0
O: $\Theta(\log n)$
O: $\Theta(n)$
O: $\Theta(n^2)$

Q: Queremos resolver un problema parecido la versión restringida del problema del camino de coste mínimo pero ahora permitimos (además) movimientos de dos pasos en las mismas direcciones. ¿Cómo se podría resolver este problema?
A: 0
O: Usando programación dinámica, de una forma muy parecida al original
O: Ya no se podría resolver usando programación dinámica y habría que recurrir a la vuelta atrás
O: No se puede resolver ni usando programación dinámica ni vuelta atrás

Q: Entre dos algoritmos para solucionar el mismo problema, siempre debemos elegir:
A: 0
O: Aquel con menor complejidad asintótica en el mejor caso
O: Aquel con menor complejidad asintótica en el peor caso
O: Si conocemos la talla máxima del problema que pretendemos resolver, es posible que un algoritmo con mayor complejidad asintótica se comporte mejor para nuestro problema

Q: Dado el siguiente programa recursivo:
```cpp
int f(int n) { // Se asume que n >= 0
  if (n == 0)
    return 1;
  return f(n - 1) + f(n - 2);
}
```
si quisiéramos mejorarlo haciendo uso de la técnica de programación dinámica, ¿cuáles serían las complejidades temporal y espacial más ajustadas del algoritmo resultante?
A: 0
O: Respectivamente, $O(n)$ y $O(1)$
O: Ambas complejidades serían $O(1)$
O: Ambas complejidades serían $O(n)$

Q: El algoritmo de ordenación Mergesort divide el problema en dos subproblemas. ¿Cuál es la complejidad temporal asintótica de realizar esa división?
A: 0
O: $O(\log n)$
O: $O(n)$
O: $O(1)$

Q: Dada la versión restringida del problema mcp resuelto mediante programación dinámica iterativa, ¿cuál es la complejidad temporal del fragmento de código que cumplimenta únicamente las celdas del almacén que corresponden a su contorno (caso base)? (suponiendo que el caso base corresponde a los casos $n = 0$ o $m = 0$)
A: 0
O: $\Theta(m)$
O: $\Theta(\max\{n, m\})$
O: $\Theta(\min\{n, m\})$

Q: Queremos resolver la versión restringida del problema del camino de coste mínimo usando una técnica de vuelta atrás.
A: 0
O: Eso no se puede hacer, ese problema no se puede resolver usando vuelta atrás
O: La técnica de vuelta atrás se podría aplicar, pero siempre sería más lento que si usamos programación dinámica
O: La técnica de vuelta atrás se podría aplicar, incluso en algunos raros casos podría ir más rápido que usando programación dinámica

Q: Dada la versión restringida del problema mcp, queremos listar todos los caminos posibles (sean o no los óptimos). ¿qué técnica deberíamos utilizar?
A: 0
O: Memoización
O: Divide y vencerás
O: Programación dinámica iterativa

Q: Dada la versión general del problema mcp ¿cuál es la mejor complejidad temporal (de entre las indicadas) con la que podría obtenerse una cota pesimista para el nodo inicial del árbol de búsqueda?
A: 0
O: $\Omega(n + m)$
O: $\Omega(nm)$
O: $\Omega(1)$

Q: Decid cuál de estas tres es la cota pesimista más ajustada al valor óptimo de la mochila discreta:
A: 0
O: El valor de la mochila continua correspondiente
O: El valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor específico de los objetos
O: El valor de una mochila que contiene todos los objetos restantes aunque se pase del peso máximo permitido

Q: Si en el problema del camino de coste mínimo, estudiado en prácticas, permitiéramos casillas con coste 0, ¿cuál de las siguientes distancias sería una cota optimista válida si se la sumamos al coste del camino actual? $(i,j)$ es la posición actual y $(n,m)$ el número de filas y columnas, respectivamente, del mapa.
A: 0
O: $\max(n-1-i, m-1-j)$
O: $(n-1-i) + (m-1-j)$
O: Ninguna de las anteriores

Q: Si el coste espacial de un algoritmo viene dado por la recurrencia $T(n) = n + T(n/2)$ siendo $T(0) = 1$, donde $n$ es el tamaño del problema, ¿a qué clase de complejidad pertenece?
A: 0
O: $O(n)$
O: $O(n \log n)$
O: $O(n^2)$

Q: Indica cuál de las siguientes afirmaciones es cierta:
A: 0
O: Si un esquema de ramificación y poda encuentra la solución óptima a un problema, un esquema de vuelta atrás también la encuentra siempre.
O: Si un esquema de ramificación y poda encuentra la solución óptima a un problema, un esquema de vuelta atrás podría no encontrarla.
O: Si un esquema de ramificación y poda encuentra la solución óptima a un problema, un esquema de vuelta atrás siempre es más ineficiente.

Q: En un algoritmo de ramificación y poda, si la lista de nodos vivos no está ordenada de forma apropiada...
A: 0
O: ...podría ocurrir que se descarten nodos factibles
O: ...podría ocurrir que se pode el nodo que conduce a la solución óptima
O: ...podría ocurrir que se exploren nodos de forma innecesaria

Q: Para resolver el problema del árbol de recubrimiento mínimo en un grafo con pesos no negativos, ¿qué algoritmo es más eficiente en términos de complejidad temporal si el grafo es denso? (tiene muchos arcos con respecto a los vértices)
A: 0
O: Algoritmo de Kruskal
O: Algoritmo de Prim
O: Da igual

Q: ¿Qué se necesita para realizar la poda basada en la mejor solución hasta el momento?
A: 0
O: Un almacén donde se guarda el mejor valor con el que se llega a cada nodo del árbol de búsqueda
O: Una manera de calcular una cota optimista para cada nodo, además de la propia mejor solución hasta el momento
O: Una manera de calcular una cota optimista para cada nodo y una manera de calcular una cota pesimista del mismo nodo, además de la propia mejor solución hasta el momento

Q: Estamos ante un nodo del árbol de búsqueda de ramificación y poda y hemos decidido no explorarlo. ¿Qué podría haber ocurrido?
A: 0
O: Que sus cotas, optimista y pesimista, han coincidido en el mismo valor
O: Que su cota pesimista no mejora la mejor solución encontrada hasta el momento
O: Podría haber ocurrido cualquiera de las otras dos alternativas

Q: En la resolución mediante ramificación y poda del problema del camino de coste mínimo, ordenamos ascendentemente las casillas del mapa por coste. Dado un nodo parcial (o nodo incompleto), sumamos al coste del camino que llevamos hasta el momento, la suma de las $k$ casillas con menor coste, siendo $k = \max(n-1-i, m-1-j)$. $(i,j)$ es la posición actual y $(n,m)$ el número de filas y columnas del mapa. El valor obtenido es:
A: 0
O: Una cota optimista
O: Una cota pesimista
O: Ninguna de las anteriores