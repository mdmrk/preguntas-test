Q: Un fontanero tiene una jornada de Q cuartos de hora (es así como se organiza la agenda) y tiene C clientes. El trabajo del cliente i tarda qi cuartos de hora y el fontanero le cobra un precio pi. Es posible que no pueda atender todos los clientes en la jornada, que nunca puede alargar. Este problema tiene una solución bien conocida que permite elegir qué clientes visitar para que la suma cobrada al final de la jornada sea la máxima. ¿Qué podemos decir de esta solución?
A:1
Que la organización de la agenda en cuartos de hora permite obtener una solución de complejidad temporal $\Theta(QC)$ y complejidad espacial $\Theta(Q)$.
Que se ha de implementar forzosamente con un algoritmo de búsqueda y enumeración como el de vuelta atrás.
Que no se puede implementar con una solución de "divide y vencerás" con memoización.

Q: Con respecto a los algoritmos estudiados durante el curso que encuentran el árbol de recubrimiento de mínimo coste, de las afirmaciones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos
A:3
El algoritmo de Prim se puede acelerar notablemente si los vértices se organizan en una estructura union-find.
La complejidad temporal del algoritmo de Prim es cúbica con respecto al número de vértices del grafo.
El algoritmo de Kruskal va construyendo un bosque de árboles que va uniendo hasta que acaba con un árbol de recubrimiento de coste mínimo.

Q: ¿Qué obtenemos con la siguiente declaración de C++: `priority_queue<nodo> pq;` ?
A:3
Un heap o montículo de mínimos.
Un heap o montículo sin orden establecido ya que no se ha definido la función de comparación.
Un heap o montículo de máximos.

Q: Con los valores numéricos almacenados en un fichero, queremos construir un heap (montículo). ¿Cuál es la forma más eficiente de proceder?
A:1
Almacenar esos valores en un vector y después, reorganizar sus elementos para que estén dispuestos en forma de heap.
Ambas formas de proceder son equivalentes en cuanto a eficiencia.
Almacenar esos valores directamente en un heap que inicialmente está vacío y va creciendo por cada uno de los valores insertados.

Q: Queremos aplicar la técnica de memoización a la siguiente función recursiva: 
```cpp
double f(double x) {
	if(x <= 2)
		return x;
	return f(sqrt(x-1)) + f(sqrt(x-2));
}
```
¿Cuál sería un buen candidato para el almacén? (La función `sqrt()` obtiene la raíz cuadrada; xMax es el valor de x en la primera llamada.)
A:2
`vector<double> M(xMax+1)`
Ninguna de las otras dos opciones es válida
`vector<vector<double>> M(xMax+1, vector<double>(xMax+1))`

Q: ¿Cuál es el coste de monticulizar (heapify) un vector de tamaño N?
A:3
$O(N)$ y $\Omega(1)$
$O(N \log N)$ y $\Omega(N)$
$\Theta(N)$

Q: De las siguientes expresiones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A:3
$\sum_{i=1}^{n} \sum_{j=1}^{\log i} 2^j \in O(n^2)$
$\sum_{i=1}^{\log n} \sum_{j=1}^{n} 2^j \in O(n \log n)$
$\sum_{i=1}^{n/2} \sum_{j=1}^{i} 2^j \in O(n \log n)$

Q: Se pretende resolver el problema del viajante de comercio (travelling salesman problem) mediante el esquema de vuelta atrás. ¿Cuál de los siguientes valores se espera que se comporte mejor como cota optimista para un nodo?
A:2
La suma de los pesos de las aristas que completan la solución paso a paso visitando el vértice más cercano al último visitado.
La suma de los pesos de las k aristas restantes más cortas, donde k es el número de ciudades que quedan por visitar.
El valor que se obtiene de multiplicar k por el peso de la arista más corta de entre las restantes, donde k es el número de ciudades que quedan por visitar.

Q: En un algoritmo de búsqueda y enumeración, ¿qué podemos decir acerca de la heurística que se utiliza para determinar si un nodo debe expandirse o no?
A:3
Las otras dos opciones son ambas ciertas.
Que puede equivocarse, por eso se le llama heurística.
Que también puede usarse como estrategia de búsqueda.

Q: Se dispone de un conjunto de n valores numéricos dispuestos en forma de montículo y se desea obtener el valor de la suma de todos los que al menos tienen un hijo (es decir, no son nodos hoja). ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
A:3
$O(\log n)$
$O(n \log n)$
$O(n)$

Q: ¿Qué hace la siguiente función? 
```cpp
void f(vector<int> &A) {
	priority_queue<int> pq;
	for(auto i : A)
		pq.push(A[i]);
	A.clear();
	while(!pq.empty()) {
		A.push_back(pq.top());
		pq.pop();
	}
}
```
A:3
Invierte el vector A (el último elemento quedará el primero).
Nada, deja el vector A como estaba.
Ordena el vector A.

Q: Una empresa de transportes dispone de M vehículos para repartir N paquetes, todos al mismo destino. Cada paquete i tiene un peso Pi y se tiene que entregar antes de que transcurra un tiempo TPi. Por otro lado, cada vehículo j puede transportar una carga máxima Cj, tarda un tiempo TVj para llegar al destino y consume una cantidad Lj de litros de combustible, independientemente de la carga que transporta. Imaginad un algoritmo de vuelta atrás que obtenga la manera en que se tienen que transportar los objetos (en qué vehículo j tiene que ir cada objeto i) para que el consumo sea el mínimo. ¿Cuál sería una buena cota optimista?
A:1
Ambas son cotas optimistas válidas.
La solución voraz del problema de cargar cada paquete en el camión de menor consumo donde cada paquete llega a tiempo, sin tener en cuenta si el camión se sobrecarga o no.
La solución voraz del problema de cargar cada paquete en el camión de menor consumo, sin sobrecargarlo, sin tener en cuenta si el paquete llega a tiempo o no.

Q: En cuanto a la posibilidad de aplicar la técnica de programación dinámica iterativa para resolver un problema:
A:3
No necesariamente ha de conocerse de antemano todos los posibles subproblemas, pero sí debe saberse, dados dos de ellos cualesquiera, cuál es más pequeño.
Se debe conocer de antemano todos los posibles subproblemas pero no necesariamente se debe disponer de una ordenación entre todos ellos según tamaño.
Se debe conocer de antemano todos los posibles subproblemas y además, se debe disponer de una ordenación entre todos ellos según tamaño.

Q: Se dispone de un conjunto de n valores numéricos dispuestos en un vector sin orden preestablecido. Se desea escribir una función que reciba ese vector y un valor k ($n/2 \leq k \leq n$) y que devuelva los k valores más pequeños dispuestos en otro vector de manera ordenada. ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
A:2
$O(kn)$
$O(k \log n)$
Ninguna de las otras dos opciones es cierta.

Q: Indica cuál es la complejidad temporal en función de n, donde A es un vector de enteros y k es una constante que no depende de n, del fragmento siguiente: 
```cpp
for(int i = k; i < n - k; i++) {
	A[i] = 0;
	for(int j = i - k; j < i + k; j++)
		A[i] += B[j];
}
```
A:3
$\Theta(k)$
$\Theta(n^2)$
$\Theta(n)$

Q: En el problema del viajante de comercio (travelling salesman problem) queremos listar todas las soluciones factibles
A:2
Lo más importante es conseguir una cota pesimista adecuada. Las diferencias entre ramificación y poda y vuelta atrás son irrelevantes en este caso.
El orden en el que se exploran las soluciones parciales no es relevante; por ello, la técnica ramificación y poda no aporta nada con respecto a vuelta atrás.
Lo más adecuado sería usar una técnica de ramificación y poda ya que es muy importante el orden en el que se exploran las soluciones parciales.

Q: El problema de la moneda consiste en formar una suma M con el número mínimo de monedas tomadas (con repetición) de un conjunto C donde hay una cantidad suficientemente grande de monedas con cada posible valor facial $C = \{c_1, c_2, \ldots, c_k\}$, con $c_1 = 1$. ¿Cuál de estas afirmaciones sobre un algoritmo recursivo de la forma $nOPT(M) = 1 + \min nOPT(M-c_i)$; $nOPT(0) = 0$; $nOPT(x) = \infty$ para $x < 0$ es falsa?
A:2
Tiene un coste temporal prohibitivo, ya que puede calcular $nOPT(x)$ para el mismo valor de x más de una vez.
Dependiendo de cuáles sean los valores faciales y la suma, puede ser que el algoritmo recursivo no encuentre solución.
Encuentra siempre la solución óptima.

Q: Dados dos nodos cualesquiera del árbol de búsqueda de ramificación y poda, en general, ¿se puede saber con certeza cuál está más cerca de la solución óptima del problema a resolver?
A:1
Sí, pero solo si ambos nodos son hoja.
Sí, el que tiene mejor cota pesimista.
Sí, el que tiene mejor cota optimista.

Q: ¿Cuál es la complejidad temporal en función de n, del siguiente fragmento: 
```cpp
for(int i = 0; i < n; i++) {
	A[i] = 0;
	for(int j = 0; j < 20; j++)
		A[i] += B[j];
}
```
A:2
$\Theta(n \log n)$
$\Theta(n)$
$\Theta(n^2)$

Q: ¿Cuál es la complejidad, en función de n, del siguiente fragmento: (suponed que A está definido como `vector<int> A(n)` y `sort()` es la función de ordenación de la librería estándar de C++, que tiene la mejor complejidad, temporal y espacial, posible para un algoritmo de ordenación de propósito general.) 
```cpp
std::sort(begin(A), end(A));
int acc = 0;
for(auto i : A)
	acc += i;
```
A:1
$\Theta(n \log n)$
$\Theta(n)$
$\Theta(n^2)$

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? 
```
f(n) = n(n - 1) + f(n - 1)   # si n > 0
f(0) = 1                      # si n = 0
```
A:3
$f(n) \in \Theta(n^2)$
Ninguna de las otras dos opciones es cierta.
$f(n) \in \Theta(n^3)$

Q: ¿Qué tienen en común los algoritmos de ordenación Quicksort y Mergesort?
A:3
El número de llamadas recursivas que hacen en el mejor de los casos.
La complejidad temporal de la combinación de las soluciones parciales.
La complejidad temporal de la división en subproblemas.

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
A:3
$\Omega(n^2) \subset \Omega(n^3)$
$\Theta(n^2) \subset \Theta(n^3)$
$O(n^2) \subset O(n^3)$

Q: De las siguientes afirmaciones marca la que es verdadera.
A:1
En un esquema de vuelta atrás, las cotas pesimistas no tienen sentido si lo que se pretende es obtener todas las soluciones factibles.
El esquema de vuelta atrás no es compatible con el uso conjunto de cotas pesimistas y optimistas.
Las cotas pesimistas no son compatibles con un esquema de vuelta atrás.

Q: Si el coste temporal de un algoritmo es T(n), ¿cuál de las siguientes situaciones es imposible?
A:1
$T(n) \in \Omega(n)$ y $T(n) \in \Theta(n^2)$
$T(n) \in \Theta(n)$ y $T(n) \in \Omega(n^2)$
$T(n) \in O(n)$ y $T(n) \in \Theta(n)$

Q: Dada la siguiente función: 
```cpp
int exa(vector<int> &v) {
	int j, i=1, n=v.size();
	if(n > 1)
		do {
			int x = v[i];
			for(j=i; j > 0 && v[j-1] > x; j--)
				v[j] = v[j-1];
			v[j] = x;
			i++;
		} while(i < n);
	return 0;
}
```
A:1
La complejidad temporal en el mejor de los casos es $\Omega(n)$.
La complejidad temporal en el mejor de los casos es $\Omega(1)$.
La complejidad temporal exacta es $\Theta(n^2)$.

Q: En un problema de optimización, si el dominio de las decisiones es un conjunto infinito,
A:2
Es probable que a través de programación dinámica se obtenga un algoritmo eficaz que lo solucione.
Podremos aplicar el esquema vuelta atrás siempre que se trate de un conjunto infinito numerable.
Una estrategia voraz puede ser la única alternativa.

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos
A:1
$O(n^2) \subset O(2^{\log_2 n})$
$n + n \log_2 n \in \Omega(n + n \log_2 n)$
$\Omega(n^2) \subset \Omega(n)$

Q: Si $\lim_{n \to \infty} \frac{f(n)}{g(n)} = \infty$ entonces...
A:2
$f(n) \in O(g(n))$
$f(n) \in \Omega(g(n))$
$f(n) \in \Theta(g(n))$

Q: Dado un problema de minimización resuelto mediante un esquema de ramificación y poda, ¿qué ocurre si la cota optimista resulta ser un valor excesivamente pequeño?
A:3
Que se podría explorar menos nodos de los necesarios.
Que se podría explorar más nodos de los necesarios.
Que se podría podar el nodo que conduce a la solución óptima.

Q: ¿Qué nos proporciona la media aritmética entre el coste temporal asintótico (o complejidad temporal) en el peor caso y el coste temporal asintótico en el mejor caso?
A:3
En general, nada de interés.
El coste temporal asintótico en el caso medio.
El coste temporal promedio.

Q: Dada la siguiente función: 
```cpp
int exa(string &cad, int pri, int ult) {
	if(pri >= ult)
		return 1;
	else if(cad[pri] == cad[ult])
		return exa(cad, pri+1, ult-1);
	else
		return 0;
}
```
A:3
$O(n^2)$
$O(\log n)$
$O(n)$

Q: Dado el problema de las torres de Hanoi resuelto mediante divide y vencerás, ¿cuál de las siguientes relaciones de recurrencia expresa mejor su complejidad temporal para el caso general, siendo n el número de discos?
A:1
$T(n) = 2T(n - 1) + n$
$T(n) = T(n - 1) + n$
$T(n) = 2T(n - 1) + 1$

Q: ¿Cuál de las siguientes estrategias de búsqueda es más apropiada en un esquema de vuelta atrás?
A:3
Ninguna de las otras dos estrategias es compatible con el esquema de vuelta atrás.
Explorar primero los nodos con mejor cota optimista.
Explorar primero los nodos con mejor valor hasta el momento en la función que se pretende optimizar.

Q: ¿Cuál sería la complejidad temporal de la siguiente función tras aplicar programación dinámica? 
```cpp
double f(int n, int m) {
	if(n == 0)
		return 1;
	return m * f(n-1, m) * f(n-2, m);
}
```
A:1
$\Theta(n)$
$\Theta(n^2)$
$\Theta(n \cdot m)$

Q: La siguiente relación de recurrencia expresa la complejidad de un algoritmo recursivo, donde g(n) es una función polinómica:
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 2T(n/2) + g(n) & \text{en otro caso} \end{cases}$
Di cuál de las siguientes afirmaciones es cierta:
A:3
Si $g(n) \in \Theta(n)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación mergesort.
Si $g(n) \in \Theta(n^2)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación mediante inserción binaria.
Si $g(n) \in \Theta(1)$ la relación de recurrencia representa la complejidad temporal del algoritmo de búsqueda dicotómica.

Q: Sea la siguiente relación de recurrencia:
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 8T(n/8) + g(n) & \text{en otro caso} \end{cases}$
Si $T(n) \in \Theta(n^2)$, ¿en cuál de estos tres casos nos podemos encontrar?
A:3
$g(n) = n^2$
$g(n) = n$
$g(n) = n^3$

Q: Se desea resolver el problema de la potencia enésima ($x^n$), asumiendo que n es par y que se utilizará la siguiente recurrencia: pot(x,n) = pot(x,n/2) * pot(x,n/2); ¿Qué estrategia resulta ser más eficiente en cuanto al coste temporal?
A:1
En este caso tanto programación dinámica como divide y vencerás resultan ser equivalentes en cuanto a la complejidad temporal.
Un algoritmo recursivo con memoización.
Divide y vencerás.

Q: En ausencia de cotas optimistas y pesimistas, la estrategia de vuelta atrás...
A:3
...no se puede usar para resolver problemas de optimización.
...debe recorrer siempre todo el árbol.
...no recorre todo el árbol si hay manera de descartar subárboles que representan conjuntos de soluciones no factibles.

Q: Se desea ordenar una lista enlazada de n elementos adaptando el algoritmo Mergesort. En este caso, al tratarse de una lista, la complejidad temporal asintótica de realizar la división en subproblemas resulta ser lineal con el tamaño de esa lista. ¿Cuál sería entonces el coste temporal de realizar dicha ordenación?
A:1
$\Theta(n \log n)$
Ninguna de las otras dos opciones es cierta.
$\Theta(n^2)$

Q: Si $f \notin O(g_1)$ y $f \in O(g_2)$ entonces siempre se cumplirá:
A:2
$f \in \Omega(\min(g_1, g_2))$
$f \notin O(\max(g_1, g_2))$
$f \in \Omega(g_1 + g_2)$

Q: ¿Qué complejidad se obtiene a partir de la relación de recurrencia $T(n) = 9T(n/3) + n^3$ con $T(1) = O(1)$?
A:3
$O(n^3 \log n)$
$O(n \log n)$
$O(n^3)$

Q: Queremos resolver mediante vuelta atrás el problema de las 8 reinas (colocar 8 reinas en un tablero de ajedrez de manera que no se maten mutuamente). Una buena cota optimista permitiría:
A:3
Muy probablemente, resolver el problema de forma más rápida.
No es aplicable este tipo de podas a este problema.
Muy probablemente, explorar menos nodos.

Q: ¿Cuál de estos problemas tiene una solución eficiente utilizando programación dinámica?
A:3
El problema del cambio.
La mochila discreta con pesos y valores reales positivos.
El problema de la asignación de tareas.

Q: Se desea obtener todas las permutaciones de una lista compuesta por n elementos. ¿Qué esquema es el más adecuado?
A:3
Ramificación y poda, puesto que con buenas funciones de cota es más eficiente que vuelta atrás.
Divide y vencerás, puesto que la división en sublistas se podría hacer en tiempo constante.
Vuelta atrás, es el esquema más eficiente para este problema.

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
A:3
...nunca tendrá un coste temporal asintótico (o complejidad temporal) exponencial.
...alcanza su máxima eficiencia cuando el problema de tamaño n se divide en a problemas de tamaño n/a.
Las otras dos opciones son ambas verdaderas.

Q: Dado un problema de minimización resuelto mediante un esquema de ramificación y poda, ¿qué propiedad cumple una cota optimista?
A:2
Las otras dos opciones son ambas falsas.
Siempre es mayor o igual que la mejor solución posible alcanzada.
Asegura un ahorro en la comprobación de todas las soluciones factibles.

Q: El esquema de vuelta atrás...
A:3
Se puede aplicar a cualquier tipo de problema aunque el coste temporal es elevado.
Garantiza que encuentra la solución óptima a cualquier problema de selección discreta.
Las otras dos opciones son ambas verdaderas.

Q: El algoritmo de ordenación Quicksort divide el problema en dos subproblemas. ¿Cuál es la complejidad temporal asintótica de realizar esa división?
A:3
$\Theta(\log n)$
$\Theta(n \log n)$
$\Theta(n)$

Q: Decidid cuál de estas tres estrategias proveería la cota pesimista más ajustada al valor óptimo de la mochila discreta:
A:3
Completar las decisiones restantes basándose en la mejor solución voraz que pueda encontrarse para los restantes objetos y espacio disponible de la mochila.
Asumir que ya no se van a coger más objetos.
El valor de una mochila que contiene todos los objetos aunque se pase del peso máximo permitido.

Q: De los problemas siguientes, indicad cuál no se puede tratar eficientemente como los otros dos:
A:3
El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el mínimo de monedas posibles.
El problema de cortar un tubo de forma que se obtenga el máximo beneficio posible.
El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores.

Q: El coste temporal de un algoritmo se ajusta a la siguiente ecuación de recurrencia:
$t(n) = \begin{cases} 1 & \text{para } n = 0 \\ n + \sum_{j=0}^{n-1} t(j) & n > 1 \end{cases}$
¿Qué coste temporal asintótico o complejidad temporal tendrá el algoritmo?
A:3
$O(n^2)$
$O(n \log n)$
$O(2^n)$

Q: Uno de estos tres problemas no tiene una solución trivial y eficiente que siga el esquema voraz.
A:3
El problema de la mochila discreta sin limitación en la carga máxima de la mochila.
El problema de la mochila continua.
El problema del cambio.

Q: ¿Cuál de estas tres expresiones es cierta?
A:2
$O(n^2) \subset O(2^{\log n}) \subset O(2^n)$
$O(2^{\log n}) \subset O(n^2) \subset O(2^n)$
$O(n^2) \subset O(2^{\log n}) \subset O(2^n)$

Q: Los algoritmos de ordenación quicksort y mergesort tienen en común:
A:2
Que ordenan el vector sin usar espacio adicional.
Que aplican la estrategia de Divide y vencerás.
Que ejecutan en tiempo $O(n)$.

Q: ¿Qué algoritmo es asintóticamente más rápido el quicksort o el mergesort?
A:3
El mergesort es siempre el más rápido o igual (salvo una constante) que el quicksort.
Como su nombre indica, quicksort.
Son los dos igual de rápidos, ya que el coste temporal asintótico de ambos es $O(n \log n)$.

Q: Cuando se resuelve el problema de la mochila discreta usando la estrategia de vuelta atrás, ¿puede ocurrir que se tarde menos en encontrar la solución óptima si se prueba primero a meter cada objeto antes de no meterlo?
A:1
Sí, pero solo si se usan cotas optimistas para podar el árbol de búsqueda.
Sí, tanto si se usan cotas optimistas para podar el árbol de búsqueda como si no.
No, ya que en cualquier caso se deben explorar todas las soluciones factibles.

Q: La complejidad temporal (o coste temporal asintótico) en el mejor de los casos
A:3
Las dos anteriores son verdaderas.
Es el tiempo que tarda el algoritmo en resolver la talla más pequeña que se le puede presentar.
Es una función de la talla, o tamaño del problema, que tiene que estar definida para todos los posibles valores de esta.

Q: Los algoritmos de programación dinámica hacen uso
A:1
De que se puede ahorrar esfuerzo guardando los resultados de esfuerzos anteriores.
De una estrategia trivial consistente en examinar todas las soluciones posibles.
De que la solución óptima se puede construir añadiendo el componente óptimo de los restantes, uno a uno.

Q: Un programa con dos bucles anidados uno dentro de otro, cada uno de los cuales hace aproximadamente n iteraciones, tarda un tiempo
A:2
$O(n)$
$O(n^2)$
$O(2^n)$

Q: La siguiente relación de recurrencia expresa la complejidad de un algoritmo recursivo, donde g(n) es una función polinómica:
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 2T(n/2) + g(n) & \text{en otro caso} \end{cases}$
Di cuál de las siguientes afirmaciones es falsa:
A:2
Si $g(n) \in O(1)$ la relación de recurrencia representa la complejidad temporal del algoritmo de búsqueda dicotómica.
Si $g(n) \in O(n^2)$ la relación de recurrencia representa la complejidad temporal del algoritmo de búsqueda por inserción.
Si $g(n) \in O(n)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación mergesort.

Q: Si un problema de optimización lo es para una función que toma valores continuos...
A:2
El uso de memoria de la programación dinámica iterativa y de la programación dinámica recursiva es el mismo independientemente de si el dominio es discreto o continuo.
La programación dinámica recursiva puede resultar mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
La programación dinámica iterativa siempre es mucho más eficiente que la programación dinámica recursiva en cuanto al uso de memoria.

Q: La eficiencia de los algoritmos voraces se basa en...
A:1
...el hecho de que las decisiones tomadas no se reconsideran.
...el hecho de que, con antelación, las posibles decisiones se ordenan de mejor a peor.
...en el esquema voraz no se puede hablar de eficiencia puesto que a menudo no resuelve el problema.

Q: ¿Cuál de estos tres problemas de optimización no tiene una solución voraz que sea óptima?
A:2
El árbol de cobertura de coste mínimo de un grafo conexo.
El problema de la mochila discreta.
El problema de la mochila continua o con fraccionamiento.

Q: ¿Pertenece $3n^2 + 3$ a $O(n^3)$?
A:3
Solo para $c=1$ y $n_0 = 5$.
No.
Sí.

Q: En el esquema de vuelta atrás el orden en el que se van asignando los distintos valores a las componentes del vector que contendrá la solución...
A:2
...es irrelevante si no se utilizan mecanismos de poda basados en la mejor solución hasta el momento.
Las otras dos anteriores son ciertas.
...puede ser relevante si se utilizan mecanismos de poda basados en estimaciones optimistas.

Q: ¿Cuál de los siguientes criterios proveería una cota optimista para el problema de encontrar el camino más corto entre dos ciudades (se supone que el grafo es conexo)?
A:3
Utilizar la solución (subóptima) que se obtiene al resolver el problema mediante un algoritmo voraz.
Calcular la distancia recorrida moviéndose al azar por el grafo hasta llegar (por azar) a la ciudad destino.
Calcular la distancia geométrica (en línea recta) entre la ciudad origen y destino.

Q: Tenemos n sustancias diferentes en polvo y queremos generar todas las distintas formas de mezclarlas de forma que el peso no supere un gramo. Como la balanza que tenemos solo tiene precisión de 0.1 gramos no se considerarán pesos que no sean múltiplos de esa cantidad. Queremos hacer un programa que genere todas las combinaciones posibles.
A:1
No hay ningún problema en usar una técnica de vuelta atrás.
No se puede usar backtracking porque el número de combinaciones es infinito.
No se puede usar backtracking porque las decisiones no son valores abstractos.

Q: Indicad cuál de estas tres expresiones es falsa
A:2
$\Theta(n) \subset O(n)$
$\Theta(n) \subset \Theta(n^2)$
$\Theta(n/2) = \Theta(n)$

Q: Se quieren ordenar d números distintos comprendidos entre 1 y n. Para ello se usa un array de n booleanos que se inicializan primero a false. A continuación se recorren los d números cambiando los valores del elemento del vector de booleanos correspondiente a su número a true. Por último se recorre el vector de booleanos escribiendo los índices de los elementos del vector de booleanos que son true. ¿Es este algoritmo más rápido (asintóticamente) que el mergesort?
A:2
Sí, ya que el mergesort es $O(n \log n)$ y este es $O(n)$.
Solo si $d \log d > kn$ (donde k es una constante que depende de la implementación).
No, ya que este algoritmo ha de recorrer varias veces el vector de booleanos.

Q: En un algoritmo de ramificación y poda, si la lista de nodos vivos no está ordenada de forma apropiada...
A:1
...podría ocurrir que se exploren nodos de forma innecesaria.
...podría ocurrir que se pode el nodo que conduce a la solución óptima.
...podría ocurrir que se descarten nodos factibles.

Q: Las relaciones de recurrencia
A:3
Aparecen solo cuando la solución es del tipo divide y vencerás.
Sirven para reducir el coste temporal de una solución cuando es prohibitivo.
Expresan recursivamente el coste temporal de un algoritmo.

Q: Complejidad de 
```cpp
void f(int n, int arr[]) {
	int i = 0, j = 0;
	for(; i < n; ++i)
		while(j < n && arr[i] < arr[j])
			j++;
}
```
A:3
$O(n^2)$
$O(n \log n)$
$O(n)$

Q: ¿Cuál de los siguientes pares de problemas son equivalentes en cuanto al tipo de solución (óptima, factible, etc.) aportada por el método voraz?
A:3
El fontanero diligente y la asignación de tareas.
El fontanero diligente y el problema del cambio.
El fontanero diligente y la mochila continua.

Q: Se desea encontrar el camino más corto entre dos ciudades. Para ello se dispone de una tabla con la distancia entre los pares de ciudades en los que hay carreteras o un valor centinela (por ejemplo, -1) si no hay, por lo que para ir de la ciudad inicial a la final es posible que haya que pasar por varias ciudades. Como también se conocen las coordenadas geográficas de cada ciudad se quiere usar la distancia geográfica (en línea recta) entre cada par de ciudades como cota para limitar la búsqueda en un algoritmo de vuelta atrás. ¿Qué tipo de cota sería?
A:2
Una cota pesimista.
Una cota optimista.
No se trataría de ninguna poda puesto que es posible que esa heurística no encuentre una solución factible.

Q: De los problemas siguientes, indicad cuál no se puede tratar eficientemente como los otros dos
A:2
El problema del viajante de comercio.
El problema del corte de tubos, que se obtenga el máximo beneficio posible.
El problema del cambio, o sea, el de entregar una cantidad de dinero usando las mínimas monedas.

Q: ¿Cuál es la diferencia principal entre una solución de vuelta atrás y una solución de ramificación y poda para el problema de la mochila?
A:1
El orden de exploración de las soluciones.
El coste asintótico en el caso peor.
El hecho de que la solución de ramificación y poda puede empezar con una solución subóptima voraz y backtracking no.

Q: Los algoritmos de vuelta atrás que hacen uso de cotas optimistas generan las soluciones posibles al problema mediante...
A:3
...un recorrido guiado por una cola de prioridad de donde se extraen primero los nodos que representan los subárboles más prometedores del espacio de soluciones.
...un recorrido guiado por estimaciones de las mejores ramas del árbol que representa el espacio de soluciones.
...un recorrido en profundidad del árbol que representa el espacio de soluciones.

Q: El problema de la función compuesta mínima consiste en encontrar a partir de un conjunto de funciones dadas, la secuencia mínima de composiciones de estas que permita transformar un número n en otro m. Se quiere resolver mediante ramificación y poda. ¿Cuál sería la forma más adecuada de representar las posibles soluciones?
A:1
Mediante un vector de booleanos.
Mediante un vector de reales.
Este problema no se puede resolver usando ramificación y poda si no se fija una cota superior al número total de aplicaciones de funciones.

Q: Estudiad la relación de recurrencia: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ pT(n/q) + g(n) & \text{en otro caso} \end{cases}$ (donde p y q son enteros mayores que 1). Di cuál de los siguientes esquemas algorítmicos produce de manera natural relaciones de recurrencia así.
A:1
Divide y vencerás.
Programación dinámica.
Ramificación y poda.

Q: Sea f(n) la solución de la relación de recurrencia $f(n) = 2f(n-1) + 1$; $f(1) = 1$. Indicad cuál de estas tres expresiones es cierta
A:1
$f(n) \in \Theta(2^n)$
$f(n) \in \Theta(n^2)$
$f(n) \in \Theta(n)$

Q: Sea f(n) la solución de la relación de recurrencia $f(n) = 2f(n/2) + n$; $f(1) = 1$. Indicad cuál de estas tres expresiones es cierta
A:1
$f(n) \in \Theta(n \log n)$
$f(n) \in \Theta(n)$
$f(n) \in \Theta(n^2)$

Q: Tenemos un conjunto de n enteros positivos y queremos encontrar el subconjunto de tamaño m y de suma mínima.
A:3
Para encontrar la solución habría que probar con todas las combinaciones posibles de m enteros, con lo que la técnica de ramificación y poda no aporta nada con respecto a vuelta atrás.
Lo más adecuado sería usar una técnica de ramificación y poda, aunque en el peor caso el coste temporal asintótico (o complejidad temporal) sería exponencial.
Una técnica voraz daría una solución óptima.

Q: Di cuál de estos resultados de coste temporal asintótico es falso
A:3
La ordenación de un vector usando el algoritmo quicksort requiere en el peor caso $\Omega(n^2)$.
La búsqueda binaria en un vector ordenado requiere en el peor caso un tiempo en $O(\log n)$.
La ordenación de un vector usando el algoritmo mergesort requiere en el peor caso un tiempo de $\Omega(n^2)$.

Q: ¿Se puede reducir el coste temporal de un algoritmo recursivo almacenando los resultados devueltos por las llamadas recursivas?
A:2
No, ello no reduce el coste temporal ya que las llamadas recursivas se deben realizar de cualquier manera.
Sí, si se repiten llamadas a la función con los mismos argumentos.
No, solo se puede reducir el coste convirtiendo el algoritmo recursivo en iterativo.

Q: La versión del quicksort que ocupa como pivote el elemento que ocupa la posición central
A:3
No presenta caso mejor y peor para instancias del mismo tamaño.
Se comporta peor cuando el vector ya está ordenado.
Se comporta mejor cuando el vector ya está ordenado.

Q: La solución recursiva ingenua (pero correcta) a un problema de optimización llama más de una vez a la función con los mismos parámetros. Una de las siguientes tres afirmaciones es falsa.
A:3
Se puede mejorar la eficiencia del algoritmo guardando en una tabla el valor devuelto para cada conjunto de parámetros de cada llamada cuando esta se produce por primera vez.
Se puede mejorar la eficiencia del algoritmo definiendo de antemano el orden en el que se deben calcular las soluciones a los subproblemas y llenando una tabla en ese orden.
Se puede mejorar la eficiencia del algoritmo convirtiendo el algoritmo recursivo directamente en iterativo sin cambiar su funcionamiento básico.

Q: El coste temporal del algoritmo de ordenación por inserción es
A:2
$O(n \log n)$
$O(n^2)$
$O(n)$

Q: El coste temporal asintótico de insertar un elemento en un vector ordenado de forma que continúe ordenado es
A:1
$O(n)$
$O(\log n)$
$O(n^2)$

Q: ¿Qué tienen en común el algoritmo que obtiene el k-ésimo elemento más pequeño de un vector (estudiado en clase) y el algoritmo de ordenación Quicksort?
A:3
El número de llamadas recursivas que se hacen.
La combinación de las soluciones a los subproblemas.
La división del problema en subproblemas.

Q: En un algoritmo de ramificación y poda, el orden escogido para priorizar los nodos en la lista de nodos vivos...
A:3
...determina la complejidad temporal en el peor de los casos del algoritmo.
...nunca influye en el resultado.
...puede influir en el número de nodos que se descartan sin llegar a expandirlos.

Q: Dado un problema de optimización ¿cuándo se puede aplicar el método de vuelta atrás?
A:2
No solo es condición necesaria que el dominio de las decisiones sea discreto o discretizable, además debe cumplirse que se puedan emplear mecanismos de poda basados en la mejor solución hasta el momento.
Es condición necesaria (aunque no suficiente) que el dominio de las decisiones sea discreto o discretizable.
Es condición necesaria y suficiente que el dominio de las decisiones sea discreto o discretizable.

Q: Indica cuál es el coste temporal en función de n del problema siguiente 
```cpp
s = 0;
for(i = 0; i < n; i++)
	for(j = i; j < n; j++)
		s += n * i * j;
```
A:3
Es $\Theta(n)$
Es $O(n^2)$ pero no $\Omega(n^2)$
Es $\Theta(n^2)$

Q: ¿Cuál de estas estrategias para calcular el n-ésimo elemento de la serie de Fibonacci ($f(n) = f(n-1) + f(n-2)$, $f(1) = f(2) = 1$) es más eficiente?
A:2
La estrategia voraz.
Programación dinámica.
Para este problema, las dos estrategias citadas serían similares en cuanto a eficiencia.

Q: Si $f(n) \in O(n^2)$, ¿podemos decir siempre que $f(n) \in O(n^3)$?
A:1
Sí ya que $n^2 \in O(n^3)$.
No, ya que $n^2 \notin O(n^3)$.
Solo para valores bajos de n.

Q: ¿Para cuál de estos problemas de optimización se conoce una solución voraz?
A:2
El problema de la asignación de coste mínimo de n tareas a n trabajadores cuando el coste de asignar la tarea i al trabajador j, $c_{ij}$ está tabulado en una matriz.
El árbol de recubrimiento mínimo para un grafo no dirigido con pesos.
El problema de la mochila discreta.

Q: Cuando se usa un algoritmo voraz para abordar la resolución de un problema de optimización por selección discreta (es decir, un problema para el cual la solución consiste en encontrar un subconjunto del conjunto de elementos que optimiza una determinada función), ¿cuál de estas tres cosas es imposible que ocurra?
A:3
Que la solución no sea la óptima.
Que el algoritmo no encuentre ninguna solución.
Que se reconsidere la decisión ya tomada anteriormente respecto a la selección de un elemento a la vista de la decisión que se debe tomar en un instante.

Q: ¿Cuál de estas expresiones es falsa?
A:3
$n + n \log n \in \Theta(n)$
$n + n \log n \in \Omega(n)$
$2n^2 + 3n + 1 \in O(n^3)$

Q: Sea $g(n) = \sum_{i=0}^{K} a_i n^i$. Di cuál de las siguientes afirmaciones es falsa:
A:1
Las otras dos afirmaciones son ambas falsas.
$g(n) \in \Theta(n^K)$
$g(n) \in \Omega(n^K)$

Q: Sea A una matriz cuadrada n × n. Se trata de buscar una permutación de las columnas tal que la suma de los elementos de la diagonal de la matriz resultante sea mínima. Indicad cuál de las siguientes afirmaciones es falsa.
A:1
La complejidad temporal de la mejor solución posible al problema es $O(n \log n)$.
Si se construye una solución al problema basada en el esquema de ramificación y poda, una buena elección de cotas optimistas y pesimistas podría evitar la exploración de todas las permutaciones posibles.
La complejidad temporal de la mejor solución posible al problema está en $\Omega(n^2)$.

Q: ¿Garantiza el uso de una estrategia "divide y vencerás" la existencia de una solución de complejidad temporal polinómica a cualquier problema?
A:3
Sí, en cualquier caso.
Sí, pero siempre que la complejidad temporal conjunta de las operaciones de descomposición del problema y la combinación de las soluciones sea polinómica.
No.

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la posición central...
A:3
...no presenta caso mejor y peor para instancias del mismo tamaño.
...se comporta peor cuando el vector ya está ordenado.
...se comporta mejor cuando el vector ya está ordenado.

Q: La mejora que en general aporta la programación dinámica frente a la solución ingenua se consigue gracias al hecho de que...
A:3
...en la solución ingenua se resuelve pocas veces un número relativamente grande de subproblemas distintos.
...el número de veces que se resuelven los subproblemas no tiene nada que ver con la eficiencia de los problemas resueltos mediante programación dinámica.
...en la solución ingenua se resuelve muchas veces un número relativamente pequeño de subproblemas distintos.

Q: La estrategia de ramificación y poda genera las soluciones posibles al problema mediante
A:3
Un recorrido en profundidad del árbol que representa el espacio de soluciones.
Un recorrido en anchura del árbol que representa el espacio de soluciones.
Un recorrido guiado por estimaciones de las mejores ramas del árbol que representa el espacio de soluciones.

Q: Un tubo de n cm de largo se puede cortar en segmentos de 1 centímetro, 2 centímetros etc. Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es que más ingresos nos producirá. Se quiere resolver el problema mediante vuelta atrás ¿cuál sería la forma más adecuada de representar las posibles soluciones?
A:3
Un par de enteros que indiquen los cortes realizados y el valor acumulado.
Un vector de booleanos.
Una tabla que indique para cada posición donde se va a cortar cada uno de los posibles valores acumulados.

Q: ¿Cuál de los siguientes algoritmos proveería una cota pesimista para el problema de encontrar el camino más corto entre dos ciudades (se supone que el grafo es conexo)?
A:2
Calcular la distancia geométrica (en línea recta) entre la ciudad origen y destino.
Calcular la distancia recorrida moviéndose al azar por el grafo hasta llegar (por azar) a la ciudad destino.
Para todas las ciudades que son alcanzables en un paso desde la ciudad inicial, sumar la distancia a dicha ciudad y la distancia geométrica hasta la ciudad destino.

Q: Si $f(n) \in O(n^3)$, ¿puede pasar que $f(n) \in O(n^2)$?
A:2
Solo para valores bajos de n.
Es perfectamente posible, ya que $O(n^2) \subset O(n^3)$.
No, porque $n^3$ "no incrementa" $O(n^2)$.

Q: Un problema de tamaño n puede transformarse en $O(n)$ en siete de tamaño n/7, por otro lado la solución al problema cuando la talla es 1 requiere tiempo constante ¿qué cota es más ajustada?
A:1
$O(n \log n)$
$O(n)$
$O(n^2)$

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es menor que el valor de una cota optimista? (entendiendo que ambas cotas se aplican sobre el mismo nodo)
A:2
En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
Sí, siempre es así.

Q: En los algoritmos de ramificación y poda...
A:2
Una cota pesimista es el valor que a lo sumo alcanza cualquier nodo factible que no es el óptimo.
Una cota optimista es necesariamente un valor insuperable, de no ser así se podría podar el nodo que conduce a la solución óptima.
Una cota optimista es necesariamente un valor alcanzable, de no ser así no está garantizado que se encuentre la solución óptima.

Q: El coste temporal asintótico del programa 
```cpp
s = 0;
for(i = 0; i < n; i++)
	for(j = i; j < n; j++)
		s += i * j;
```
y del programa 
```cpp
s = 0;
for(i = 0; i < n; i++)
	for(j = 0; j < n; j++)
		s += i * i * j
```
A:2
El del segundo, menor que el primero.
Iguales.
El del primero, menor que el segundo.

Q: ¿Para qué sirven las cotas pesimistas en ramificación y poda?
A:3
Para descartar nodos basándose en la preferencia por algún otro nodo ya completado.
Para tener la certeza de que la cota optimista está bien calculada.
Para descartar nodos basándose en el beneficio esperado.

Q: La complejidad en el mejor de los casos de un algoritmo de ramificación y poda
A:1
Puede ser polinómica con el número de decisiones a tomar.
Suele ser polinómica con el número de alternativas por cada decisión.
Es siempre exponencial con el número de decisiones a tomar.

Q: Cuando la descomposición de un problema da lugar a subproblemas de tamaño similar al original, muchos de los cuales se repiten, ¿qué esquema es a priori más apropiado?
A:2
Ramificación y poda.
Programación dinámica.
Divide y vencerás.

Q: Dado un problema de optimización, el método voraz...
A:1
...garantiza la solución óptima solo para determinados problemas.
...siempre obtiene la solución óptima.
...siempre obtiene una solución factible.

Q: Al resolver el problema del viajante de comercio mediante backtracking asumiendo un grafo de n vértices totalmente conexo ¿cuál de estas es una buena cota pesimista al iniciar la búsqueda?
A:2
Se ordenan las aristas restantes de menor a mayor distancia y se calcula la suma de las n aristas más cortas.
Se resuelve el problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido.
Se multiplica n por la distancia de la arista más corta que nos queda por considerar.

Q: ¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, una solución voraz (greedy) que es óptima?
A:2
El árbol de cobertura de coste mínimo de un grafo conexo.
El problema de la mochila discreta.
El problema de la mochila continua o con fraccionamiento.

Q: La complejidad en el peor de los casos de un algoritmo de ramificación y poda
A:1
Es exponencial con el número de decisiones a tomar.
Puede ser polinómica con el número de decisiones a tomar.
Puede ser exponencial con el número de alternativas por cada decisión.

Q: Un problema de tamaño n puede transformarse en tiempo $O(n^2)$ en nueve de tamaño n/3, por otro lado la solución al problema cuando la talla es 1 requiere un tiempo constante, ¿cuál de estas clases de coste temporal asintótico es la más ajustada?
A:2
$O(n \log n)$
$O(n^2 \log n)$
$O(n^2)$

Q: Cuando la descomposición recursiva de un problema da lugar a subproblemas de tamaño similar, ¿qué esquema promete ser más apropiado?
A:2
El método voraz.
Programación dinámica.
Divide y vencerás, siempre que se garantice que los subproblemas no son del mismo tamaño.

Q: Al resolver el problema del viajante de comercio mediante vuelta atrás, ¿cuál de estas cotas optimistas se espera que pode mejor el árbol de búsqueda?
A:2
Se resuelve el resto del problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido.
Se ordenan las aristas restantes de menor a mayor distancia y se calcula la suma de las k aristas más cortas, donde k es el número de saltos que nos quedan por dar.
Se multiplica k por la distancia de la arista más corta que nos queda por considerar, donde k es el número de saltos que nos quedan por dar.

Q: El uso de funciones de cota en ramificación y poda...
A:3
...garantiza que el algoritmo va a ser más eficiente ante cualquier instancia del problema.
...transforma en polinómicas complejidades que antes eran exponenciales.
...puede reducir el número de instancias del problema que pertenecen al caso peor.

Q: Un problema de tamaño n puede transformarse en tiempo $O(n^2)$ en otro de tamaño n-1. Por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante, ¿cuál de estas clases de coste temporal asintótico es la más ajustada?
A:2
$O(2^n)$
$O(n^3)$
$O(n^2)$

Q: Cuando se resuelve usando backtracking un problema de n decisiones en el que siempre hay como mínimo 2 opciones para cada decisión, ¿cuál de las siguientes complejidades es la mejor que nos podemos encontrar?
A:3
$O(n!)$
$O(n^2)$
$O(2^n)$

Q: Di cuál de estos tres algoritmos no es un algoritmo de divide y vencerás
A:2
Mergesort.
Algoritmo de Prim.
Quicksort.

Q: La solución recursiva ingenua a un determinado problema de optimización muestra estas dos características: por un lado, se basa en obtener soluciones óptimas a problemas parciales más pequeños y por otro, estos subproblemas se resuelven más de una vez durante el proceso recursivo. Este problema es candidato a tener una solución alternativa basada en...
A:3
Un algoritmo del estilo de divide y vencerás.
Un algoritmo voraz.
Un algoritmo de programación dinámica.

Q: Se desea encontrar el camino más corto entre dos ciudades. Para ello se dispone de una tabla con la distancia entre los pares de ciudades en los que hay carreteras o un valor centinela (por ejemplo, -1) si no hay por lo que para ir de la ciudad inicial a la final es posible que haya que pasar por varias ciudades. También se conocen las coordenadas geográficas de cada ciudad y por tanto la distancia geométrica (en línea recta) entre cada par de ciudades. Se pretende acelerar la búsqueda de un algoritmo de ramificación y poda priorizando los nodos vivos (ciudades) que estén a menor distancia geográfica de la ciudad objetivo
A:3
El nuevo algoritmo siempre será más rápido.
Esta estrategia no asegura que se obtenga el camino más corto.
El nuevo algoritmo no garantiza que vaya a ser más rápido para todas las instancias del problema posibles.

Q: ¿Para cuál de estos problemas de optimización existe una solución voraz?
A:1
El árbol de recubrimiento mínimo para un grafo no dirigido con pesos.
El problema de la mochila discreta.
El problema de la asignación de coste mínimo de n tareas a n trabajadores cuando el coste de asignar la tarea i al trabajador j, $c_{ij}$ está tabulado en una matriz.

Q: La mejor solución que se conoce para el problema de la mochila continua sigue el esquema...
A:3
...voraz.
...ramificación y poda.
...divide y vencerás.

Q: Si para resolver un mismo problema usamos un algoritmo de vuelta atrás y lo modificamos mínimamente para convertirlo en un algoritmo de ramificación y poda, ¿qué cambiamos realmente?
A:2
Cambiamos la función que damos a la cota pesimista.
El algoritmo puede aprovechar mejor las cotas optimistas.
La comprobación de las soluciones factibles: en ramificación y poda no es necesario puesto que solo genera nodos factibles.

Q: En los algoritmos de ramificación y poda ¿el valor de una cota pesimista es mayor que el valor de una cota optimista? (entendiendo que ambas cotas se aplican sobre el mismo nodo)
A:3
No, nunca es así.
En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.

Q: Uno de estos tres problemas no tiene una solución eficiente que siga el esquema de programación dinámica
A:3
El problema de la mochila discreta.
El problema de las torres de Hanoi.
El problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud.

Q: En una cuadrícula se quiere dibujar el contorno de un cuadrado de n casillas de lado, ¿cuál será la complejidad temporal del mejor algoritmo que pueda existir?
A:3
$O(n^2)$
$O(\sqrt{n})$
$O(n)$

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
A:1
...será más eficiente cuanto más equitativa sea la división en subproblemas.
Las dos anteriores son ciertas.
...nunca tendrá una complejidad exponencial.

Q: Sea la siguiente relación de recurrencia:
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 2T(n/2) + g(n) & \text{en otro caso} \end{cases}$
Si $T(n) \in O(n^2)$, ¿en cuál de estos tres casos nos podemos encontrar?
A:3
$g(n) = 1$
$g(n) = n$
$g(n) = n^2$

Q: Una de estas tres situaciones no es posible
A:3
$f(n) \in O(n)$ y $f(n) \in \Omega(1)$
$f(n) \in O(n)$ y $f(n) \in O(n^2)$
$f(n) \in \Theta(n^2)$ y $f(n) \in O(n)$

Q: La función $\Gamma$ de un número semiEntero positivo (un número es semiEntero si al restarle 0.5 es entero) se define como 
```cpp
double gamma(double n) {
	if(n == 0.5)
		return sqrt(PI);
	return n * gamma(n-1);
}
```
¿Se puede calcular usando programación dinámica iterativa?
A:2
No, ya que el índice del almacén sería un número real y no entero.
Sí.
No, ya que no podríamos almacenar los resultados intermedios en el almacén.

Q: Dado un problema de optimización cualquiera, ¿la estrategia de vuelta atrás garantiza la solución óptima?
A:3
Sí, puesto que este método analiza todas las posibilidades.
Sí, siempre que el dominio de las decisiones sea discreto o discretizable y además se empleen mecanismos de poda basados en la mejor solución hasta el momento.
Es condición necesaria que el dominio de las decisiones sea discreto o discretizable y que el número de decisiones a tomar esté acotado.

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición...
A:2
...no presenta caso mejor y peor para instancias del mismo tamaño.
...se comporta peor cuando el vector ya está ordenado.
...se comporta mejor cuando el vector ya está ordenado.

Q: ¿Garantiza el uso de una estrategia "divide y vencerás" la existencia de una solución de complejidad temporal polinómica a cualquier problema?
A:3
Sí, en cualquier caso.
Sí, pero siempre que la complejidad temporal conjunta de las operaciones de descomposición del problema y la combinación de las soluciones sea polinómica.
No.

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es mayor que el valor de una cota optimista? (se entiende que ambas cotas se aplican sobre el mismo nodo)
A:2
En general, sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
No, nunca es así.

Q: La complejidad temporal en el mejor de los casos de un algoritmo recursivo
A:2
Siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo.
Las demás opciones son falsas.
Coincide con el valor del caso base de la ecuación de recurrencia que expresa la complejidad del algoritmo.

Q: La complejidad en el mejor de los casos de un algoritmo de ramificación y poda
A:2
Es siempre exponencial con el número de decisiones a tomar.
Puede ser polinómica con el número de decisiones a tomar.
Suele ser polinómica con el número de alternativas por cada decisión.

Q: La solución recursiva ingenua (pero correcta) a un problema de optimización llama más de una vez a la función con los mismos parámetros. Una de las siguientes afirmaciones es falsa
A:3
Se puede mejorar la eficiencia del algoritmo definiendo de antemano el orden en el que se deben calcular las soluciones a los subproblemas y llenando una tabla en ese orden.
Se puede mejorar la eficiencia del algoritmo guardando en una tabla el valor devuelto para cada conjunto de parámetros de cada llamada cuando esta se produce por primera vez.
Se puede mejorar la eficiencia del algoritmo convirtiendo el algoritmo recursivo directamente en iterativo sin cambiar su funcionamiento básico.

Q: En ausencia de cotas optimistas y pesimistas, la estrategia de vuelta atrás...
A:1
...no recorre todo el árbol si hay manera de descartar subárboles que representan conjuntos de soluciones no factibles.
...no se puede usar para resolver problemas de optimización.
...debe recorrer siempre todo el árbol.

Q: La mejor solución que se conoce para el problema de la mochila continua sigue el esquema
A:1
Divide y vencerás.
Voraz.
Ramificación y poda.

Q: ¿Para cuál de estos problemas de optimización existe una solución voraz?
A:2
El problema de la mochila discreta.
El árbol de recubrimiento mínimo para un grafo no dirigido con pesos.
El problema de la asignación de coste mínimo de n tareas a n trabajadores cuando el coste de asignar la tarea i al trabajador j, $c_{ij}$ está tabulado en una matriz.

Q: Dado el problema de las torres de Hanoi resuelto mediante divide y vencerás, ¿cuál de las siguientes relaciones de recurrencia expresa mejor su complejidad temporal para el caso general, siendo n el número de discos?
A:1
$T(n) = 2T(n - 1) + 1$
$T(n) = T(n - 1) + n$
$T(n) = 2T(n - 1) + n$

Q: Si un problema de optimización lo es para una función que toma valores continuos
A:2
El uso de memoria de la programación dinámica iterativa y de la programación dinámica recursiva es el mismo independientemente de si el dominio es discreto o continuo.
La programación dinámica recursiva puede resultar mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
La programación dinámica iterativa siempre es mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.

Q: Se desea resolver el problema de la potencia enésima ($x^n$), asumiendo que n es par y que se utilizará la siguiente recurrencia: pot(x,n) = pot(x,n/2) * pot(x,n/2); ¿Qué esquema resulta ser más eficiente en cuanto al coste temporal?
A:3
Divide y vencerás.
En este caso tanto programación dinámica como divide y vencerás, resultan ser equivalentes en cuanto a la complejidad temporal.
Programación dinámica.

Q: Un tubo de n centímetros de largo se puede cortar en segmentos de 1 ctm., 2 ctm, etc. Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es la que más ingresos nos producirá. Se quiere resolver el problema mediante vuelta atrás ¿cuál sería la forma más adecuada de representar las posibles soluciones?
A:2
Una tabla que indique, para cada posición donde se va a cortar, cada uno de los posibles valores acumulados.
Un vector de booleanos.
Un par de enteros que indiquen los cortes realizados y el valor acumulado.

Q: Un algoritmo recursivo basado en divide y vencerás
A:2
Nunca tendrá una complejidad exponencial.
Será más eficiente cuanto más equitativa sea la división en subproblemas.
Las dos anteriores son correctas.

Q: Uno de estos tres problemas no tiene una solución eficiente que siga el esquema de programación dinámica
A:3
El problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud.
El problema de la mochila discreta.
El problema de las torres de Hanoi.

Q: Dado un problema de maximización resuelto mediante un esquema de ramificación y poda, ¿qué ocurre si la cota optimista resulta ser un valor excesivamente elevado?
A:2
Que se podría explorar menos nodos de los necesarios.
Que se podría explorar más nodos de los necesarios.
Que se podría podar el nodo que conduce a la solución óptima.

Q: Dado un problema de minimización resuelto mediante un esquema de ramificación y poda, ¿qué propiedad cumple una cota optimista?
A:2
Siempre es mayor o igual que la mejor solución posible alcanzada.
Las otras dos opciones son ambas falsas.
Asegura un ahorro en la comprobación de todas las soluciones factibles.

Q: ¿Qué nos proporciona la media entre el coste temporal asintótico (o complejidad temporal) en el peor caso y el coste temporal asintótico en el mejor caso?
A:3
El coste temporal asintótico en el caso medio.
El coste temporal promedio.
Nada de interés.

Q: Cuando se usa un algoritmo voraz para abordar la resolución de un problema de optimización por selección directa (es decir, un problema para el cual la solución consiste en encontrar un subconjunto del conjunto de elementos que optimiza una determinada función) ¿Cuál de estas tres cosas es imposible que ocurra?
A:3
Que la solución no sea la óptima.
Que el algoritmo no encuentre ninguna solución.
Que se reconsidere la decisión ya tomada anteriormente respecto a la selección de un elemento a la vista de la decisión que se debe tomar en el instante actual.

Q: ¿Cuál sería la complejidad temporal de la siguiente función tras aplicar programación dinámica?
```cpp
double f(int n, int m) {
	if(n == 0)
		return 1;
	return m * f(n-1, m) * f(n-2, m);
}
```
A:1
$\Theta(n)$
$\Theta(n \cdot m)$
$\Theta(n^2)$

Q: En los algoritmos de ramificación y poda...
A:3
Una cota optimista es necesariamente un valor alcanzable, de no ser así no está garantizado que se encuentre la solución óptima.
Una cota pesimista es el valor que a lo sumo alcanza cualquier nodo factible que no es el óptimo.
Una cota optimista es necesariamente un valor insuperable, de no ser así se podría podar el nodo que conduce a la solución óptima.

Q: ¿Qué se deduce de f(n) y g(n) si se cumple $\lim_{n \to \infty} \frac{f(n)}{g(n)} = K$, con K distinto de 0?
A:1
$f(n) \in O(g(n))$ y $g(n) \in O(f(n))$
$g(n) \in O(f(n))$ pero $f(n) \notin O(g(n))$
$f(n) \in O(g(n))$ pero $g(n) \notin O(f(n))$

Q: Se desea encontrar el camino más corto entre dos ciudades. Para ello se dispone de una tabla con la distancia entre los pares de ciudades en los que hay carreteras o un valor centinela (por ejemplo, -1) si no hay, por lo que para ir de la ciudad inicial a la final es posible que haya que pasar por varias ciudades. También se conocen las coordenadas geográficas de cada ciudad y por tanto la distancia geométrica (en línea recta) entre cada par de ciudades. Se pretende acelerar la búsqueda de un algoritmo de ramificación y poda priorizando los nodos vivos (ciudades) que estén a menor distancia geográfica de la ciudad objetivo
A:2
El nuevo algoritmo siempre será más rápido.
El nuevo algoritmo no garantiza que vaya a ser más rápido para todas las instancias del problema posibles.
Esta estrategia no asegura que se obtenga el camino más corto.

Q: Un problema de tamaño n puede transformarse en tiempo $O(n^2)$ en otro de tamaño n-1, por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante, ¿cuál de estas clases de coste temporal asintótico es la más ajustada?
A:1
$O(n^3)$
$O(n^2)$
$O(2^n)$

Q: Se desea ordenar una lista enlazada de n elementos haciendo uso del algoritmo Mergesort. En este caso, al tratarse de una lista, la complejidad temporal asintótica de realizar la división en subproblemas resulta ser lineal con el tamaño de esa lista. ¿Cuál sería entonces el coste temporal de realizar dicha ordenación?
A:1
$\Theta(n \log n)$
Ninguna de las otras dos opciones es cierta.
$\Theta(n^2)$

Q: La complejidad temporal en el mejor de los casos
A:1
Es una función del tamaño o talla del problema que tiene que estar definida para todos los posibles valores de esta.
Las otras dos opciones son ciertas.
Es el tiempo que tarda el algoritmo en resolver el problema de tamaño o talla más pequeña que se le puede presentar.

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
A:3
...nunca tendrá un coste temporal asintótico (o complejidad temporal) exponencial.
Las otras dos opciones son ambas verdaderas.
...alcanza su máxima eficiencia cuando el problema de tamaño n se divide en "a" problemas de tamaño n/a.

Q: ¿En ramificación y poda, tiene sentido utilizar la cota optimista de los nodos como criterio para ordenar la lista de nodos vivos?
A:1
Sí, aunque no es una garantía de que sea una buena estrategia de búsqueda.
Sí, en el caso de que se ordene la lista de nodos vivos, siempre debe hacerse según el criterio de la cota optimista.
No, la cota optimista solo se utiliza para determinar si una n-tupla es prometedora.

Q: Una de las prácticas de laboratorio consistió en el cálculo empírico de la complejidad temporal promedio del algoritmo de ordenación de vectores Quicksort tomando como centinela el elemento del vector que ocupa la posición central. ¿Cuál es el orden de complejidad que se obtuvo?
A:2
$n^2$
$n \log n$
$n \log^2 n$

Q: El esquema de vuelta atrás...
A:1
Garantiza que encuentra la solución óptima a cualquier problema de selección discreta.
Las otras dos opciones son ambas verdaderas.
Se puede aplicar a cualquier tipo de problema aunque el coste temporal es elevado.

Q: Sea la siguiente relación de recurrencia: $T(n) = 1$ si $n \leq 1$; $2T(n/2) + g(n)$ en otro caso. Si $T(n) \in O(n)$, ¿en cuál de estos tres casos nos podemos encontrar?
A:3
$g(n) = \log n$
$g(n) = n^2$
Las otras dos opciones son ambas ciertas.

Q: El uso de funciones de cota en ramificación y poda
A:2
Transforma en polinómicas complejidades que antes eran exponenciales.
Puede reducir el número de instancias del problema que pertenecen al caso peor.
Garantiza que el algoritmo va a ser más eficiente ante cualquier instancia del problema.

Q: El esquema voraz...
A:3
Puede que no encuentre una solución pero si lo hace se garantiza que es óptima.
Garantiza encontrar una solución a cualquier problema, aunque puede que no sea óptima.
Las otras dos opciones son ambas falsas.

Q: El coste temporal asintótico de insertar un elemento en un vector ordenado de forma que continúe ordenado es...
A:1
...$O(n)$
...$O(\log n)$
...$O(n^2)$

Q: Decidid cuál de estas tres es la cota pesimista más ajustada al valor óptimo de la mochila discreta
A:2
El valor de la mochila continua correspondiente.
El valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor específico de los objetos.
El valor de una mochila que contiene todos los objetos aunque se pase del peso máximo permitido.

Q: Dada la siguiente función:
```cpp
int exa(string &cad, int pri, int ult) {
	if(pri >= ult) {
		return 1;
	}
	else {
		if(cad[pri] == cad[ult]) {
			return exa(cad, pri+1, ult-1);
		}
		else {
			return 0;
		}
	}
}
```
¿Cuál es su complejidad temporal asintótica?
A:1
$O(n)$
$O(n \log n)$
$O(n^2)$

Q: ¿Qué estrategia de búsqueda es a priori más apropiada en un esquema de vuelta atrás?
A:2
Explorar primero los nodos con mejor cota optimista.
En el esquema de vuelta atrás no se pueden definir estrategias de búsqueda.
Explorar primero los nodos que están más completados.

Q: Sea la siguiente relación de recurrencia: $T(n) = 1$ si $n \leq 1$; $2T(n/2) + g(n)$ en otro caso. Si $T(n) \in O(n^2)$, ¿en cuál de los casos nos podemos encontrar?
A:2
$g(n) = 1$
$g(n) = n^2$
$g(n) = n$

Q: Si el coste temporal de un algoritmo es T(n), ¿cuál de las siguientes situaciones es imposible?
A:3
$T(n) \in \Omega(n)$ y $T(n) \in \Theta(n^2)$
$T(n) \in O(n)$ y $T(n) \in \Theta(n)$
$T(n) \in \Theta(n)$ y $T(n) \in \Omega(n^2)$

Q: Cuando la descomposición recursiva de un problema da lugar a subproblemas de tamaño similar, ¿qué esquema promete ser más apropiado?
A:1
Programación dinámica.
Divide y vencerás, siempre que se garantice que los subproblemas no son del mismo tamaño.
Voraz.

Q: De las siguientes afirmaciones marca la que es verdadera
A:1
En un esquema de vuelta atrás, las cotas pesimistas no tienen sentido si lo que se pretende es obtener todas las soluciones factibles.
Las cotas pesimistas no son compatibles con un esquema de vuelta atrás.
El esquema de vuelta atrás no es compatible con el uso conjunto de cotas pesimistas y optimistas.

Q: Si $f \in \Omega(g_1)$ y $f \in \Omega(g_2)$ entonces
A:2
$f \notin \Omega(\min(g_1, g_2))$
$f \in \Omega(g_1 + g_2)$
$f \in \Omega(g_1 \cdot g_2)$

Q: ¿Qué ocurre si la cota pesimista de un nodo se corresponde con una solución que no es factible?
A:1
Que el algoritmo sería incorrecto pues podría descartarse un nodo que conduce a la solución óptima.
Que el algoritmo sería más lento pues se explorarían más nodos de los necesarios.
Nada especial, las cotas pesimistas no tienen por qué corresponderse con soluciones factibles.

Q: Dado un problema de optimización cualquiera, ¿la estrategia de backtracking garantiza la solución óptima?
A:3
Sí, siempre que el dominio de las decisiones sea discreto o discretizable y además se empleen mecanismos de poda basados en la mejor solución hasta el momento.
Sí, puesto que ese método analiza todas las posibilidades.
Es condición necesaria que el dominio de las decisiones sea discreto o discretizable y que el número de decisiones a tomar esté acotado.

Q: Al resolver el problema del viajante de comercio mediante backtracking, ¿cuál de estas cotas optimistas se espera que pode mejor el árbol de búsqueda?
A:2
Se multiplica k por la distancia de la arista más corta que nos queda por considerar donde k es el número de saltos que nos quedan por dar.
Se ordenan las aristas restantes de menor a mayor distancia y se calcula la suma de las k aristas más cortas, donde k es el número de saltos que nos quedan por dar.
Se resuelve el resto del problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido.

Q: ¿Qué complejidad se obtiene a partir de la relación de recurrencia $T(n) = 8T(n/2) + n^3$ con $T(1) = O(1)$?
A:2
$O(n \log n)$
$O(n^3 \log n)$
$O(n^3)$

Q: En el esquema de ramificación y poda, ¿qué estructura es la más adecuada si queremos realizar una exploración por niveles?
A:3
Pila.
Cola de prioridad.
Cola.

Q: Que tiene que valer b en la relacion de recurrencia $T(n) = 1$ si $n < 1$; $1+bT(n-1)$ si $n > 1$ para que $T(n) = 2^n$
A:2
1
2
0

Q: En la solucion al problema de la mochila continua ¿por que es conveniente la ordenacion previa de los objetos?
A:2
Porque si no se hace no es posible garantizar que la toma de decisiones siga un criterio voraz.
Para reducir la complejidad temporal en la toma de cada decision de $O(n)$ a $O(1)$, donde n es el numero de objetos a considerar.
Para reducir la complejidad temporal en la toma de cada decision: de $O(n^2)$ a $O(n \log n)$, donde n es el numero de objetos a considerar.

Q: Cual es el coste espacial asintotico del siguiente algoritmo:
```cpp
int f(int n) {
	int a = 1, r = 0;
	for(int i = 0; i < n; i++) {
		r = a + r;
		a = 2 * r;
	}
}
```
A:3
$O(n)$
$O(\log(n))$
$O(1)$

Q: Con respecto al tamaño del problema ¿Cual es el orden de complejidad temporal asintotica de la siguiente funcion? `void traspuesta(mat & A)`
A:2
constante
lineal
cuadratico

Q: Se pretende implementar mediante programacion dinamica iterativa la funcion recursiva:
```cpp
unsigned f(unsigned y, unsigned x) { // suponemos y >= x
	if (x == 0 || y == x)
		return 1;
	return f(y-1, x-1) + f(y-1, x);
}
```
¿Cual es la mejor complejidad espacial que se puede conseguir?
A:3
$O(1)$
$O(y^2)$
$O(y)$

Q: Un tubo de n centimetros de largo se puede cortar en segmentos de 1 centimetro, 2 centimetros, etc. Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es la que mas ingresos nos producira. Di cual de estas tres afirmaciones es falsa
A:3
Es posible evitar hacer la evaluacion exhaustiva "de fuerza bruta" guardando, para cada posible longitud $j < n$ el precio mas elevado posible que se puede obtener dividiendo el tubo correspondiente.
Hacer una evaluacion exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $\Theta(2^n)$.
Hacer una evaluacion exhaustiva de "fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $\Theta(n!)$.

Q: Asumiendo que n es par, las siguientes recurrencias matematicas, obtienen el valor de la potencia enésima ($x^n$), cual de las siguientes afirmaciones es cierta
A:2
Ambas recurrencias son equivalentes en cuanto a complejidad temporal
La primera recurrencia resultara ser la mas eficiente siempre que se utilice la programacion dinamica recursiva para su implementacion.
La segunda recurrencia resulta ser la mas eficiente siempre que se utilice divide y venceras.

Q: Los algoritmos de ordenacion quicksort y mergesort
A:2
tienen el mismo coste temporal asintotico en el caso peor
tienen el mismo coste temporal asintotico en el caso mejor
tienen el mismo coste temporal en los dos casos

Q: ¿Cual es la mejor complejidad espacial que se puede conseguir
A:3
$O(1)$
$O(y^2)$
$O(y)$

Q: Se pretende implementar mediante programacion dinamica iterativa la funcion recursiva:
```cpp
float f(unsigned x, int y) {
	if(y < 0)
		return 0;
	float A = 0.0;
	if(v1[y] <= x)
		A = v2[y] + f(x-v1[y], y-1);
	float B = f(x, y-1);
	return min(A, 2+B);
}
```

Q: Un informatico quiere subir a una montana y para ello decide que tras cada paso, el siguiente debe tomarlo en la direccion de maxima pendiente hacia arriba. Ademas, entendera que ha alcanzado la cima cuando llegue a un punto en el que no haya ninguna direccion que sea cuesta arriba. ¿que tipo de algoritmo esta usando nuestro informatico?
A:2
un algoritmo de programacion dinamica.
un algoritmo voraz
un algoritmo divide y venceras

Q: Tenemos un vector ordenado de tamaño $n_o$ y un vector desordenado de tamaño $n_d$, queremos obtener un vector ordenado con todos los elementos ¿Que sera mas rapido?
A:2
Insertar los elementos del vector desordenado (uno a uno) en el vector ordenado.
Ordenar el desordenado y luego mezclar las listas.
Depende de si $n_o > n_d$ o no

Q: Decid cual de estas tres es la cota optimista mas ajustada al valor optimo de la mochila discreta:
A:3
el valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor especifico de los objetos
el valor de una mochila que contiene todos los objetos aunque se pase del peso maximo
el valor de la mochila continua correspondiente

Q: Queremos resolver por ramificacion y poda el problema de la mochila discreta.Si resolvemos el mismo problema de la forma voraz PERMITIENDO COGER OBJETOS FRACCIONADOS pero sin ordenar previamente los objetos por valor/peso, obtendremos
A:3
Una cota pesimista
Una cota optimista
Nada que podamos utilizar

Q: Sea V el conjunto de todos los valores faciales que presentan las monedas de un pais, una cantidad M¿Cual de las siguientes afirmaciones es falsa?
A:1
El algoritmo que calcularia n(M) asi seria un algoritmo voraz y tendria un coste razonable.
El algoritmo recursivo que calcularia n(M) asi tendria un coste prohibitivo
El algoritmo recursivo que calcularia n(M) se podria convertir en un algoritmo con coste razonable usando memoizacion.

Q: ¿Como se veria afectada la solucion voraz al problema de la asignacion de tareas en el caso de que se incorporaran restricciones que contemplen que ciertas tareas no pueden ser adjudicadas a ciertos trabajadores?
A:1
La solucion factible ya no estaria garantizada, es decir, pudiera ser que el algoritmo no llegue a solucion alguna
Habria que replantearse el criterio de seleccion para comenzar por aquellos trabajadores con mas restricciones en cuanto a las tareas que no pueden realizar para asegurar, al menos, una solucion factible
Ya no se garantizaria la solucion optima pero si una factible.

Q: En el metodo voraz
A:1
es habitual preparar los datos para disminuir el coste temporal de la funcion que determina cual es la siguiente decision a tomar.
siempre se encuentra solucion pero puede que no sea la optima.
el dominio de las decisiones solo pueden ser conjuntos discretos o discretizables

Q: Que tiene que valer k en la relacion de recurrencia $T(n) = 1$ si $n < 1$; $n^k + 2T(n/2)$ si $n > 1$ para que $T(n) = n \log(n)$?
A:3
0
$\log(n)$
1

Q: En la solucion al problema de la mochila continua ¿por que es conveniente la ordenacion previa de los objetos?
A:3
Para reducir la complejidad temporal en la toma de cada decision: de $O(n^2)$ a $O(n \log n)$, donde n es el numero de objetos a considerar.
Porque si no se hace no es posible garantizar que la toma de decisiones siga un criterio voraz
Para reducir la complejidad temporal en la toma de cada decision: de $O(n)$ a $O(1)$, donde n es el numero de objetos a considerar.

Q: Sea n el numero de elementos que contienen los vectores w y v, ¿cual es la complejidad temporal asintotica en funcion de n asumiendo que la llamada inicial i toma valor n? `float f(vector<float> &w, vector<unsigned> &v)`
A:1
$\Omega(n)$ y $O(n^2)$
$\Omega(n)$ y $O(2^n)$
$\Theta(2^n)$

Q: El arbol de expansion de minimo coste de un grafo
A:2
...puede utilizarse como cota pesimista para resolver el problema del viajante de comercio
...puede utilizarse como cota optimista para resolver el problema del viajante de comercio
Ninguna de las otras dos opciones es verdadera

Q: Se desea obtener todas las permutaciones de una lista compuesta por n elementos. ¿Que esquema es el mas adecuado?
A:2
divide y venceras, puesto que la division en sublistas se podria hacer en tiempo constante
vuelta atras, es el esquema mas eficiente para este problema
ramificacion y poda, puesto que con buenas funciones de cota es mas eficiente que vuelta atras

Q: Tenemos un vector ordenado y queremos comprobar si contiene un elemento dado ¿Cual sera la complejidad temporal mas ajustada para hacerlo?
A:3
El tamaño del vector
Constante con el tamaño del vector
El logaritmo del tamaño del vector

Q: Si $f \notin O(g_1)$ y $f \in O(g_2)$ entonces NO siempre se cumplira
A:2
$f \in O(\max(g_1,g_2))$
$f \in \Omega(g_1+g_2)$
$f \in \Omega(\min(g_1,g_2))$

Q: La programacion dinamica...
A:2
en algunos casos se puede utilizar para resolver problemas de optimizacion con dominios continuos pero probablemente pierda su eficacia ya que puede disminuir drasticamente el numero de subproblemas repetidos
Las otras dos opciones son ciertas
normalmente se usa para resolver problemas de optimizacion con dominios discretizables puesto que las tablas se han de indexar con este tipo de valores.

Q: Queremos resolver por vuelta atras el problema de las n reinas. El usar una buena cota optimista permitiria:
A:3
Muy probablemente, hacer que el programa vaya mas lento.
Muy probablemente, resolver el problema de forma mas rapida.
No es aplicable ese tipo de podas a este problema.

Q: Dadas las siguientes funciones: //Precondicion: $0 <= i < v.size()$; $i < j <= v.size()$ Se quiere reducir la complejidad temporal usando programacion dinamica iterativa, cual seria la complejidad espacial
A:1
cuadratica
cubica
exponencial

Q: ¿Que mecanismo se usa para acelerar el algoritmo de Prim?
A:2
El TAD "Union-find"
Mantener para cada vertice su "padre" mas cercano
Mantener una lista de los arcos ordenados segun su peso.

Q: Un algoritmo que calcula una funcion recursivamente tiene coste prohibitivo y se decide mejorarlo transformandolo en un algoritmo de programacion dinamica iterativa, pero se le añade memoizacion. ¿podria ser que el algoritmo iterativo evalue la funcion mas veces que el recursivo con memoizacion?
A:1
Podria ser, por ejemplo, como ocurre en el caso de la mochila discreta con pesos enteros.
No, ambos evaluan la funcion el mismo numero de veces.
No, el recursivo evalua la funcion muchas mas veces.

Q: Tratandose de un esquema general para resolver problemas de minimizacion ¿que falta en el hueco? `Solution BB(Problem p) if(????????????)`
A:3
`n.optimistic_b() >= pb`
`n.pesimistic_b() <= pb`
`n.optimistic_b() <= pb`

Q: En el siguiente problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n ¿Que deberia ir en lugar de XXXXXX? `void fill(price m[]) +cutrod(XXXXXX)`
A:1
`n-i, m, p`
`n-m[n], m, p`
`n, m[n]-1, p`

Q: En el problema del viajante de comercio (travelling salesman problem) queremos listar todas las soluciones factibles
A:1
el orden en el que se exploran las soluciones parciales no es relevante; por ello, la tecnica ramificacion y poda no aporta nada con respecto a vuelta atras
lo mas adecuado seria usar una tecnica de ramificacion y poda ya que es muy importante el orden en el que se exploran las soluciones parciales
lo mas importante es conseguir una cota pesimista adecuada. Las diferencias entre ramificacion y poda y vuelta atras son irrelevantes en este caso

Q: ¿Cual es la complejidad temporal, en el peor de los casos, del mejor algoritmo que se puede escribir para resolver el problema de la mochila discreta?
A:3
Polinomica con el numero de objetos a tratar, siempre que se utilice programacion dinamica.
Ninguna de las otras dos son ciertas.
Exponencial con el numero de objetos a tratar.

Q: Tratandose de un esquema general para resolver problemas de maximizacion ¿que falta en el hueco? `Solution BB(Problem p) if(????????????)`
A:2
`n.pesimistic_b() <= pb`
`n.optimistic_b() >= pb`
`n.optimistic_b() <= pb`

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos
A:3
$O(2^{\log n}) \subset O(n^2)$
$n + n \log n \in \Omega(n)$
$\Theta(n) \subset \Theta(n^2)$

Q: Queremos resolver por ramificacion y poda el problema de la mochila discreta.Si resolvemos el mismo problema de la forma voraz pero sin ordenar previamente los objetos por valor/peso, obtendremos
A:1
Una cota pesimista
Nada que podamos utilizar
Una cota optimista

Q: ¿Cual de estas estrategias voraces obtiene siempre un mejor valor para la mochila discreta?
A:2
Meter primero los elementos de mayor valor especifico o valor por unidad de peso.
Ninguna de las otras dos opciones es cierta.
Meter primero los elementos de mayor valor.

Q: Que diferencia (entre otras) hay entre el algoritmo de Prim y el de Kruskal?
A:1
El subgrafo que paso a paso va generando el algoritmo de prim siempre contiene una única componente conexa.
Aun siendo el grafo de partida totalmente conexo, el algoritmo de Kruskal garantiza la solución optima mientras que el de prim solo garantiza un suboptimo.
El algoritmo de Prim es voraz y el de Kruskal no.

Q: Tenemos una lista ordenada de tamaño $n_o$ y una lista desordenada de tamaño $n_d$, queremos obtener una lista ordenada con todos los elementos, ¿Cual seria la complejidad de insertar uno a uno todos los elementos de la lista desordenada en la ordenada?
A:1
$O(n_o \times n_d + n_d^2)$
$O(n_d \times n_o)$
$O(n_d \log n_o)$

Q: La siguiente relacion de recurrencia expresa la complejidad de un algoritmo recursivo, donde g(n) es una funcion polinomica Cual es la definicion correcta de $\Omega(f)$
A:2
$\Omega(g) = \{f: \mathbb{N} \to \mathbb{R} \mid g(n) \leq cf(n)\}$
$\Omega(g) = \{f: \mathbb{N} \to \mathbb{R} \mid f(n) \leq cg(n)\}$
$O(g) = \{f: \mathbb{N} \to \mathbb{R} \mid g(n) \leq cf(n)\}$

Q: Cual de las siguientes relaciones de recurrencia es la del algoritmo mergesort
A:1
$T(n) = n + 2T(n/2)$ para $n > 1$
$T(n) = n + T(n/2)$ para $n > 1$
$T(n) = n + T(n-1)$ para $n > 1$

Q: Tenemos una lista recursiva con la siguiente cabecera: `double f(const double &)` Con solo esta informacion, cual podria ser la definicion adecuada para el almacen?
A:3
`int A[]`
`vector<double> A`
Ninguna de las dos otras opciones son verdaderas

Q: El problema del alfarero (solución discreta con tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$? ¿Cuál de los siguientes esquemas algorítmicos resultaría más eficiente para resolverlo?
A:1
Programación dinámica.
Un algoritmo voraz.
Vuelta atrás.

Q: Cuál de la siguientes es la complejidad temporal más ajustada para un algoritmo que calcula la potencia n-ésima de una matriz cuadrada, expresada en función de n?
A:3
$O(\log n)$
$O(n \log n)$
$O(n)$

Q: Las soluciones factibles a un problema de optimización deben cumplir dos restricciones y queremos resolver el problema mediante vuelta atrás o ramificación y poda. ¿Cuál de las siguientes afirmaciones es cierta?
A:3
La cota optimista usada para podar nunca se puede basar en la relajación de ninguna de las restricciones que deben cumplir las soluciones factibles.
La cota optimista usada para podar se debe basar en relajar ambas restricciones simultáneamente.
La cota optimista usada para podar se puede basar en relajar una cualquiera de las dos restricciones.

Q: Sea el vector v={1,3,2,7,4,6,8} cuyos elementos están dispuestos formando un montículo de mínimos. Posteriormente añadimos en la última posición del vector un elemento nuevo con valor 5. ¿Qué operación hay que hacer para que el vector siga representando un montículo de mínimos?
A:3
No hay que hacer nada pues el vector v={1,3,2,7,4,6,8,5} también es un montículo de mínimos.
Intercambiar el 8 con el 5.
Intercambiar el 7 con el 5.

Q: Si $\lim_{n \to \infty} \frac{g(n)}{f(n)} = 0$, ¿Cuál de las siguientes expresiones NO puede darse?
A:3
$g(n) \notin \Theta(f(n))$
$f(n) \notin \Theta(g(n))$
$g(n) \in \Omega(f(n))$

Q: El problema del cambio: Se dispone de un conjunto finito de números naturales y se pretende obtener el subconjunto de menor tamaño cuyos elementos suman una cierta cantidad C. ¿Qué estrategia es la más apropiada para resolverlo?
A:3
Un algoritmo voraz.
Ramificación y poda.
Programación dinámica.

Q: ¿Cuál de las siguientes formulaciones expresa mejor la complejidad temporal, en función del parámetro n, de la siguiente función? (asumimos que n es potencia exacta de 2)
```cpp
int f(int n) {
	int k = 0;
	for (int i = 2; i <= n; i *= 2)
		for (int j = i; j > 0; j -= 2)
			k++;
	return k;
}
```
A:2
$\sum_{p=1}^{\log n} 2 \cdot (p - 1)$
$\sum_{p=1}^{\log n} 2^{(p - 1)}$
$\sum_{p=2}^{n/2} \frac{(p - 1)}{2}$

Q: ¿Cuál de las siguientes formulaciones expresa mejor el número de llamadas recursivas que hace Quicksort en el mejor de los casos?
A:3
$\sum_{i=0}^{n} \log n$
$\sum_{i=0}^{\log n} 1$
$\sum_{i=0}^{\log n} 2^i$

Q: La función test() procesa una lista de n elementos y devuelve un real. La definición de la función es recursiva. Primero descompone la lista en dos sublistas de la misma longitud usando un segmento de código que tiene una complejidad lineal con la longitud de la lista, y después envía una de las dos sublistas a test() para que la procese, hace una serie de operaciones, con el resultado y el retorno, de coste temporal constante. ¿Cuál es el coste temporal asintótico de la función test() en función de n?
A:3
$\Theta(n)$
$\Theta(n \log n)$
$\Theta(\log n)$

Q: El problema del alfarero (solución discreta con valores y tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cual es el valor máximo de los objetos que puede fabricar teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Para ello se escribe la siguiente función siguiendo la técnica de divide y vencerás:
```cpp
int potter(const vector<int> &v, const vector<int> &m,
	const vector<int> &t, int T, int k) {
	if(k == 0)
		return 0;
	int max_earnings = -1;
	for(int c = 0; c <= m[k-1]; c++) {
		int earnings = 0;
		if(T >= c * t[k-1])
			# ==> Falta una línea <==
		max_earnings = max(max_earnings, earnings);
	}
	return max_earnings;
}
```
A:1
`earnings = c * v[k-1] + potter(v, m, t, k-1, T - c * t[k-1]);`
`earnings = potter(v, m, t, k-1, T);`
`earnings = potter(v, m, t, k-1, T - c * t[k-1]);`

Q: El problema del alfarero (solución discreta con tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. El tiempo disponible para la fabricación de objetos está limitado por $T \in \mathbb{R}$. Se pretende resolver mediante ramificación y poda y para ello se hace uso de una cota que consiste en coger, de entre las clases aún no consideradas, un número al azar de objetos a fabricar siempre que se cumpla las restricciones del problema ¿Que podemos decir de esta cota?
A:3
Que es una cota optimista
Que no es cota, ni optimista ni pesimista
Que es una cota pesimista.

Q: Una de las afirmaciones siguientes es cierta y las otras dos falsas. Indicad cuál es la falsa.
A:2
$O(n^n) \subset O(n!)$
La complejidad temporal de Quicksort es $O(n^2)$ y $\Omega(n \log n)$
$O(3^n) \subset O(2^n)$

Q: Una de estas afirmaciones es falsa. ¿Cuál es?
A:1
El algoritmo de Prim va construyendo un bosque de árboles que va uniendo hasta que acaba con un árbol de recubrimiento de coste mínimo.
El algoritmo de Kruskal se puede acelerar notablemente si los vértices se organizan en una estructura union-find.
El algoritmo de Prim se puede acelerar notablemente si se guarda, para cada vértice no visitado, los datos de la arista de mínimo peso que lo une a un vértice visitado.

Q: Una empresa tiene M referencias en su stock. Cada referencia $j \in [1,M]$ tiene un peso $p_j$ y un valor $v_j$ y dispone de $n_j$ unidades en su stock. Dispone de un solo camión en el que puede cargar como máximo un peso P. Indicad cuál de las tres funciones siguientes representa una posible solución voraz aproximada al problema de cargar el camión de manera que se transporte un valor máximo.
A:1
```cpp
int f(const vector<int> &p, const vector<int> &v, const vector<int> &n, int P, int k) {
	if(k == 0 || P == 0)
		return 0;
	int num_objs = min(P/p[k-1], n[k-1]);
	return num_objs * v[k-1] + f(p, v, n, P - num_objs * p[k-1], k-1);
}
```
```cpp
int f(const vector<int> &p, const vector<int> &v, const vector<int> &n, int P, int k) {
	if(k == 0 || P == 0)
		return 0;
	int gain = 0;
	for(int num_objs = 0; num_objs <= n[k-1]; num_objs++)
		gain = max(gain, f(p, v, n, P - num_objs * p[k-1], k-1));
	return gain;
}
```
```cpp
int f(const vector<int> &p, const vector<int> &v, const vector<int> &n, int P, int k) {
	if(k == 0 || P == 0)
		return 0;
	int gain = 0;
	for(int num_objs = 0; num_objs <= 1; num_objs++)
		gain = max(gain, f(p, v, n, P - num_objs * p[k-1], k-1));
	return gain;
}
```

Q: El problema del alfarero (solución continua con tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$? Si el alfarero pudiera vender objetos sin terminar a un precio proporcional al estado de terminación. ¿Cuál de las siguientes estrategias sería más apropiada para resolverla?
A:2
Vuelta atrás.
Un algoritmo voraz.
Programación dinámica.

Q: La serie denominada tribonacci se define de la siguiente manera: T(0)=T(1)=1, T(2)=2, y T(n)=T(n-3)+T(n-2)+T(n-1) para n>3. Solo una de las afirmaciones siguientes es cierta. ¿Cuál es?
A:1
Un algoritmo de programación dinámica iterativa permite calcular el valor de T(n) en tiempo $\Theta(n)$.
Un algoritmo de programación dinámica iterativa para calcular T(n) tendría un coste espacial $\Theta(n)$ y este coste no se podría reducir a $\Theta(1)$.
Un algoritmo recursivo con memoización para calcular T(n) para a un n grande tendría una complejidad prohibitiva.

Q: El problema del alfarero (solución discreta con valores y tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{R}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$? Se pretende resolverlo mediante ramificación y poda. Las siguientes funciones tratan de estimar una ganancia aproximada para la parte del nodo aún sin completar. ¿cuál es la mejor para usarla como parte de la cota optimista?
A:3
```cpp
double optimistic(const vector<int> &m, const vector<double> &v, const vector<double> &t, double T, size_t from) {
	double gain = 0.0;
	for(size_t i = from; i < m.size() && T > 0; i++) {
		for(int j = 1; j <= m[i]; j++) {
			if(t[i] < T) {
				gain += v[i];
				T -= t[i];
			}
		}
	}
	return gain;
}
```
```cpp
double optimistic(const vector<int> &m, const vector<double> &v, const vector<double> &t, double T, size_t from) {
	double gain = 0.0;
	for(size_t i = from; i < m.size() && T > 0; i++) {
		for(int j = 1; j <= m[i]; j++) {
			gain += v[i];
			T -= t[i];
		}
	}
	return gain;
}
```
```cpp
double optimistic(const vector<int> &m, const vector<double> &v, const vector<double> &t, double T, size_t from) {
	double gain = 0.0;
	for(size_t i = from; i < m.size() && T > 0; i++) {
		double num_objs = min(T/t[i], double(m[i]));
		gain += num_objs * v[i];
		T -= num_objs * t[i];
	}
	return gain;
}
```

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. El tiempo total disponible viene dado por $T \in \mathbb{N}$. Se pretende listar todas las posibilidades de fabricación de objetos. ¿Qué estrategia es la más adecuada?
A:2
Ramificación y poda.
Vuelta atrás.
Un algoritmo voraz.

Q: La función test() procesa una lista de n elementos y devuelve un real. La definición de la función es recursiva. Primero descompone la lista en dos sublistas de la misma longitud usando un segmento de código que tiene una complejidad lineal con la longitud de la lista, envía cada una de dos sublistas a test() para que la procese, hace una serie de operaciones, con el resultado y el valor de retorno, de coste temporal constante. ¿Cuál es el coste temporal asintótico de la función test() en función de n?
A:3
$\Theta(\log n)$
$\Theta(n \log n)$
$\Theta(n)$

Q: El funcionamiento del algoritmo de ordenación Heapsort es similar al algoritmo de ordenación por selección, ya que localiza el valor más grande y lo sitúa en la posición final del vector; a continuación, localiza el siguiente valor más grande y lo sitúa en la posición anterior a la última, etc. ¿Cuál de las afirmaciones siguientes es cierta?
A:2
El algoritmo Heapsort tiene una complejidad $O(n)$ en el caso peor, mejor que la complejidad $O(n^2)$ del algoritmo de selección, porque Heapsort utiliza una algoritmo mucho más eficiente para localizar los valores del vector que valen más.
El algoritmo Heapsort tiene una complejidad $O(n \log n)$ en el caso peor, mejor que la complejidad $O(n^2)$ del algoritmo de selección, porque Heapsort utiliza una algoritmo mucho más eficiente para localizar los valores del vector que valen más.
Por ello, los dos algoritmos tienen la misma complejidad en el caso peor, $O(n^2)$, aunque la complejidad en el caso mejor de Heapsort es $O(n \log n)$.

Q: Una de las respuestas siguientes es falsa. ¿Cuál es? El problema del viajante de comercio ...
A:2
... se puede resolver exactamente usando un algoritmo de búsqueda y enumeración como es el de vuelta atrás o el de ramificación y poda.
... se puede resolver exactamente usando un algoritmo voraz derivado del de Kruskal.
... se puede resolver exactamente usando un algoritmo de programación dinámica.

Q: Indica cuál es la complejidad, en función de n (n≥0), del fragmento siguiente:
```cpp
int f(int n) {
	if(n == 0)
		return n;
	return f(n/2) * f(n/2);
}
```
A:2
$\Theta(\log n)$
$\Theta(n)$
$\Theta(n \log n)$

Q: Dada la siguiente función construida mediante la técnica memoización:
```cpp
int f(vector<unsigned> &x, unsigned i) {
	if(x[i] != SENTINEL)
		return x[i];
	if(i < 5)
		return i;
	return x[i] = f(x, i-1) + f(x, i-3);
}

int f(unsigned i) {
	vector<unsigned> x(i, SENTINEL);
	return f(x, i);
}
```
¿Cual es la declaración para SENTINEL mas adecuada?
A:3
`const unsigned SENTINEL = numeric_limits<unsigned>::max();`
`const unsigned SENTINEL = 0;`
`const unsigned SENTINEL = -1;`

Q: ¿Qué complejidad tiene la siguiente función?
```cpp
void f(vector<int> &A) {
	priority_queue<int> pq(begin(A), end(A));
	A.clear();
	while(!pq.empty()) {
		A.push_back(pq.top());
		pq.pop();
	}
}
```
Suponed que la cola de prioridad está implementada como un heap y que n = A.size(). `priority_queue<int> pq(begin(A), end(A))` construye un heap a partir de los datos que hay en el vector A.
A:3
$\Theta(n^2)$
$\Theta(n)$
$\Theta(n \log n)$

Q: Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. Queremos listar todas las posibilidades de fabricación de objetos teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$. Para ello hemos hecho el siguiente programa donde faltan unas líneas:
```cpp
void combinations(const vector<int> &m, const vector<double> &t, double T, size_t k, vector<int> &x) {
	if(k == m.size()) {
		print_comb(x);
		return;
	}
	# ==> Aquí falta código <==
}
```
```cpp
void combinations(const vector<int> &m, const vector<double> &t, double T) {
	vector<int> x(m.size());
	combinations(m, t, T, 0, x);
}
```
¿Cuales son las líneas que faltan? [suponed que `print_comb()` imprime correctamente la combinación que hay codificada en x]
A:1
```cpp
for(int j = 0; j <= m[k]; j++) {
	x[k] = j;
	if(T >= j * t[k])
		combinations(m, t, T - j * t[k], k+1, x);
}
```
```cpp
for(int j = 0; j < m[k]; j++) {
	x[k] = j;
	if(T >= j * t[k])
		combinations(m, t, T - j * t[k], k+1, x);
}
```
```cpp
for(int j = 0; j < m[k]; j++) {
	x[j] = k;
	if(T >= j * t[k])
		combinations(m, t, T - j * t[k], k+1, x);
}
```

Q: En el método voraz ...
A:1
... es habitual preparar los datos para disminuir el coste temporal de la función que determina cuál es la siguiente decisión a tomar.
... para garantizar la solución óptima, las decisiones solo pueden pertenecer a dominios discretos o discretizables.
... para garantizar la solución óptima, las decisiones solo pueden pertenecer a dominios continuos.

Q: Indica cuál es la complejidad, en función de n, del fragmento siguiente:
```cpp
for(int i = 0; i < n; i++) {
	A[i] = 0;
	for(int j = 0; j < 20; j++)
		A[i] += B[j];
}
```
A:1
$\Theta(n)$
$\Theta(n^2)$
$\Theta(n \log n)$

Q: ¿Qué hace la siguiente función?
```cpp
void f(vector<int> &A) {
	priority_queue<int> pq;
	for(auto a: A)
		pq.push(a);
	A.clear();
	while(!pq.empty()) {
		A.push_back(pq.top());
		pq.pop();
	}
}
```
A:1
Ordena el vector A
Invierte el vector A (el último elemento quedará el primero)
Nada, deja el vector como estaba

Q: Dada la siguiente función recursiva:
```cpp
unsigned f(unsigned a, unsigned b) {
	if(a < 3)
		return a + 2*b;
	return f(a-1, (7*b)%10);
}
```
donde suponemos que siempre se va a invocar la función con b < 10. Queremos acelerarla aplicando la técnica de programación dinámica iterativa. ¿Cómo quedaría?
A:1
```cpp
unsigned f(unsigned a, unsigned b) {
	vector<vector<unsigned>> M(a, vector<unsigned>(10));
	for(unsigned j = 0; j < 10; j++)
		for(unsigned i = 0; i <= a; i++)
			if(i < 3)
				M[i][j] = i + 2*j;
			else
				M[i][j] = M[i-1][(7*j)%10];
	return M[a][b];
}
```
```cpp
unsigned f(unsigned a, unsigned b) {
	vector<vector<unsigned>> M(a+1, vector<unsigned>(10));
	for(unsigned i = 0; i <= a; i++)
		for(unsigned j = 0; j < 10; j++)
			if(i < 3)
				M[i][j] = i + 2*j;
			else
				M[i][j] = M[i-1][(7*j)%10];
	return M[a][b];
}
```
```cpp
unsigned f(unsigned a, unsigned b) {
	vector<vector<unsigned>> M(a+1, vector<unsigned>(10));
	for(unsigned j = 0; j < 10; j++)
		for(unsigned i = 0; i <= a; i++)
			if(i < 3)
				M[i][j] = i + 2*j;
			else
				M[i][j] = M[i-1][(7*j)%10];
	return M[a][b];
}
```

Q: En la solución al problema de la mochila continua, ¿por qué es conveniente la ordenación previa de los objetos?
A:1
Para reducir la complejidad temporal en la toma de cada decisión de $O(n)$ a $O(1)$, donde n es el numero de objetos a considerar
Para reducir la complejidad temporal en la toma de cada decisión de $O(n^2)$ a $O(n \log n)$, donde n es el numero de objetos a considerar
Porque si no se hace no es posible garantizar que la toma de decisiones siga un criterio voraz

Q: Si ante un problema de decisión existe un criterio de selección voraz entonces...
A:2
la solución óptima está garantizada
Ninguna de las otras dos es cierta
al menos una solución factible está garantizada

Q: La solución óptima al problema de encontrar el árbol de recubrimiento de coste mínimo para un grafo no dirigido, conexo y ponderado ...
A:3
... se construye haciendo crecer un único árbol.
... se construye haciendo crecer varios árboles que al final acaban injertados en un único árbol.
... puede construir un único árbol que va creciendo o bien construir un bosque de árboles que al final se injertan en un único árbol

Q: El problema de encontrar el árbol de recubrimiento de coste mínimo para un grafo dirigido y ponderado...
A:1
... se puede resolver siempre con una estrategia voraz
sólo se puede resolver con una estrategia voraz si existe una arista para cualquier par de vértices del grafo
... no se puede resolver en general con una estrategia voraz

Q: La mejora que en general aporta la programación dinámica frente a la solución ingenua se consigue gracias al hecho de que ...
A:2
... en la solución ingenua se resuelve pocas veces un número relativamente grande de subproblemas distintos.
... en la solución ingenua se resuelve muchas veces un número relativamente pequeño de subproblemas distintos.
El número de veces que se resuelven los subproblemas no tiene nada que ver con la eficiencia de los problemas resueltos mediante programación dinámica

Q: ¿Qué mecanismo se usa para acelerar el algoritmo de Prim?
A:3
Mantener una lista de los arcos ordenados según su peso.
El TAD "Union-find"
Mantener para cada vértice el vértice origen de la arista más corta hasta él.

Q: Un informático quiere subir a una montaña y para ello decide que tras cada paso, el siguiente debe tomarlo en la dirección de máxima pendiente hacia arriba. Además, entenderá que ha alcanzado la cima cuando llegue a un punto en el que no haya ninguna dirección que sea cuesta arriba. ¿qué tipo de algoritmo está usando nuestro informático?
A:1
un algoritmo voraz.
un algoritmo de programación dinámica
un algoritmo divide y vencerás.

Q: ¿Como se vería afectada la solución voraz al problema de la asignación de tareas en el caso de que se incorporaran restricciones que contemplen que ciertas tareas no pueden ser adjudicadas a ciertos trabajadores?
A:1
La solución factible ya no estaría garantizada, es decir, pudiera ser que el algoritmo o llegue a solución alguna
Habría que replantearse el criterio de selecciones
Ya no se garantizaría la solución óptima pero sí una factible

Q: Cuando la descomposición de los problemas da lugar a subproblemas de tamaño similar, ¿qué esquema promete ser más apropiado?
A:1
Programación dinámica
El metodo voraz
Divide y vencerás, siempre que se garantice que los problema no son del mismo tamaño

Q: ¿Cual de estas tres estrategias voraces obtiene un mejor valor para la mochila discreta?
A:1
Meter primero los elementos de mayor valor específico o valor por unidad de peso
Meter primero los elementos de mayor valor
Meter primero los elementos de menor peso

Q: Dado un problema de optimización, el método voraz...
A:1
garantiza la solución óptima sólo para determinados problemas
Siempre obtiene una solución factible
Siempre obtiene una solución óptima

Q: ¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, un solución voraz óptima?
A:3
El árbol de cobertura de coste mínimo de un grafo conexo
El problema de la mochila continua o con fraccionamiento
El problema de la mochila discreta o sin fraccionamiento

Q: ¿Cual de los siguientes pares de problemas son equivalente en cuanto al tipo de solución(óptima, factible, etc) aportada por el método voraz?
A:2
El fontanero diligente y el problema del cambio
La mochila discreta y la asignación de tareas
La mochila continua y la asignación de tareas

Q: Se pretende aplicar la técnica memoización a la siguiente función recursiva:
```cpp
int f(int x, int y) {
	if(x <= y)
		return 1;
	return x + f(x-1, y);
}
```
En el caso más desfavorable, ¿qué complejidades temporal y espacial cabe esperar de la función resultante?
A:1
$O(x-y)$, tanto temporal como espacial.
Temporal $O(x-y)$ y espacial $O(1)$
Ninguna de las otras dos opciones es correcta

Q: La solución de programación dinámica iterativa del problema de la mochila discreta...
A:2
... calcula menos veces el valor de la mochila que la correspondiente solución de programación dinámica recursiva
... tiene la restricción de que los valores tienen que ser enteros positivos
... tiene un coste temporal asintótico exponencial con respecto al número de objetos

Q: Supongamos que una solución recursiva a un problema de optimización muestra estas dos características: por un lado, se basa en obtener soluciones óptimas a problemas parciales más pequeños, y por otro, estos subproblemas se resuelven más de una vez durante el proceso recursivo. Este problema es candidato a tener una solución alternativa basada en ...
A:2
... un algoritmo voraz.
... un algoritmo de programación dinámica.
... un algoritmo del estilo de divide y vencerás.

Q: Los algoritmos de programación dinámica hacen uso...
A:1
... de que se puede ahorrar cálculos guardando resultados anteriores en un almacén
... de una estrategia trivial consistente en examinar todas las soluciones posibles
... de que la solución óptima se puede construir añadiendo a la solución el elemento óptimo de los elementos restantes, uno a uno.

Q: ```cpp
unsigned f(unsigned y, unsigned x) { // suponemos y >= x
	if (x == 0 || y == x)
		return 1;
	return f(y-1, x-1) + f(y-1, x);
}
```
A:2
$O(y)$
$O(x-y)$
$O(x)$

Q: ```cpp
int f(int x, int y) {
	if (x <= y)
		return 1;
	return x + f(x-1, y);
}
```
A:3
$O(x)$
$O(x^2)$
$O(1)$

Q: ¿Cual de los siguientes pares de problemas son equivalentes en cuanto al tipo de solución(óptima, factible, etc) aportada por el método voraz?
A:1
El fontanero diligente y mochila continua
El fontanero diligente y el problema del cambio
El fontanero diligente y asignación de tareas

Q: Un algoritm recursivo basado en el esquema divide y vencerás...
A:1
... será más eficiente cuanto más equitativa sea la división en subproblemas
Las demás opciones son verdaderas
... nunca tendrá una complejidad exponencial

Q: Un tubo de centímetros de largo se puede cortar en segmentos de 1 centímetro, 2 centímetros, etc. Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es la que más ingresos nos producirá. Di cuál de estas tres afirmaciones es falsa.
A:1
Hacer una evaluación exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $O(n!)$.
Es posible evitar hacer la evaluación exhaustiva "de fuerza bruta" guardando, para cada posible longitud $j < n$ el precio más elevado posible que se puede obtener dividiendo el tubo correspondiente.
Hacer una evaluación exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo $O(2^n)$.

Q: Se pretende implementar mediante programación dinámica iterativa la función recursiva:
```cpp
unsigned f(unsigned x, unsigned v[]) {
	if (x == 0)
		return 0;
	unsigned m = 0;
	for (unsigned k = 0; k < x; k++)
		m = max(m, v[k] + f(x-k, v));
	return m;
}
```
¿Cuál es la mejor complejidad espacial que se puede conseguir?
A:1
$O(x)$
$O(1)$
$O(x^2)$

Q: De los problemas siguientes, indicad cuál no se puede tratar eficientemente como los otros dos
A:2
El problema de cortar un tubo de forma que se obtenga el máximo beneficio posible
El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores
El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el mínimo de monedas posibles

Q: En el método voraz ...
A:2
... el dominio de las decisiones sólo pueden ser conjuntos discretos o discretizables.
... es habitual preparar los datos para disminuir el coste temporal de la función que determina cuál es la siguiente decisión a tomar.
... siempre se encuentra solución pero puede que no sea la óptima.

Q: ¿Cómo se vería afectada la solución voraz al problema de la asignación de tareas en el caso de que se incorporaran restricciones que contemplen que ciertas tareas no pueden ser adjudicadas a ciertos trabajadores?
A:3
Ya no se garantizaría la solución óptima pero sí una factible.
Habría que replantearse el criterio de selección para comenzar por aquellos trabajadores con más restricciones en cuanto a las tareas que no pueden realizar para asegurar, al menos, una solución factible.
La solución factible ya no estaría garantizada, es decir, pudiera ser que el algoritmo no llegue a solución alguna.

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la posición central...
A:1
.... se comporta mejor cuando el vector ya está ordenado
... se comporta peor cuando el vector ya está ordenado
... no presenta casos mejor y peor distintos para instancias del mismo tamaño

Q: La versión de Quicksort que utiliza como pivote la mediana del vector...
A:2
... es más eficiente si el vector ya está ordenado
... no presenta caso mejor y peor distinto para instancia del mismo tamaño
... es la versión con mejor complejidad en el mejor de los casos.

Q: ¿Cuál de las siguientes relaciones de recurrencia expresa mejor la complejidad espacial es la del algoritmo Mergesort?
A:3
$T(n) = n + T(n - 1)$ para $n > 1$ y $T(n) = 1$ para $n < 1$
$T(n) = n + T(n/2)$ para $n > 1$ y $T(n) = 1$ para $n < 1$
$T(n) = n + 2T(n/2)$ para $n > 1$ y $T(n) = 1$ para $n < 1$

Q: La versión de Quicksort que utiliza como pivote la mediana del vector...
A:2
... se comporta mejor cuando el algoritmo ya está ordenado
... El hecho de que el vector estuviera previamente ordenado o no, no influye en la complejidad temporal de este algoritmo
... se comparta peor cuando el algoritmo ya está ordenado

Q: Si $f \in \Theta(g_1)$ y $f \in \Theta(g_2)$ entonces
A:1
$f \in \Theta(g_1 \cdot g_2)$
$f \notin \Theta(\max(g_1,g_2))$
$f \in \Theta(g_1+g_2)$

Q: Los algoritmos de ordenación Quicksort y Mergesort tienen en común...
A:2
Que ordenan el vector sin usar espacio adicional
Que aplican la estrategia divide y vencerás
Que se ejecutan en tiempo $O(n)$

Q: ¿En qué caso la complejidad temporal del algoritmo de ordenación Quicksort es igual a la complejidad temporal del algoritmo Mergesort?
A:1
En el caso mejor de ambos.
En el caso peor de ambos.
Tanto en el caso peor como en el caso mejor de ambos.

Q: Para que la complejidad de un algoritmo presenta caso mejor y peor distintos...
A:1
... es condicion necesaria que existan instancias distintas del problema con el mismo tamaño
es condicion suficiente que existan instancias distintas del problema con el mismo tamaño
... es condicion necesaria y suficiente que existan instancias distintas del problema con el mismo tamaño

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
A:2
Las demás opciones con verdaderas
... será más eficiente cuanto más equitativa sea la división en subproblema
... nunca tendrá una complejidad exponencial

Q: La complejidad temporal en el mejor de los casos de un algoritmo recursivo...
A:2
... coincide con el valor del caso base de la ecuación de la recurrencia que expresa la complejidad temporal del algoritmo
Las demás opciones son falsas
... siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo

Q: Si $f(n) \in O(n^2)$, ¿podemos decir siempre que $f(n) \in O(n^3)$?
A:2
No, ya que $n^2 \in O(n^3)$
Si ya que $n^2 \in O(n^3)$
Sólo para valores bajos de

Q: ¿Qué se entiende por tamaño del problema?
A:2
El número de parámetros que componen el problema.
La cantidad de espacio en memoria que se necesita para codificar una instancia de ese problema.
El valor máximo que puede tomar una instancia cualquiera de ese problema.

Q: Para que la complejidad de un algoritmo presenta caso mejor y peor distintos...
A:3
... es condición necesaria y suficiente que existan instancias distintas del problema con el mismo tamaño
... es condición suficiente que existan instancias distintas del problema con el mismo tamaño
... es condición necesaria que existan instancia distintas del problema con el mismo tamaño

Q: Las siguientes funciones calculan el valor de la potencia n-ésima de dos. ¿Cuál es más eficiente en cuanto a coste temporal?
```cpp
unsigned long pot2_1(unsigned n) {
	if (n == 0)
		return 1;
	if (n % 2 == 0)
		return pot2_1(n/2) * pot2_1(n/2);
	else
		return 2 * pot2_1(n/2) * pot2_1(n/2);
}
```
```cpp
unsigned long pot2_2(unsigned n) {
	if (n == 0)
		return 1;
	unsigned long aux = pot2_2(n/2);
	if (n % 2 == 0)
		return aux * aux;
	else
		return 2 * aux * aux;
}
```
A:2
La primera, `pot2_1(n)`, es más eficiente que la otra.
La segunda, `pot2_2(n)`, es más eficiente que la otra.
Las dos funciones son equivalentes en cuanto a coste temporal.

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
A:2
$(4^{\log_2(n)}) \subseteq O(n^2) \subset O(2^n)$
$O(n^2) \subset O(2^{\log_2(n)}) \subset O(2^n)$
$O(2^{\log_2(n)}) \subseteq O(n^2) \subset O(n!)$

Q: Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función?
```cpp
void f(unsigned n) {
	if(n < 1)
		return;
	for(int i = 0; i < n; i++)
		for(int j = 0; j < n; j++)
			for(int k = 0; k < n; k++)
				cout << "*";
	for(int i = 0; i < 8; i++)
		f(n / 2);
}
```
A:3
$\Theta(n^2 \log n)$
$\Theta(n^3 )$
$\Theta(n^3 \log n)$

Q: ¿Cuál es la relación de recurrencia que representa la complejidad en el peor caso del algoritmo de búsqueda del k-ésimo elemento más pequeño de un vector (estudiado en clase).
A:3
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n/2)+1 & \text{en otro caso} \end{cases}$
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n/2)+n & \text{en otro caso} \end{cases}$
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n-1)+n & \text{en otro caso} \end{cases}$

Q: La siguiente relación de recurrencia expresa la complejidad de un algoritmo recursivo, donde $g(n)$ es una función polinómica: $T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ 2T(n/2)+g(n) & \text{en otro caso} \end{cases}$ Di cuál de las siguientes afirmaciones es cierta:
A:1
Si $g(n) \in O(n)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación Mergesort.
Si $g(n) \in O(n^2)$ la relación de recurrencia representa la complejidad temporal del algoritmo de ordenación mediante inserción binaria.
Si $g(n) \in O(1)$ la relación de recurrencia representa la complejidad temporal del algoritmo de búsqueda dicotómica.

Q: Con respecto al esquema Divide y venderás, ¿es cierta la siguiente afirmación?
A:3
Sí, siempre, en divide y vencerás la complejidad temporal depende únicamente del tamaño de los problemas
No, nunca, pues que también hay que añadir el coste de la división en subproblemas y la posterior combinación
No tiene porqué, la complejidad no depende únicamente del tamaño resultante de los subproblemas

Q: Cuál de las siguientes formulaciones expresa mejor el coste temporal asintótico de la siguiente función?
```cpp
int f(int n) {
	int count = 0;
	for (int i = n; i > 0; i /= 2)
		for (int j = 0; j < 2 * i; j++)
			count += 1;
	return count;
}
```
A:1
$f(n) = \sum_{i=1}^{\log n} 4n \left( \frac {1}{2} \right)^i$
$f(n) = \sum_{i=0}^{n/2} \sum_{j=0}^{2*i} 1$
Ninguna de las otras dos opciones es correcta.

Q: Tenemos un vector desordenado y queremos obtener los tres elementos más pequeños. ¿Cuál sería la complejidad temporal más ajustada para hacerlo? (sin pérdida de generalidad puedes suponer que en el vector todos los elementos son distintos)
A:2
El logaritmo de la longitud del vector
Lineal con la longitud del vector
Cuadrática con la longitud del vector

Q: La complejidad temporal en el mejor de los casos...
A:2
... es el tiempo que tarda el algoritmo el resolver la talla más pequeña que se le puede presentar
... es una función de la talla que tiene que estar definida en todos los posibles valores de esta
Las demás son correctas

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición...
A:3
... se comporta mejor cuando el vector ya está ordenado
... El hecho de que el vector estuviera previamente ordenado o no, no incluye en la complejidad temporal de este algoritmo.
... se comporta peor cuando el vector ya está ordenado

Q: ¿Tiene sentido usar una función que indique cómo de prometedor es un nodo cuando resolvemos un problema que no es de optimización mediante ramificación y poda?
A:3
No. Los problemas que no son de optimización no se pueden resolver mediante ramificación y poda.
No. Sólo tiene sentido usar una función de promesa en problemas de optimización, y esta ha de ser necesariamente una cota optimista.
Sí, si se puede diseñar de manera que intente predecir si un nodo conducirá o no a la solución.

Q: Si resolvemos un problema de optimización mediante el método de la vuelta atrás, ¿se puede usar, además de una cota optimista, una cota pesimista para reducir el número de soluciones exploradas?
A:3
No, porque las podas las determina la cota optimista, y lo hace independientemente de cuál sea el valor de la mejor solución en curso.
No. En el método de la vuelta atrás siempre es necesario visitar las hojas para actualizar la mejor solución en curso.
Sí. Aunque las cotas pesimistas no se hayan explicado en clase hasta llegar al tema de ramificación y poda, no hay ninguna razón que impida su uso en el método de la vuelta de atrás.

Q: ¿Cuál es la relación de recurrencia que representa la complejidad en el peor caso del algoritmo de búsqueda del k-ésimo elemento más pequeño de un vector (estudiado en clase).
A:3
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n/2)+n & \text{en otro caso} \end{cases}$
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n/2)+n & \text{en otro caso} \end{cases}$
$T(n) = \begin{cases} 1 & \text{si } n \leq 1 \\ T(n-1)+n & \text{en otro caso} \end{cases}$

Q: Indica cuál es la complejidad, en función de n, del fragmento siguiente:
```cpp
for(int i = 0; i < n; i++) {
	A[i] = 0;
	for(int j = 0; j < 2*n; j++)
		A[i] += B[j];
}
```
A:2
$\Theta(n \log n)$
$\Theta(n^2)$
$\Theta(n)$

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Se pretende resolver mediante ramificación y poda y para ello se hace uso de una cota que consiste en asumir que de las restantes clases de objetos aún no tratadas se va a fabricar exactamente una pieza. ¿Que podemos decir de esta cota?
A:1
Que no es cota, ni optimista ni pesimista
Que es una cota optimista.
Que es una cota pesimista.

Q: Si $f(n) \in O(g(n))$ ¿cuál de estas situaciones no es posible?
A:2
$g(n) \in O(f(n))$
$\lim_{n \to \infty} \frac{g(n)}{f(n)} = 0$
$f(n) \in \Omega(g(n))$

Q: ¿Cuál sería la complejidad temporal de la siguiente función tras aplicar programación dinámica?
```cpp
double f(int n, int m) {
	if(n <= 1)
		return 1;
	return m * f(n-1, m) * f(n-2, m);
}
```
A:2
$\Theta(n \cdot m)$
$\Theta(n)$
$\Theta(n^2)$

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Se pretende resolver mediante un algoritmo de ramificación y poda. ¿Qué ocurre si el subóptimo de partida coincide con la cota optimista del nodo inicial?
A:2
Que el algoritmo sería incorrecto ya que el subóptimo de partida es en realidad una cota pesimista para el nodo inicial.
Que el algoritmo no debería explorar ningún nodo.
Que la cota optimista está mal estimada.

Q: De las expresiones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos.
A:1
Si $f \in \Theta(g)$ entonces $O(f) = O(g)$.
Si $f \in O(g)$ entonces $g \notin O(f)$.
Si $f \notin \Omega(g)$ entonces $O(f) = \Omega(g)$.

Q: Una de las afirmaciones siguientes es cierta y las otras dos falsas. Indicad cuál es la cierta.
A:3
$O(n^n) \subset O(n!)$
$O(3^n) \subset O(2^n)$
$O(2^n) \subset O(n!)$

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es menor que el valor de una cota optimista? (se entiende que ambas cotas se aplican sobre el mismo nodo)
A:3
Sí, siempre es así.
En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir

Q: Qué diferencia (entre otras) hay entre el algoritmo de Prim y el de Kruskal?
A:3
Aún siendo el grafo de partida totalmente conexo, el algoritmo de Kruskal garantiza la solución óptima mientras que el de Prim sólo garantiza un subóptimo.
El algoritmo de Prim es voraz y el de Kruskal no.
El subgrafo que paso a paso va generando el algoritmo de Prim siempre contiene una única componente conexa mientras que el de Kruskal no tiene por qué.

Q: Si $\lim_{n \to \infty} \frac{g(n)}{f(n)}$ resulta ser una constante positiva no nula, cuál de las siguientes expresiones NO puede darse?
A:2
$f(n) \in \Omega(g(n))$ y $g(n) \in \Omega(f(n))$
$g(n) \notin \Theta(f(n))$
$f(n) \in \Theta(g(n))$

Q: El problema del alfarero (solución discreta con tiempos continuos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{R}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{R}$? Se pretende resolver mediante un algoritmo de ramificación y poda. Para determinar si un nodo es prometedor se estima su ganancia máxima haciendo uso de de la solución voraz discreta (sin fraccionamientos) de la parte aún sin completar. ¿Qué podemos decir del algoritmo resultante?
A:1
Que presumiblemente explorará menos nodos de los necesarios.
Que presumiblemente explorará más nodos de los necesarios.
Que si comienza con una solución subóptima encontrará antes la óptima.

Q: Indica cuál es la complejidad, en función de n, del fragmento siguiente: (suponed que A está definido como `vector<int> A(n)` y `sort` es la función de ordenación de la STL)
```cpp
sort(begin(A), end(A));
int acc = 0;
for(auto i : A)
	acc += i;
```
A:1
$\Theta(n \log n)$
$\Theta(n^2)$
$\Theta(n)$

Q: Indica cuál es la complejidad en función de n, donde k es una constante (no depende de n), del fragmento siguiente:
```cpp
for(int i = k; i < n - k; i++) {
	A[i] = 0;
	for(int j = i - k; j < i + k; j++)
		A[i] += B[j];
}
```
A:1
$O(n)$
$O(n^2)$
$O(n \log n)$

Q: ¿Qué hace la siguiente función?
```cpp
void f(vector<int> &A) {
	priority_queue<int> pq;
	for(int i = A.size()-1; i >= 0; i--) {
		pq.push(A[i]);
	}
	A.clear();
	while(!pq.empty()) {
		A.push_back(pq.top());
		pq.pop();
	}
}
```
A:3
Invierte el vector A (el último elemento quedará el primero)
Nada, deja el vector como estaba
Ordena el vector A

Q: De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
A:1
$O(n^2) \subset O(2^{\log_2 n})$
$n + n \log_2 n \in \Omega(n + n \log_2 n)$
$\Omega(n^2) \subset \Omega(n)$

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? $f(n) = n(n-1) + f(n-1)$ si $n > 0$; $f(0) = 1$ si $n = 0$
A:2
$f(n) \in \Theta(n^2)$
$f(n) \in \Theta(n^3)$
$f(n) \in \Theta(n^4)$

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Si T no es muy grande con respecto a n ¿Cuál de los siguientes esquemas algorítmicos resultaría más eficiente para resolverlo?
A:3
Vuelta atrás.
Un algoritmo voraz.
Programación dinámica.

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Utilizando la técnica programación dinámica iterativa se pretende conocer únicamente la ganancia máxima que podría obtener el alfarero. ¿Cuál es la mejor complejidad espacial y temporal que se puede conseguir?
A:3
Espacial $\Theta(n)$ y temporal $\Theta(n \cdot T \cdot \max_{i=0}^{n-1} m_i)$.
$\Theta(n \cdot T)$, tanto espacial como temporal.
Espacial $\Theta(T)$ y temporal $\Theta(n \cdot T \cdot \max_{i=0}^{n-1} m_i)$.

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? $f(n) = 1 + f(n/b)$ si $n > 1$; $f(1) = 1$, con $b \in \mathbb{N}, b > 1$
A:2
$f(n) \in \Theta(n)$
$f(n) \in \Theta(\log n)$
Depende del valor de b.

Q: El problema del alfarero (solución discreta con tiempos discretos): Se dispone de n clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $m_i \in \mathbb{N}$; El valor de cada pieza terminada, $v_i \in \mathbb{N}$ y el tiempo necesario para su fabricación $t_i \in \mathbb{N}$, $i \in [0..n-1]$. ¿Cuántos objetos de cada clase hay que fabricar para maximizar la ganancia teniendo en cuenta que el tiempo total está limitado por $T \in \mathbb{N}$? Utilizando una técnica de divide y vencerás, ¿se podría saber cuál es la ganancia máxima que podría alcanzar el alfarero?
A:3
No, ya que no se cumple la propiedad "subestructura óptima".
No, ya que no es posible descomponer el problema en subproblemas.
Sí, pero a costa de una complejidad temporal prohibitiva.

Q: Con respecto al tamaño del problema, ¿Cuál es el orden de complejidad temporal asintótica de la siguiente función? (asumimos que A es una matriz cuadrada)
```cpp
void traspuesta(vector<vector<int>> A) {
	for(int i = 1; i < A.size(); i++)
		for(int j = 0; j < i; j++)
			swap(A[i][j], A[j][i]);
}
```
A:2
constante
lineal
cuadrático

Q: Al resolver el problema del viajante de comercio mediante vuelta atrás, ¿cuál de estas cotas optimistas se espera que pode mejor el árbol de búsqueda?
A:3
Se multiplica k por la distancia de la arista más corta que nos queda por considerar, donde k es el número de saltos que nos quedan por dar.
Se resuelve el resto del problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido.
Se ordenan las aristas restantes de menor a mayor distancia y se calcula la suma de las k aristas más cortas, donde k es el número de saltos que nos quedan por dar.

Q: El uso de funciones de cota en ramificación y poda...
A:2
... transforma en polinómicas complejidades que antes eran exponenciales.
... puede reducir el número de instancias del problema que pertenecen al caso peor.
... garantiza que el algoritmo va a ser más eficiente ante cualquier instancia del problema.

Q: Si $f(n) \in O(n^3)$, ¿puede pasar que $f(n) \in O(n^2)$?
A:2
Sólo para valores bajos de n.
Es perfectamente posible, ya que $O(n^2) \subset O(n^3)$
No, porque $n^3 \notin O(n^2)$.

Q: En una cuadrícula se quiere dibujar el contorno de un cuadrado de n casillas de lado. ¿cuál será la complejidad temporal del mejor algoritmo que pueda existir?
A:1
$O(n)$
$O(n^2)$
$O(\sqrt{n})$

Q: Se desea encontrar el camino más corto entre dos ciudades. Para ello se dispone de una tabla con la distancia entre los pares de ciudades en los que hay carreteras o un valor centinela (-1) si no hay, por lo que para ir de la ciudad inicial a la final es posible que haya que pasar por varias ciudades. También se conocen las coordenadas geográficas de cada ciudad y por tanto la distancia en línea recta entre cada par de ciudades. Se pretende acelerar la búsqueda de un algoritmo de ramificación y poda priorizando los nodos vivos (ciudades) que estén a menor distancia geográfica de la ciudad objetivo.
A:2
El nuevo algoritmo siempre será más rápido.
El nuevo algoritmo no garantiza que vaya a ser más rápido para todas las instancias del problema posibles.
Esta estrategia no asegura que se obtenga el camino más corto.

Q: Un algoritmo recursivo basado en el esquema divide y vencerás...
A:2
... Las dos anteriores son ciertas.
... será más eficiente cuanto más equitativa sea la división en subproblemas.
... nunca tendrá una complejidad exponencial.

Q: Cuando se resuelve el problema de la mochila discreta usando la estrategia de vuelta atrás, ¿puede ocurrir que se tarde menos en encontrar la solución óptima si se prueba primero a meter cada objeto antes de no meterlo?
A:2
Sí, tanto si se usan cotas optimistas para podar el árbol de búsqueda como si no.
Sí, pero solo si se usan cotas optimistas para podar el árbol de búsqueda.
No, ya que en cualquier caso se deben explorar todas las soluciones factibles.

Q: Cuando la descomposición recursiva de un problema da lugar a subproblemas de tamaño similar, ¿qué esquema promete ser más apropiado?
A:1
Programación dinámica.
Divide y vencerás, siempre que se garantice que los subproblemas no son del mismo tamaño.
El método voraz.

Q: Uno de estos tres problemas no tiene solución eficiente que siga el esquema de programación dinámica:
A:3
El problema de la mochila discreta.
El problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud.
El problema de las torres de Hanoi.

Q: ¿Para cuál de estos problemas de optimización existe una solución voraz?
A:3
El problema de la mochila discreta.
El problema de la asignación de coste mínimo de n tareas a n trabajadores cuando el coste de asignar la tarea i al trabajador j, $c_{ij}$ está tabulado en una matriz.
El árbol de recubrimiento mínimo para un grafo no dirigido con pesos.

Q: En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es mayor que el valor de una cota optimista? (se entiende que ambas cotas se aplican sobre el mismo nodo)
A:3
No, nunca es así.
En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.
En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.

Q: La mejora que en general aporta programación dinámica frente a la solución ingenua se consigue gracias al hecho de que...
A:1
... en la solución ingenua se resuelve muchas veces un número relativamente pequeño de subproblemas distintos.
... en la solución ingenua se resuelve pocas veces un número relativamente grande de subproblemas distintos.
El número de veces que se resuelven los subproblemas no tiene nada que ver con la eficiencia de los problemas resueltos mediante programación dinámica.

Q: ¿Garantiza el uso de una estrategia "divide y vencerás" la existencia de una solución de complejidad temporal polinómica a cualquier problema?
A:1
No.
Sí, en cualquier caso.
Sí, pero siempre que la complejidad temporal conjunta de las operaciones de descomposición de problema y la combinación de las soluciones sea polinómica.

Q: Sea A una matriz cuadrada n x n. Se trata de buscar una permutación de las columnas tal que la suma de los elementos de la diagonal principal se mínima. Indica cuál de las siguientes afirmaciones es falsa:
A:3
Si se construye una solución al problema basada en el esquema de ramificación y poda, una buena elección de cotas optimistas y pesimistas podría evitar la exploración de todas las permutaciones posibles.
La complejidad temporal de la mejor solución posible al problema es $O(n!)$.
La complejidad temporal de la mejor solución posible al problema es $O(n^2)$.

Q: En el esquema de vuelta atrás, los mecanismos de poda basados en la mejor solución hasta el momento...
A:2
... garantizan que no se va a explorar nunca todo el espacio de soluciones posibles.
... pueden eliminar soluciones parciales que son factibles.
Las otras dos opciones son correctas.

Q: ¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, una solución voraz que es óptima?
A:1
El problema de la mochila discreta
El árbol de cobertura de coste mínimo de un grafo conexo.
El problema de la mochila continua o con fraccionamiento.

Q: La solución recursiva ingenua (pero correcta) a un problema de optimización llama más de una vez a la función con los mismos parámetros. Una de las siguientes afirmaciones es falsa.
A:3
Se puede mejorar la eficiencia del algoritmo guardando en una tabla el valor devuelto para cada conjunto de parámetros de cada llamada cuando ésta se produce por primera vez.
Se puede mejorar la eficacia del algoritmo definiendo de antemano el orden en el que se deben calcular las soluciones a los subproblemas y llenando una tabla en ese orden.
Se puede mejorar la eficiencia del algoritmo convirtiendo el algoritmo recursivo directamente en iterativo sin cambiar su funcionamiento básico.

Q: Una de estas tres situaciones no es posible:
A:1
$f(n) \in \Omega(n^2)$ y $f(n) \in O(n)$
$f(n) \in O(n)$ y $f(n) \in O(n^2)$
$f(n) \in O(n)$ y $f(n) \in \Omega(1)$

Q: La complejidad en el mejor de los casos de un algoritmo de ramificación y poda...
A:1
... puede ser polinómica con el número de decisiones a tomar.
... suele ser polinómica con el número de alternativas por cada decisión.
... es siempre exponencial con el número de decisiones a tomar.

Q: Si un problema de optimización lo es para una función que toma valores continuos...
A:3
La programación dinámica recursiva siempre es mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
El uso de memoria de la programación dinámica iterativa y de la programación dinámica recursiva es el mismo independientemente de si el dominio es discreto o continuo.
La programación dinámica recursiva puede resultar mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.

Q: Di cuál de estos tres algoritmos no es un algoritmo de "divide y vencerás":
A:3
Quicksort.
Mergesort.
El algoritmo de Prim.

Q: Dado un problema de optimización cualquiera, ¿la estrategia de vuelta atrás garantiza la solución óptima?
A:1
Es condición necesaria que el dominio de las decisiones sea discreto o discretizable y que el número de decisiones a tomar esté acotado.
Sí, siempre que el dominio de las decisiones sea discreto o discretizable y además se empleen mecanismos de poda basados en la mejor solución hasta el momento.
Sí, puesto que ese método analiza todas las posibilidades.

Q: La complejidad temporal en el mejor de los casos...
A:3
... es el tiempo que tarda el algoritmo en resolver el problema de tamaño o talla más pequeña que se le puede presentar.
Las dos opciones son ciertas.
... es una función del tamaño o talla del problema que tiene que estar definida para todos los posibles valores de está.

Q: La mejor solución que se conoce para el problema de la mochila continua sigue el esquema de...
A:3
... ramificación y poda.
... voraz.
... divide y vencerás

Q: Un problema de tamaño n puede transformarse en tiempo $O(n^2)$ en otro de tamaño n - 1. Por otro lado, la solución al problema cuando la talla es 1 requiere tiempo constante. ¿cuál de estas clases de coste temporal asintótico es la más ajustada?
A:1
$O(n^3)$
$O(2^n)$
$O(n^2)$

Q: Cuando se usa un algoritmo voraz para abordar la resolución de un problema de optimización por selección discreta (es decir, un problema para el cual la solución consiste en encontrar un subconjunto del conjunto de elementos que optimiza una determinada función), ¿cuál de estas tres cosas es imposible que ocurra?
A:3
Que el algoritmo no encuentre ninguna solución.
Que la solución no sea óptima.
Que se reconsidere la decisión ya tomada anteriormente respecto a la selección de un elemento a la vista de la de la decisión que se debe tomar en el instante actual.

Q: En un problema de optimización, si el dominio de las decisiones es un conjunto finito,
A:1
una estrategia voraz puede ser la única alternativa.
podremos aplicar el esquema de vuelta atrás siempre que se trate de un conjunto infinito numerable.
es probable que a través de programación dinámica se obtenga un algoritmo eficaz que lo solucione.

Q: En los algoritmos de ramificación y poda...
A:1
Una cota optimista es necesariamente un valor insuperable, de no ser así se podría podar el nodo que conduce a la solución óptima.
Una cota pesimista es el valor que a lo sumo alcanza cualquier nodo factible que no es el óptimo.
Una cota optimista es necesariamente un valor alcanzable, de no ser así no está garantizando que se encuentre la solución óptima.

Q: Si para resolver un mismo problema usamos un algoritmo de vuelta atrás y lo modificamos mínimamente para convertirlo en un algoritmo de ramificación y poda, ¿qué cambiamos realmente?
A:3
Cambiamos la función que damos a la cota pesimista.
La comprobación de las soluciones factibles: en ramificación y poda no es necesario puesto que sólo genere nodos factibles.
El algoritmo puede aprovechar mejor las cotas optimistas.

Q: ¿Cuál de estos problemas tiene una solución eficiente utilizando programación dinámica?
A:1
El problemas del cambio.
La mochila discreta sin restricciones adicionales.
El problema de la asignación de tareas.

Q: La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición...
A:3
... se comporta mejor cuando el vector ya está ordenado.
... no presenta caso mejor y caso peor para instancias del mismo tamaño.
... se comporta peor cuando el vector ya está ordenado.

Q: En el esquema de vuelta atrás el orden en el que se van asignando los distintos valores a la componentes del vector que contendrá la solución...
A:3
... puede ser relevante si se utilizan mecanismos de poda basados en estimaciones optimistas.
... es irrelevante si no se utilizan mecanismos de poda basados en la mejor solución hasta el momento.
Las otras dos opciones son correctas.

Q: Decid cuál de estas tres es la cota pesimista más ajustada al valor óptimo de la mochila discreta:
A:2
El valor de una mochila que contiene todos los objetos aunque se pase del peso máximo permitido.
El valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor específico de los objetos.
El valor de la mochila continua correspondiente.

Q: La complejidad en el mejor de los casos...
A:2
Las dos anteriores son ciertas
es una función de la talla, o tamaño del problema, que tiene que estar definida para todos los posibles valores de esta
es el tiempo que tarda el algoritmo en resolver la talla mas pequeña que se le puede presentar

Q: Marca la falsa
A:1
$n + n \log(n) \in \Theta(n)$
$3n^2 + 1 \in O(n^3)$
$n + n \log(n) \in \Omega(n)$

Q: Queremos generar todas las formas distintas de mezclar n substancias de forma que el peso no supere el gramo. Queremos hacer un programa que genere todas las combinaciones posibles
A:3
No se puede usar Backtracking porque las decisiones no son valores discretos
No se puede usar Backtracking porque el número de combinaciones es infinito
No hay ningún problema en usar Backtracking

Q: Las relaciones de recurrencia...
A:3
sirven para reducir el coste temporal de una solución cuando es prohibitivo
aparecen sólo cuando la solución sea del tipo divide y vencerás
expresan recursivamente el coste temporal de un algoritmo

Q: Los algoritmos de programación dinámica hacen uso de...
A:1
que se puede ahorrar cálculos guardando resultados anteriores en un almacén
una estrategia trivial consistente en examinar todas las posibles soluciones
que la solución óptima se puede construir añadiendo a la solución el elemento óptimo de los elementos restante, uno a uno

Q: Cuando resolvemos un problema mediante RyP
A:3
las decisiones solo pueden ser binarias
los valores entre los cuales se elige en cada una de las decisiones pueden formar un conjunto infinito
los valores entre los cuales se elige en cada una de las decisiones tienen que formar un conjunto finito

Q: Un algoritmo recursivo basado en divide y vencerás
A:2
Las demás son ciertas
será mas eficiente cuanto mas equitativa sea la división en subproblemas
Nunca tendrá complejidad exponencial

Q: Para que sirven las cotas pesimistas en RyP
A:1
Para descartar nodos basándose en el beneficio esperado
Para tener la certeza de que la cota optimista está bien calculada
Para descartar nodos basándose en la preferencia por algún otro nodo ya completado

Q: Al resolver el problema del viajante de comercio con Backtracking, cual de estas es una buena cota pesimista?
A:2
se ordenan las aristas restante de menor a mayor distancia y se calcula la suma de las n ciudades
se resuelve el problema usando un algoritmo voraz que añade cada vez al camino el vértice más cercano al último añadido
se multiplica n por la distancia de la arista más corta que nos queda por considerar

Q: La eficiencia de los algoritmos voraces se basa en
A:3
El hecho de que, con antelación, las posibles decisiones se ordenan de mejor a peor
En el esquema voraz no se puede hablar de eficiencia
El hecho de que las decisiones tomadas no se reconsideran

Q: $f(n) = \sqrt{n} + 3f(n/3)$
A:1
$f(n) \in O(n)$
$f(n) \in O(\sqrt{n} \log n)$
$f(n) \in O(n^3)$

Q: ¿Cuál es la complejidad temporal de la siguiente función recursiva?
```cpp
unsigned desperdicio(unsigned n) {
	if (n <= 1)
		return 0;
	unsigned sum = desperdicio(n/2) + desperdicio(n/2);
	for (unsigned i = 1; i < n-1; i++)
		for (unsigned j = 1; j <= i; j++)
			sum += i * j;
	return sum;
}
```
A:2
$O(2^n)$
$O(n^2)$
$O(n^2 \log n)$

Q: Sea f(n) la solución de $f(n) = 2f(n/2) + n$, $f(1) = 1$
A:3
$f(n) \in O(n)$
$f(n) \in O(n^2)$
$f(n) \in O(n \log n)$

Q: Sea $f(n) = 2f(n/2) + 1$, $f(1) = 1$
A:2
$f(n) \in O(n \log(n))$
$f(n) \in O(n)$
$f(n) \in O(n^2)$

Q: La complejidad temporal en el mejor de los casos de un algoritmo recursivo
A:2
coincide con el valor del caso base de la ecuación de recurrencia
Las demás son falsas
siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo

Q: Marca la FALSA
A:2
$\Theta(n/2) = \Theta(n)$
$\Theta(n) \subset \Theta(n^2)$
$\Theta(n) \subset O(n)$

Q: Que problema se da, y como se puede resolver, cuando se calcula el coeficiente binomial
A:3
La recursión puede ser infinita y por tanto es necesario organizarla según el esquema iterativo del programa
Se repiten muchos cálculos y ello se puede evitar haciendo uso de una estrategia voraz
Se repiten muchos cálculos y ello se puede evitar usando programación dinámica

Q: Los algoritmos de ordenación Quicksort y Mergesort tienen en común...
A:2
que ordenan el vector sin usar espacio adicional
que aplican la estrategia divide y vencerás
que se ejecutan en $O(n)$

Q: Cual de estos tres problemas de optimización no tiene solución voraz óptima
A:1
mochila discreta
mochila continua
árbol de recubrimiento de coste mínimo

Q: Un programa con dos bucles anidados, el primero hace n iteraciones y el segundo la mitad...
A:3
$O(n \log(n))$
$O(n\sqrt{n})$
$O(n^2)$

Q: $f(n) = 2f(n/2) + n$, $f(1) = 1$
A:1
$f(n) \in O(n \log(n))$
$f(n) \in O(n^2)$
$f(n) \in O(n)$

Q: La estrategia de RyP genera las soluciones posibles mediante...
A:2
un recorrido en profundidad del árbol que representa el espacio de soluciones
un recorrido guiado por estimaciones de las mejores ramas del árbol que representa el espacio de soluciones
un recorrido en anchura del árbol que representa el espacio de soluciones

Q: La complejidad en el caso peor un algoritmo RyP
A:3
puede ser exponencial con el número de alternativas por cada decisión
puede ser polinómica con el número de decisiones a tomar
es exponencial con el número de decisiones a tomar

Q: ¿Pertenece $3n^2 + 3$ a $O(n^3)$?
A:2
Solo para $c = 1$ y $n_0 = 5$
Sí
No

Q: Que algoritmo es mas rápido, quicksort o mergesort?
A:3
el mergesort es siempre más rápido
como su nombre indica, el quicksort
son los dos igual de rápidos: $O(n \log(n))$

Q: Marca la falsa
A:3
$n + n \log(n) \in \Omega(n)$
$2n^2 + 3n + 1 \in O(n^3)$
$n + n \log(n) \in \Theta(n)$

Q: Dado un problema de optimización, se puede usar backtracking cuando...
A:3
Es condición necesaria y suficiente que el dominio de decisiones sea discreto o discretizable
De cumplirse que se puedan emplear mecanismos de poda basados en la mejor solución hasta el momento
Es condición necesaria, (aunque no suficiente) que el dominio de decisiones sea discreto o discretizable

Q: Tenemos un conjunto de n enteros positivos y queremos encontrar el subconjunto de tamaño m de suma mínima
A:1
Una técnica voraz daría una solución óptima
Para encontrar la solución habría que probar con todas las combinaciones posibles de m enteros, con lo que RyP no aporta nada con respecto a Backtracking
Lo mas adecuado sería usar una técnica de ramificación y poda, aunque en el peor caso el coste temporal sería exponencial

Q: La solución ingenua a un problema de optimización, por un lado se basa en obtener soluciones óptimas a problemas parciales mas pequeños, y por otro, estos subproblemas se resuelven más de una vez. Este problema tiene una solución alternativa basada en...
A:1
Programación dinámica
Divide y vencerás
Voraz

Q: Marca la FALSA
A:1
La ordenación de un vector usando Mergesort requiere en el caso peor un tiempo de $O(n^2)$
La ordenación de un vector usando el algoritmo Quicksort requiere en el peor caso un tiempo $O(n^2)$
La búsqueda binaria en un vector ordenado requiere en el peor caso un tiempo de $O(\log n)$

Q: $f(n) = n^2 + 3f(n/3)$
A:2
$O(n^2 \log n)$
$O(n^2)$
$O(n)$

Q: Sea $f(n) = 2f(n - 1) + 1$
A:2
$f(n) \in O(n)$
$f(n) \in O(2^n)$
$f(n) \in O(n^2)$

Q: Cual de estas tres estrategias voraces obtiene un mejor valor para la mochila discreta
A:3
Meter primero los elementos de menor peso
Meter primero los elementos de mayor valor
Meter primero los elementos de mayor valor específico o valor por unidad de peso

Q: En un programa con dos bucles anidados, cada uno de los cuáles hace n iteraciones tarda:
A:1
$O(n^2)$
$O(n)$
$O(2^n)$

Q: Cuando se resuelve, usando Backtracking, un problema de n decisiones, en el que siempre hay como mínimo dos opciones por decisión, cual de estas complejidades en el caso peor es la mejor que nos podemos encontrar
A:2
$O(n!)$
$O(2^n)$
$O(n^2)$

Q: Los algoritmos de programación dinámica hacen uso...
A:1
de que se puede ahorrar esfuerzo guardando los resultados de esfuerzos anteriores
de que la solución óptima se puede construir añadiendo el componente óptimo de los restantes, uno a uno
de una estrategia trivial consistente en examinar todas las soluciones posibles

Q: Para resolver un mismo problema usamos un algoritmo de RyP y lo modificamos para convertirlo en Backtracking
A:1
Provocamos que las cotas optimistas pierdan eficacia
Sería necesario comprobar si las soluciones son factible o no puesto que RyP solo genera nodos factibles
Cambiamos la función que damos a la cota pesimista

Q: La ventaja de RyP frente a Backtracking es que la primera genera las soluciones posibles al problema mediante..
A:1
Las otras dos son verdaderas
un recorrido guiado por la cola de prioridad de donde se extraen primero los nodos que representan subárboles más prometedores del espacio de soluciones
Un recorrido guiado por estimaciones de las mejores ramas del árbol que representa el espacio de soluciones

Q: Marca la CORRECTA
A:3
$O(n^2) \subset O(2^{\log(n)}) \subset O(2^n)$
$O(n^2) \subset O(2^{\log(n)}) \subset O(2^n)$
$O(2^{\log(n)}) \subset O(n^2) \subset O(2^n)$

Q: En RyP
A:3
cada nodo tiene su propia cota pesimista, la optimista sin embargo, es común a todos los nodos
cada nodo tiene su propia cota optimista, la pesimista sin embargo, es común a todos los nodos
cada nodo tiene su propia cota optimista y pesimista

Q: El coste temporal del algoritmo de ordenación por inserción es
A:2
$O(n \log(n))$
$O(n^2)$
$O(n)$

Q: Se pretende resolver el problema del viajante de comercio (travelling salesman problem) mediante el esquema de vuelta atrás. ¿Cuál de los siguientes valores se espera que se comporte mejor como cota optimista para un nodo?
A:1
La suma de los pesos de las k aristas restantes más cortas, donde k es el número de ciudades que quedan por visitar.
La suma de los pesos de las aristas que completan la solución paso a paso visitando el vértice más cercano al último visitado.
El valor que se obtiene de multiplicar k por el peso de la arista más corta de entre las restantes, donde k es el número de ciudades que quedan por visitar.

Q: Indica cuál es la complejidad temporal en función de n, donde A es un vector de enteros y k es una constante que no depende de n, del fragmento siguiente:
```cpp
for(int i = k; i < n-k; i++) {
	A[i] = 0;
	for(int j = i-k; j < i+k; j++)
		A[i] += B[j];
}
```
A:2
$\Theta(k)$
$\Theta(n)$
$\Theta(n^2)$

Q: ¿Qué obtenemos con la siguiente declaración de C++: `priority_queue<nodo> pq;` ?
A:1
Un heap o montículo de máximos.
Un heap o montículo de mínimos.
Un heap o montículo sin orden establecido ya que no se ha definido la función de comparación.

Q: Para resolver la versión general del problema de la mochila con n objetos y carga máxima W , hemos escrito un algoritmo de divide y vencerás que, sucesivamente, divide el problema en dos subproblemas; cada uno de ellos toma la mitad de los objetos y la mitad de la carga máxima de la mochila. El caso base ocurre cuando solo hay un objeto que se añade a la solución si cabe en la fracción de carga máxima que corresponde a ese subproblema, y si no cabe se descarta. Asumiendo que n y W son potencias exactas de 2, ¿qué podemos decir de esta solución?
A:3
Que, aunque con los resultados de los subproblemas se puede componer la solución del problema original, esta formulación no mejora la solución estudiada en clase.
Que no cumple el teorema de reducción.
Que con los resultados de los subproblemas no siempre se puede componer la solución del problema original.

Q: De las siguientes expresiones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
A:2
$\sum_{i=1}^{n/2} \sum_{j=1}^{i} 2^j \in O(n \log n)$
$\sum_{i=1}^{n} \sum_{j=1}^{\log i} 2^j \in O(n^2)$
$\sum_{i=1}^{\log n} \sum_{j=1}^{n} 2^j \in O(n \log n)$

Q: Dados dos nodos cualesquiera del árbol de búsqueda de ramificación y poda, en general, ¿se puede saber con certeza cuál está más cerca de la solución óptima del problema a resolver?
A:1
Sí, pero solo si ambos nodos son hoja.
Sí, el que tiene mejor cota pesimista.
Sí, el que tiene mejor cota optimista.

Q: El problema de la moneda consiste a formar una suma M con el número mínimo de monedas tomadas (con repetición) de un conjunto C donde hay una cantidad suficientemente grande de monedas con cada posible valor facial $C = \{c_1, c_2, \ldots, c_k\}$, con $c_1 = 1$. ¿Cuál de estas afirmaciones sobre un algoritmo recursivo de la forma $n_{opt}(M) = 1 + \min_{1 \leq i \leq |C|} n_{opt}(M - c_i)$; $n_{opt}(0) = 0$; $n_{opt}(x) = \infty$ para $x < 0$ es falsa?
A:1
Dependiendo de cuáles sean los valores faciales y la suma, puede ser que el algoritmo recursivo no encuentre solución.
Encuentra siempre la solución óptima.
Tiene un coste temporal prohibitivo, ya que puede calcular $n_{opt}(x)$ para el mismo valor de x más de una vez.

Q: ¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia?
```
f(n) = n(n-1) + f(n-1) # si n>0
f(0) = 1 # si n=0
```
A:1
$f(n) \in \Theta(n^3)$
$f(n) \in \Theta(n^2)$
Ninguna de las otras dos opciones es cierta.

Q: Una empresa de transportes dispone de M vehículos para repartir N paquetes, todos al mismo destino. Cada paquete i tiene un peso $P_i$ y se tiene que entregar antes de que transcurra un tiempo $TP_i$. Por otro lado, cada vehículo j puede transportar una carga máxima $C_j$, tarda un tiempo $TV_j$ para llegar al destino y consume una cantidad $L_j$ de litros de combustible, independientemente de la carga que transporta. Imaginad un algoritmo de vuelta atrás que obtenga la manera en que se tienen que transportar los objetos (en qué vehículo j tiene que ir cada objeto i) para que el consumo sea el mínimo. ¿Cuál sería una buena cota optimista?
A:2
La solución voraz del problema de cargar cada paquete en el camión de menor consumo donde cada paquete llega a tiempo, sin tener en cuenta si el camión se sobrecarga o no.
Ambas son cotas optimistas válidas.
La solución voraz del problema de cargar cada paquete en el camión de menor consumo, sin sobrecargarlo, sin tener en cuenta si el paquete llega a tiempo o no.

Q: Se dispone de un conjunto de n valores numéricos dispuestos en forma de montículo y se desea obtener el valor de la suma de todos los que al menos tienen un hijo (es decir, no son nodos hoja). ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
A:2
$O(\log n)$
$O(n)$
$O(n \log n)$

Q: ¿Cuál es el coste de monticulizar (heapify) un vector de tamaño N?
A:2
$O(N)$ y $\Omega(1)$
$\Theta(N)$
$O(N \log N)$ y $\Omega(N)$

Q: En cuanto a la posibilidad de aplicar la técnica de programación dinámica iterativa para resolver un problema:
A:1
Se debe conocer de antemano todos los posibles subproblemas y además, se debe disponer de una ordenación entre todos ellos según tamaño.
No necesariamente ha de conocerse de antemano todos los posibles subproblemas pero sí debe saberse, dados dos de ellos cualesquiera, cuál es más pequeño.
Se debe conocer de antemano todos los posibles subproblemas pero no necesariamente se debe disponer de una ordenación entre todos ellos según tamaño.

Q: Con los valores numéricos almacenados en un fichero, queremos construir un heap (montículo). ¿cuál es la forma más eficiente de proceder?
A:1
Almacenar esos valores en un vector y después, reorganizar sus elementos para que estén dispuestos en forma de heap.
Ambas formas de proceder son equivalentes en cuanto a eficiencia.
Almacenar esos valores directamente en un heap que inicialmente está vacío y va creciendo por cada uno de los valores insertados.

Q: Se dispone de un conjunto de n valores numéricos dispuestos en un vector sin orden preestablecido. Se desea escribir una función que reciba ese vector y un valor k ($n/2 \leq k \leq n$) y que devuelva los k valores más pequeños dispuestos en otro vector de manera ordenada. ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
A:3
Ninguna de las otras dos opciones es cierta.
$O(kn)$
$O(k \log n)$

Q: Queremos aplicar la técnica de memoización a la función recursiva de la imagen. ¿Cuál sería un buen candidato para el almacén? (La función `sqrt()` obtiene la raíz cuadrada; xMax es el valor de x en la primera llamada.)
```cpp
double f(double x) {
	if (x <= 2)
		return x;
	return f(sqrt(x-1)) + f(sqrt(x-2));
}
```
A:1
Ninguna de las otras dos opciones es válida.
`vector<double> M(xMax+1)`
`vector<vector<double>> M(xMax+1, vector<double>(xMax+1))`

Q: Con respecto a los algoritmos estudiados durante el curso que encuentran el árbol de recubrimiento de mínimo coste, de las afirmaciones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos.
A:1
El algoritmo de Kruskal va construyendo un bosque de árboles que va uniendo hasta que acaba con un árbol de recubrimiento de coste mínimo.
La complejidad temporal del algoritmo de Prim es cúbica con respecto al número de vértices del grafo.
El algoritmo de Prim se puede acelerar notablemente si los vértices se organizan en una estructura union-find.

Q: ¿Cuál es la complejidad, en función de n, del siguiente fragmento: (suponed que A está definido como `vector<int> A(n)` y `sort()` es la función de ordenación de la librería estándar de C++, que tiene la mejor complejidad, temporal y espacial, posible para un algoritmo de ordenación de propósito general.)
```cpp
std::sort(begin(A), end(A));
int acc = 0;
for (auto i : A)
	acc += i;
```
A:2
$\Theta(n^2)$
$\Theta(n \log n)$
$\Theta(n)$

Q: Sea el vector v = {1, 3, 2, 7, 4, 6, 8} cuyos elementos están dispuestos formando un montículo de mínimos. Posteriormente añadimos en la última posición del vector un elemento nuevo con valor 5. ¿Qué operación hay que hacer para que el vector siga representando un montículo de mínimos?
A:3
Intercambiar el 8 con el 5.
No hay que hacer nada pues el vector v = {1, 3, 2, 7, 4, 6, 8, 5} también es un montículo de mínimos.
Intercambiar el 7 con el 5.

Q: ¿Cuál es la complejidad temporal en función de n, del siguiente fragmento:
```cpp
for (int i = 0; i < n; i++) {
	A[i] = 0;
	for (int j = 0; j < 20; j++)
		A[i] += B[j];
}
```
A:2
$\Theta(n \log n)$
$\Theta(n)$
$\Theta(n^2)$

Q: En un algoritmo de búsqueda y enumeración, ¿qué podemos decir acerca de la heurística que se utiliza para determinar si un nodo debe expandirse o no?
A:1
Que también puede usarse como estrategia de búsqueda.
Que puede equivocarse, por eso se le llama heurística.
Las otras dos opciones son ambas ciertas.

Q: Un fontanero tiene una jornada de Q cuartos de hora (es así como se organiza la agenda) y tiene C clientes. El trabajo del cliente i tarda $q_i$ cuartos de hora y el fontanero le cobra un precio $p_i$. Es posible que no pueda atender todos los clientes en la jornada, que nunca puede alargar. Este problema tiene una solución bien conocida que permite elegir qué clientes visitar para que la suma cobrada al final de la jornada sea la máxima. ¿Qué podemos decir de esta solución?
A:1
Que la organización de la agenda en cuartos de hora permite obtener una solución de complejidad temporal $\Theta(QC)$ y complejidad espacial $\Theta(Q)$.
Que se ha de implementar forzosamente con un algoritmo de búsqueda y enumeración como el de vuelta atrás.
Que no se puede implementar con una solución de "divide y vencerás" con memoización.

¿Puede ocurrir que la solución recursiva de estilo “divide y vencerás” pero con memoización de un problema resuelva menos subproblemas que la mejor solución iterativa posible de programación dinámica?
2
Sí, porque no existe garantía de que la mejor solución iterativa posible no resuelva problemas repetidos, mientras que la técnica de memoización lo garantiza directamente mediante el uso de un almacén.
Sí, porque la mejor solución iterativa posible de programación dinámica puede resolversubproblemas que no sean necesarios al resolver subproblemas posteriores.
No, nunca.

Sea un problema de optimización por selección discreta, con restricciones, en el que se debentomar n decisiones booleanas para optimizar un indicador, y se abordará mediante un método de búsqueda y enumeración (vuelta atrás, ramificación y poda). ¿Cuál de las siguientes afirmaciones es correcta?
2
La complejidad temporal será como mucho O(n·log(n)) porque en general basta con ordenar adecuadamente las decisiones para convertir cualquier problema de este tipo en un problema de complejidad temporal lineal.
Puede haber problemas para los que la complejidad será exponencial o peor; ningunaestrategia de poda puede garantizar que esto no va a ocurrir.
La complejidad temporal en el peor caso será O(n²) ya que se toman n decisiones binarias.

Se pretende calcular el valor $$2^n$$, $$n\in N$$, haciendo una transcripción literal de la expresión de la imagen. ¿Cuál sería la complejidad temporal asintótica, en función de n, del algoritmo resultante? \n\n\t\t\t\t\t\t $$2^n = 1 + \sum_{i=0}^{n-1} \prod_{j=1}^{i} 2$$
3
O(n)
O(2^n)
O(n²)

Un algoritmo recursivo basado en el esquema divide y vencerás ...
3
Las dos anteriores son verdaderas.
... nunca tendrá un coste temporal asintótico exponencial.
... alcanza su máxima eficiencia cuando el problema de tamaño n se divide en a problemas de tamaño n/a.

Se dispone de un conjunto de n valores numéricos dispuestos en forma de árbol binario y se desea obtener el valor de la suma de todos ellos. ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
2
O(log(n))
O(n)
O(n·log(n))

¿Cuál de las siguientes formulaciones expresa mejor la complejidad temporal, en función delparámetro n, de la siguiente función? (asumimos que n es potencia exacta de 2)```int f(int n){ \n\tint k=0; \n\tfor (int i=2; i<=n; i*=2) \n\t\tfor (int j=i; j>0; j-=2) \n\t\t\tk++; \n\treturn k; \n} ```
3
$$\sum_{p=2}^{n/2}$$  (p - 1)/2
$$\sum_{p=1}^{\log n} 2 \cdot (p - 1)$$
$$\sum_{p=1}^{\log n} 2^{p-1}$$

Sea el vector v[8] = {8, 6, 4, 5, 4, 3, 2, 2}. Indica cuál de las siguientes opciones es cierta. (se asume la notación del lenguaje C/C++ en la que el primer elemento del vector está en la posición 0, es decir, en v[0]).
3
El vector v no es un montículo máximo porque el elemento v[2]=4 debe ser “hundido”(desplazado hacia la derecha)..
El vector v no es un montículo máximo porque el elemento v[3]=5 debe ser “flotado”(desplazado hacia la izquierda).
El vector v es un montículo máximo.

¿Se puede resolver mediante ramificación y poda un problema de selección discreta en el que cada una de las n decisiones se toman de un conjunto finito diferente?
3
No. Las decisiones deben ser todas de la misma naturaleza.
Sí, pero sólo si las decisiones son todas binarias.
Sí, siempre.

¿Podemos saber cuál sería el elemento en posición k cuando ordenáramos un vector de n elementos sin tener que ordenarlo?
1
Sí, y el algoritmo es Ω(n) y O(n²), aunque la frecuencia de los casos peores disminuye muy rápidamente con n.
Sí, y el algoritmo es Ω(n·log(n)) y O(n²), aunque la frecuencia de los casos peores disminuye muy rápidamente con n.
No. Debemos ordenarlo.

De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
3
Ω(n) ⊂ Ω(1)
Θ(log(n²)) = Θ(log(n³))
O(n) ⊂ O(1)

Cuál es la complejidad temporal en función del tamaño del problema (n) de multiplicar dos matrices cuadradas?
1
O(n^(3/2))
O(n²)
O(n³)

Se pretende mejorar mediante programación dinámica iterativa la siguiente función (v1 y v2 son vectores definidos como variables globales). ¿Cuál es la mejor complejidad espacial que se puede conseguir?```float f(unsigned n, int m){ \n\tif (m < 0) \n\t\treturn 0; \n\tfloat A = 0.0; \n\tif (v1[m] <= n) \n\t\tA = v2[m] + f( n-v1[m], m-1 ); \n\tfloat B = f( n, m-1 ); \n\treturn A+B; \n}```
2
O(m·n)
O(n)
O(m)

Encargamos a un becario que elabore un algoritmo para sumar todos los números de un vector.Al cabo de un rato nos viene con un algoritmo cuya complejidad temporal es O(log(n)). ¿Qué hacemos?
1
Despedimos al becario, eso es imposible.
Subimos el sueldo al becario, ha encontrado un algoritmo innovador.
Damos las gracias al becario, ese es el algoritmo obvio.

¿Cuál de estos problemas no tiene una solución eficiente utilizando programación dinámica?
1
El problema de la asignación de tareas.
El problema del cambio.
La mochila discreta cuyos pesos son números naturales.

Una de las tres afirmaciones siguientes sobre los algoritmos que obtienen el árbol de recubrimiento mínimo de un grafo ponderado no dirigido es cierta. ¿Cuál es?
3
El algoritmo de Kruskal va ampliando un único árbol de recubrimiento mínimo.
El algoritmo de Prim se puede acelerar usando una estructura de datos de conjuntos disjuntos con las operaciones union y find.
El algoritmo de Prim va ampliando un único árbol de recubrimiento mínimo.

El esquema voraz...
3
Puede que no encuentre una solución pero si lo hace se garantiza que es la óptima.
Garantiza encontrar una solución a cualquier problema, aunque puede que no sea óptima.
Las otras dos opciones son ambas falsas.

Tenemos un conjunto de n enteros positivos y queremos encontrar el subconjunto de tamaño m de suma mínima.
2
Para encontrar la solución habría que probar con todas las combinaciones posibles de menteros, con lo que la técnica de ramificación y poda no aporta nada con respecto a vuelta atrás.
Una técnica voraz daría una solución óptima.
Lo más adecuado sería usar una técnica de ramificación y poda, aunque en el peor caso el coste temporal asintótico (o complejidad temporal) sería exponencial.

Existen dos algoritmos que para ordenar un vector de n elementos, buscan el máximo de esos n elementos, lo intercambian con el n-ésimo elemento para ponerlo al final, y luego ordenan, usando el mismo algoritmo, el vector de las primeras n - 1 componentes. ¿Cuál de las afirmaciones siguientes es cierta?
2
Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar laordenación por burbuja o bubblesort; el primero tiene un coste temporal O(n·log(n)) y el segundo, O(n²).
Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizarla ordenación por selección; el primero tiene un coste temporal O(n·log(n)) y el segundo,O(n²).
Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar laordenación por selección; el primero tiene un coste temporal O(n) y el segundo, O(n²).

En la estrategia de ramificación y poda se suele usar una cola de prioridad para decidir en quéorden se expanden los nodos. Imaginemos un problema de optimización. ¿Puede ser que el valor por el cual se ordenan los nodos sea una cota pesimista del nodo?
2
No, porque para podar necesitamos una cota optimista.
Sí.
No, porque una cota pesimista es típicamente el valor que se encuentra en una de las hojas que cuelga del nodo.

En un algoritmo de búsqueda exhaustiva, ¿Qué ocurre si la cota pesimista de un nodo se corresponde con una solución que no es factible?
3
Que el algoritmo sería más lento pues se explorarían más nodos de los necesarios.
Nada especial, las cotas pesimistas no tienen por qué corresponderse con soluciones factibles.
Que podría descartarse un nodo que conduce a la solución óptima.

Tengo que sumar una larga lista de n cantidades diferentes y se me ha ocurrido que una manera de ganar tiempo es la siguiente estrategia recursiva: parto la lista en dos sublistas iguales, calculo su suma por separado usando la misma técnica y luego sumo las dos cantidades. Cuando al partir una lista me quedo con una cantidad sólo, la suma es esa cantidad, y si me quedan cero cantidades, la suma es cero. ¿Gano tiempo, es decir, hago menos sumas?
2
No, en este caso el coste temporal es Θ(n·log(n)).
No, ya que la complejidad temporal del método propuesto es la misma que la de sumaruna a una las cantidades.
Sí, ya que en este caso el coste temporal se reduce a Θ(log(n)).

Se pretende resolver el problema del viajante de comercio (travelling salesman problem) mediante el esquema de vuelta atrás, ¿cuál de los siguientes valores se espera que se comporte mejor para decidir si un nodo es prometedor?
3
La suma de los pesos de las k aristas restantes más cortas, donde k es el número de ciudades que quedan por visitar.
El valor que se obtiene de multiplicar k por el peso de la arista más corta de entre lasrestantes, donde k es el número de ciudades que quedan por visitar.
El coste del mínimo árbol de recubrimiento de las ciudades restantes.

¿Cuál es el coste temporal de crear un montículo de máximos a partir de un vector ordenado demayor a menor?
2
Θ(1)
Θ(n)
Θ(n·log(n))

Con respecto al parámetro n, ¿Cuál sería la complejidad temporal de la siguiente función si seaplicara memoización?```long f(unsigned n) { \n\tif (n <= 1) \n\t\treturn 1; \n\treturn n * f(n - 2); \n}```
3
logarítmica
constante
lineal

En un problema de minimización resuelto mediante ramificación y poda, una cota pesimista es...
1
Ninguna de las otras dos opciones es cierta.
... una cota superior para el valor óptimo, pero que nunca coincide con este.
... una cota inferior para el valor óptimo que a veces coincide con este.

La complejidad temporal del algoritmo Mergesort cuando se aplica a un vector de tamaño nes. . . (selecciona la más ajustada)
2
. . . Ω(n) y O(n²).
. . . Θ(n·log(n)).
. . . Ω(n·log(n)) y O(n²).

De las siguientes situaciones, o bien dos son posibles y una no lo es, o bien al contrario, solo una es posible y las otras dos no lo son. Marca la que, en este sentido, es diferente a las demás.
1
f(n) ∈ O(n) y f(n) ∈ Ω(n²).
f(n) ∈ O(n) y f(n) ∈ Ω(1).
f(n) ∈ O(n) y f(n) ∈ O(n²).

¿Puede utilizarse relaciones de recurrencia para analizar la complejidad de un algoritmo de vuelta atrás?
3
No, ya que siempre saldría una complejidad exponencial
No, las relaciones de recurrencia no se pueden aplicar en este caso.
Sí

¿Cuál es el caso peor del algoritmo de ordenación Quicksort que toma el primer elemento comopivote?
2
Cuando el elemento pivote queda siempre en medio.
Cuando el elemento pivote queda siempre en uno de los dos extremos.
Cuando debemos hundir el pivote hasta el fondo del montículo.

En cuanto a la complejidad temporal de la siguiente función, ¿qué podemos decir acerca del mejor de los casos?```int f(vector<int> &v) { \n\tint n = v.size(), i = 2, k = 0; \n\twhile (i < n) { \n\t\tint j = i; \n\t\twhile (v[j] != v[1]) { \n\t\t\tk++; \n\t\t\tj = j / 2; \n\t\t} \n\t\ti = i + 2; \n\t} \n\treturn k; \n}```
1
Que uno de los mejores casos ocurre cuando v[j] = v[1] ∀j ∈ N y la complejidad es Ω(n).
Las otras dos opciones son ambas falsas.
Que el mejor de los casos ocurre cuando el vector tiene 2 elementos o menos y la complejidad es Ω(1).

Tenemos un “superprocesador” que tiene una instrucción que permite la ordenación de 100 elementos en un tiempo constante. Para este superprecesador, adaptamos el algoritmo  Mergesort de forma que cada vez que queremos ordenar menos de 100 elementos, en lugar de hacer las llamadas recursivas, llama a esta instrucción. ¿cuál serı́a la complejidad de este algoritmo?
1
O(n·log(n))
O(n)
O(1)

Uno de estos tres algoritmos de ordenación no opera directamente sobre el vector, y necesita almacenamiento adicional para los elementos del mismo. ¿Cuál es?
1
Mergesort
Quicksort
Heapsort

Los algoritmos Dijkstra, Floyd, Warshall y Kruskal resuelven respectivamente
3
Camino mínimo entre todos los vértices, camino mínimo de un vértice al resto, existencia de caminos entre todos los vértices, clausura transitiva
Camino mínimo de un vértice al resto, existencia de caminos mínimos, existencia de caminos entre todos los vértices, árbol de expansión mínimo
Camino mínimo de un vértice al resto, camino mínimo entre todos los vértices, existencia de caminos entre todos los vértices, árbol de expansión mínimo
Camino mínimo entre todos los vértices,  camino mínimo de un vértice al resto, existencia de camino de un vértice al resto, árbol de expansión mínimo

Cual de los siguientes recorridos sobre un montículo de máximos nos garantiza la obtención de sus elementos ordenados de manera descendente
1
Ninguna
InOrden
PostOrden
PreOrden

Considera el siguiente algoritmo:Nos interesa medir cuantas veces se ejecuta nº 3 entonces el caso mejor se obtiene cuando
4
Cuando los datos vienen dispuestos en orden inverso, que se ejecuta del orden de n^2 veces
Cuando los datos vienen ordenados ascendentemente, que se ejecuta del orden de n^2 veces
Cuando los datos vienen ordenados ascendentemente, que se ejecuta del orden de n veces
Cuando los datos vienen ordenados ascendentemente, que se ejecuta 0 veces.

Considera el siguiente algoritmo:Nos interesa medir cuantas veces se ejecuta nº 3 entonces el caso mejor se obtiene cuando :```Ordena (vector V[N] de enteros) \n\tint i, j, aux; \n\tfor (i=1; i < N; i++) { \n\t\tfor (j=0; j < N-i; j++) { \n\t\t\tif (V[j] > V[j+1]) { # (2) \n\t\t\t\taux = V[j]; \n\t\t\t\tV[j] = V[j+1]; # (3) \n\t\t\t\tV[j+1] = aux; \n\t\t\t} \n\t\t} \n\t}```
4
Cuando los datos vienen dispuestos en orden inverso, que se ejecuta del orden de n^2 veces
Cuando los datos vienen ordenados ascendentemente, que se ejecuta del orden de n^2 veces
Cuando los datos vienen ordenados ascendentemente, que se ejecuta del orden de n veces
Cuando los datos vienen ordenados ascendentemente, que se ejecuta 0 veces.

Supongamos que obtenemos de teclado una secuencia ordenada de datos la cual vamos a almacenar en un árbol binario ordenado entonces la gran ventaja de la estructura obtenida con respecto a una lista enlazada lineal
1
Realmente no existen ventajas
Esta en el coste de la operación de borrado
Esta en el coste de la operación de inserción
Esta en el coste de la operación de busqueda

Tenemos un problema en el que hay que almacenar un numero variable de tiendas en la que existen un numero también variable de artículos tanto las tiendas como los artículos tienen una clave identificativa teniendo en cuenta que tenemos que realizar muchas consultar inserciones y borrados de artículos que estructura será la mas adecuada para implementarlo tened en cuenta que una tienda se puede cerrar en cualquier momento y todos sus artículos serian repartidos por las demás tiendas
4
Un árbol AVL para las tiendas y dentro de cada AVL otro para los artículos
Una tabla hashing para las tiendas, y dentro de cada celda un conjunto de artículos
Una tabla hashing para almacenarlas tiendas y dentro de cada tienda un árbol AVL para los artículos
Un árbol AVL para las tiendas y dentro de cada nodo un árbol de búsqueda

Sea G un grafo dirigido y A+ la matriz de cierre transitivo entonces
2
Si A+[i,i] = 1 para algún valor de i significa que G es fuertemente conexo
Si A+[i,i] = 1 para algún valor de i G tiene al menos un ciclo partiendo de i
Si A+[i,i] = 1 para algún para todo  i significa que G es fuertemente conexo
Si A+[i,i] = 1 para algún valor de i existe un ciclo hamiltoniano partiendo de i

Considera el algoritmo descrito a continuacion. Si consideramos como medida significativa el numero de movimientos del vector instrucciones 1 y 3 entonces el algoritmo tiene un coste: ```for (i=1; i<N; i++) {\n\tX=V[i]; # (1) \n\tIzq=0;\n\tDer=i-1;\n\twhile (Izq <= Der) {\n\t\tMedio = (Izq+Der)/2;\n\t\tif (X<V[Medio]) #(2)\n\t\t\tDer=Medio-1;\n\t\telse\n\t\t\tIzq = Medio +1;\n\t}\n\tfor(j=i-1; j>=Izq; j--) {\n\t\tV[j+1] = V[j]; # (3) \n\t}\n\tV[Izq]=X;\n}```
4
Θ(n^2)
O(n)
Θ(n)
Ω(n) y O(n^2)

Calcula el numero de veces que se realiza la operación de escritura en la siguiente función siendo n el numero de elementos de la lista: ```Void imprime ( Lista L ) {\n\tDatosLista x;\n\tLista Aux;\n\tAux= L;\n\twhile (!L.Vacia()){\n\t\tx = L.Primero();\n\t\tcout <<x;\n\t\tAux.Resto();\n\t\tImprime(Aux);\n\t}\n}```
1
n
n+1
2n + 1
n-1
Ninguna de las anteriores

El algoritmo que se describe a continuación calcula: ```Función Ejercicio (ent A:ArbolBinarioGeneral):entero\nvariables Izq,Der: ArbolBinarioGeneral\ninicio\n\t si NO A.Vacio entonces\n\t\tA.HijoIzq(Izq); A.HijoDer(Der);\n\t\tretorna(ejercicio(izq)+ejercicio(der)+1)\n\t si no\n\t\tretorna (0)\n\tfinsi\nfin```
3
El nivel en el que se encuentra (hijo izquierdo + hijo derecho + 1) del árbol A
Cuantos niveles distintos tiene el árbol A
Ninguna de las anteriores
El numero de veces que aparece el hijo izquierdo y el derecho en el árbol A
El grado del árbol A

Tras aplicar el algoritmo MM sobre un grafo dirigido y no valuado se obtiene que la matriz C resultante tiene todo a 1's menos la diagonal principal que esta a 0's entonces con este resultado podemos asegurar
3
Que existen n componentes fuertemente conexas
Que el grafo no es fuertemente conexo
Ninguna de las anteriores
Que el grado es aciclico

Cual es la complejidad de la función pertenece de un dato, en un árbol binario ordenado
1
Ω(1) y O(n)
Θ(log n)
Ω(1) y O(n^2)
Ninguna de las anterirores

Sea A un árbol binario ordenado de n nodos, en el que todos sus elementos son distintos entonces la operación de búsqueda de un elemento que no esta en el árbol tendrá un coste
3
O(log n)
Ω(log n) y O(n)
Θ(log n)
Θ(n)

Su ecuación de recurrencia es: ```Función F (ent n: entero): entero\n\tvariables x, i: entero\n\tInicio\n\tsi (n>=1) entonces\n\t\tretorna 1\n\tsi no\n\t\tpara i de 1 a n hacer\n\t\t\tx← 1\n\t\t\tmientras x<n hacer\n\t\t\t\tx← x*2\n\t\t\tfinmientras\n\t\tfinpara\n\t\tretorna F(n/2)+F(n/2)\n\tfinsi\nfin```
1
2*T(n/2)+n*log n
2*T(n-1)+1
2*T(n/2)+1
2*T(n-1)+n
2*T(n/2)+1

Cual seria la función de coste del algoritmo siguiente considera que la medida significativa es la operación * y que el modulo potencia es el calculo de la potencia implementado mediante productos sucesivos Tpotencia(n)=n: ```{Q} ={n=N, N> 1) \nint ejerc6 ( int n ) {\n\tint i = 1;\n\tint x = 1;\n\twhile (i<=n) {\n\t\tx = x*potencia(i, i);\n\t\ti=i+1;\n\t}\n\treturn x;\n}```
4
T(n) = 3 + c*n siendo c una constante
T(n)  E^logn (i+1)
T(n) = 3 + E3
T(n) = E(i+1)

Sea un vector de n elementos y supongamos que todos los elementos de a son distintos, considera el siguiente algoritmoSi consideramos como medida significativa el numero de comparaciones con respecto de los elementos del vector, entonces el algoritmo tiene una complejidad: ```función Ordena (ent/sal a:vector): nada\n\tvariables: i,j,temp: entero\n\tinicio\n\t\tpara i de 0 a n-2 hacer\n\t\t\tpara j de n-1 a i+1 incr-1 hacer\n\t\t\t\tsi a[j-1]>a[j] entonces\n\t\t\t\t\ttemp← a[j]\n\t\t\t\t\ta[j]← a[j-1]\n\t\t\t\t\ta[j-1]← temp\n\t\t\t\tfinsi\n\t\t\tfinpara\n\t\tfinpara\n\tfin```
2
Ω(n) y O(n^2)
Θ(n^2)
Ω(1) y O(n^2)
Θ(n)

Si consideramos como medida significativa el numero de comparaciones con respecto a las variables Min y Max siendo n el numero total de elementos a trata. Entonces el caso mejor se obtiene
2
Cuando los datos vienen ordenados ascendentemente que hay n comparaciones
Cuando los datos dispuestos en orden inverso que hay n comparaciones
Cuando los datos vienen dispuesto en orden inverso que hay 2n comparaciones
Cuando los datos vienen ordenado ascendentemente que hay 2n comparaciones

Dadas las siguiente ecuaciones de recurrencia determinar el orden al que pertenecen cada una de ellas T1(n)=2T1(n/2)+c1, T2(n)=T2(n-1) + n + c2, T3(n) = cT3(n-1)+c3, T4(n) = T4(n-1)+c4
1
T1(n) E O(n), T2(n) E O(n^2), T3(n) E O(c^n) y T4(n) E O(n) 
T1(n) E O(n), T2(n) E O(n), T3(n) E O(n^2) y T4(n) E O(n^2) 
T1(n) E O(log n), T2(n) E O(2^n), T3(n) E O(c^n) y T4(n) E O(n) 
T1(n) E O(log n), T2(n) E O(n^2), T3(n) E O(n) y T4(n) E O(n) 

Considera la función siguiente, donde todos los elementos del vector L son distintos.Considera como medida significativa las asignaciones a max, entonces el numero de asignaciones para el caso mejor y pero son, respectivamente: ```int maximo( int L[N] ) {\n\tint i, max;\n\tmax=L[0];\n\tfor (i=1; i<N; i++)\n\t\tif (max<L[i])\n\t\t\tmax=L[i];\n\treturn (max);\n}```
1
1 cuando el mayor elemento esta en la posición inicial y n cuando los elementos están ordenados ascendentemente
1 cuando los elementos están ordenados ascendentemente y n cuando los elementos están en orden inverso
depende siempre del valor de N, estén como estén dispuestos los datos, si N=1 se obtiene el mejor caso, y el pero con el mayor numero de N
siempre tiene un coste lineal, independiente del orden inicial, pues todos los elementos son distintos por hipótesis y se realiza un numero fijo de iteraciones

Cual seria el montículo de mínimos implementado en un vector resultantes después de haber insertado los siguientes elementos en el orden indicado 5,3,8,2,1
3
0 1 2 3 4 5 5 3 8 2 1 ...
0 1 2 3 4 5 1 3 8 5 2 ...
0 1 2 3 4 5 1 2 8 5 3 ...
0 1 2 3 4 5 1 2 3 5 8 ...

Si estamos trabajando con un lenguaje de programacion no recursivo
4
Ninguna de las anteriores es correcta
Podáramos simular la recursividad mediante colas
No podríamos implementar ningún algoritmo recursivo
Podríamos simular la recursividad mediante pilas
No existen lenguajes de programación no recursivos

Sea G un grafo no dirigido valuado con etiquetas positivas y conexo entonces los algoritmos Prim y kruskal aplicados sobre el grafo G
2
Darían el mismo resultado independientemente de como fueran las etiquetas del grafo G
Darían el mismo resultado si todas las etiquetas del grafo G fueran distintas
Siempre obtendrían resultados distintos
Darían el mismo resultado solo si hubiera etiquetas con el mismo valor en el grafo G

Cual seria la función de coste del algoritmo anterior en el caso medio
1
T(N) = 3 + E^logN i=1 2
T(N) = 3 + c*N siendo c una constante
T(N) = 2 + E^N i=1 3
T(N) = 3+ E^N j=1 2

La complejidad del algoritmo es: ```función recursiva(n: entero): entero;\nvar i:entero;\n{\n\tif(n<=1)then\n\t\trecursiva:=1\n\telse\n\t\tfor(i=1;i<=n;i++)\n\t\t\twriteln(i);\n\t\trecursiva:=recursiva(n/2)+recursiva(n/2)\n}```
3
O(2^n)
O(log^2(n))
O(n*log(n))
O(log(n))

Sea A un array ordenado de n enteros que se vuelca en un árbol binario ordenado, y sea x un entero a buscar dentro del árbol binario. Entonces, la complejidad de ese algoritmo de búsqueda es:
2
Depende del algoritmo de volcado. Sera lineal si A se vuelca de forma lineal, y logarítmica si se sigue un algoritmo puro de back tracking para localizar el elemento x dentro del árbol.
Depende del algoritmo de volcado del array. Sera lineal A si se vuelca de forma lineal, y logarítmica si se sigue una estrategia divide y vencerás, tomando como pivote A[N/2].
Es independiente del algoritmo de volcado del array. Siempre es logarítmica, pues en una búsqueda de ABO siempre tenemos una ecuación de recurrencia de la forma T(n)=(n/2)+1;T(1)=O(1), que al resolverla nos proporciona una complejidad logarítmica.
Depende del algoritmo de volcado. Si empieza desde el final será logarítmica y si empieza desde el principio será lineal.

Dado el siguiente código, calcule la complejidad del mismo: ```int sumaDigitos ( int num ) {\n\tint s;\n\ts = num % 10;\n\twhile ( num >= 10 ) {\n\t\tnum = num/10\n\t\ts = s + (num % 10);\n\t}\n\treturn (s);\n}```
2
Ω(1) y O(log n)
O(n)
O(10n)
O(1)
O(log n)

Se entiende como solución optima al problema del viajante de comercio la que representa el ciclo de Hamilton de menor coste que se puede conseguir un grafo valuado que esquema nos garantiza la resolución optima de ese problema
4
II y III
I Aplicando un algoritmo de divide y vencerás basado en las componentes conexas del grafo
III aplicando un algoritmo voraz con una función de selección basada en la arista mas corta
II aplicando un esquema vuelta atrás back tracking

Una función recursiva es
5
III una función que llama a otra y esta llama a la primera
I una función que se llama a si misma
Todas son correctas
II una función que llama a otro numero indeterminado de veces
IV I y III son correctas

Un árbol binario ordenado se caracteriza porque
2
Se construye desde la raíz hasta las hojas y no existe una relacion de orden entre los datos
Se construye desde las hojas a la raíz y existe una relacion jerárquica entre los datos
Se construye desde las hojas a la raíz y existe una relacion de orden entre los datos
Se construye desde la raíz hasta las hojas y existe una relacion exclusivamente jerárquica entre los datos
Se construye desde la raíz hasta las hojas y no existe ninguna relacion entre los datos

Que calcula el siguiente algoritmo: ```función Ejercicio (ent A: ÁrbolBinario, ent/sal actual:entero):nada\nvariables\t\tx: entero\n\t\tIzq, Der: ÁrbolBinario\ninicio\n\tsi A.Vacio entonces\n\t\tA.HijoIzq(Izq)\n\t\tA.HijoDer(Der)\n\t\tA.Raíz(x)\n\t\tactual:=actual + x\n\t\tEjercicio (Izq, actual)\n\t\tEjercicio (Der, actual)\n\tfinsi\nfin\nLlamada desde el programa principal:\nn:= 0\t\t\t\t#Arb es un árbol\nEjercicio(Arb, n)```
2
n devuelve la suma de los valores de los nodos que no son hojas en el arbol
n devuelve la suma de valores de los nodos del arbol
n devuelve el valor de la raiz del arbol
n devuelve la suma de los valores de las hojas del arbol

La complejidad de un algoritmo recursivo con dos llamadas recursivas crece de manera exponencial
4
Ninguna de las anteriores es correcta
Si el algoritmo es recursivo y tenemos el numero de datos es de 2^k, siendo k el numero de llamadas recursivas
Si en cada llamada recursiva vuelven a entrar los n datos
Si se va decrementando los datos de forma lineal

Mediante el algoritmo de floyd podemos
2
e. Las respuestas a y c son correctas
d. Las respuestas a b y c son correctas
c. Calcular el coste mínimo de ir desde cualquier vértice i a cualquier otro
b. Calcular el coste mínimo de ir desde un vértice i a todos los demás
a. Calcular el coste mínimo de ir desde un vértice i a un vértice j

Calcular la complejidad del siguiente fragmento de codigo: ```for(i=1; i<=n; i++)\n\tfor(j=1; j<= 10000; j++)\n\t\tfor(k=n-1; k<=n; k++)\n\t\t\tcout<<i<<j<<k<<endl;```
4
O(n^2)
O(n^3)
O(2^n)
O(n)
O(n*log n

Mediante el algoritmo de Floyd podemos
1
IV Las respuestas l, ll y lll son correctas
II calcular el coste mínimo de ir desde un vértice i a todos los demás
V Las respuesta I y II son correctas
ll calcular el coste mínimo de ir desde cualquier vértice i a cualquier otro
I calcular el coste mínimo de ir desde un vértice i a un vértice j

Un árbol binario ordenado se caracteriza porque
2
Se construye desde la raíz hasta las hojas y no existe ninguna relacion entre los datos
Se construye desde la raíz hasta las hojas y existe una relacion de orden entre los datos
Se construye desde la raíz hasta las hojas y existe una relacion exclusivamente jerárquica entre los datos
Se construye desde las hojas a la raíz y existe una relacion jerárquica entre los datos
Se construye desde las hojas a la raíz y existe una relacion de orden entre los datos

De los algoritmos vistos en clase, cual se corresponde con el siguiente: ```for(i=1; i<=n; i++) {\n\tX=V[i];\n\tIzq=0;\n\tDer=i-1;\n\twhile (Izq <= Der) {\n\t\tMedio = (Izq+Der)/2;\n\t\tif (X<V[Medio])\n\t\t\tDer=Medio-1;\n\t\telse\n\t\t\tIzq = Medio +1;\n\t}\n\tfor(j=i-1; j>=Izq; j--) {\n\t\tV[j+1] = V[j];\n\t}\n\tV[Izq]=X;\n}```
3
Ordenación mediante el algoritmo de Quicksort
Ordenación mediante el algoritmo de selección directa
Ordenación mediante el algoritmo de inserción binaria
Ordenación mediante el algoritmo de la burbuja

¿Con que algoritmo de ordenación clásico se corresponde el pseudocodigo del siguiente ejemplo?: ```módulo ordena ( var A es vector de n enteros);\nvariables i, j, x: es entero\nfor (i = 2; i<=N; i++) {\n\tX=A[i];\n\tA[0]=X;\n\tj=i-1;\n\twhile ( X<A[j] ) { # (2)\n\t\tA[j+1]=A[j]; # (3) \n\t\tj = j – 1\n\t}\n\tA[j+1]=X;\n}\nfinmódulo```
3
Ordenación por el método de la burbuja
Ordenación por el método de selección directa
Ordenación por el método de inserción directa
Ordenación por el método de inserción binaria

Supongamos que queremos hacer una copia de seguridad de nuestro ficheros mas importantes y para ello solo disponemos de un DVD+R grabable de 4.7Gb según esto tenemos n ficheros con distintos tamaños respectivamente y además nuestro DVD tiene capacidad máxima T se cumple que T< t1+t2+t3+...+tn
1
Para maximizar el numero de ficheros en DVD utilizaría un esquema de voraz
Para maximizar el numero de ficheros en DVD utilizaría un esquema de divide y vencerás
Para maximizar el numero de ficheros en DVD utilizaría un esquema backtracking
Para maximizar el numero de ficheros en DVD utilizaría un esquema de ramificación y poda

Sea A un árbol binario ordenado equilibrado de n elementos, en el que todos sus elementos son distintos, entonces la función búsqueda de un elemento que no esta en el árbol tendrá coste
4
O(log n)
Ω(log n) y O(n)
Θ(n)
Θ(log n)

Que ventaja tiene un esquema de ramificación y poda frente a un vuelta atrás
4
Que no tiene un coste exponencial
Que se exploran todos los nodos del árbol de búsqueda de soluciones
Que simplifica el código
Que tiene un coste menor

Un conjunto es
1
Ninguna de las anteriores
Una estructura no lineal en la que deberemos tener en cuenta el orden de llegada de los dats
Una estructura lineal en la que puede haber repetidos
Una estructura lineal y ordenada en la que no puede haber repetidos
Una estructura no lineal en la que no puede haber elementos repetido y los elementos están ordenados

La búsqueda de un elemento dentro de un árbol tiene un coste de
5
Siempre constante, O(1)
Si es ABO es logarítmica siempre
Si es un AVL es logarítmica siempre
Siempre lineal, O(n)
Ninguna de las anteriores

El recorrido en profundidad de un grafo G no dirigido ha producido el arbol que se muestra en la figura, en el que cada nodo esta numerado siguiendo el orden de visita del recorrido en profundidad: ```\n    1\n   / \\n  2   6\n / \   \\n3   4   7\n   /\n  5```
1
El nodo 2 puede ser adyacente al nodo 5, y el nodo 4 puede ser adyacente al nodo 1
El nodo 6 y 7 no son adyacentes y el nodo 5 y el nodo 7 si lo son
El nodo 1 solo puede ser adyacente a los nodos 2,6 y 7
El nodo 6 es adyacente al nodo 4

Sabemos que un árbol se construye
1
Se construye de la raíz a las hojas si es un AVL, y de las hojas a la raíz si es un binario
Ninguna de las anteriores
Si el árbol es binario de la raíz a las hojas igual que si es un árbol en general
Se construye empezando por la raíz luego por la izquierda y después por la derecha hasta llegar a las hojas si es binario ordenado y de las hojas a la raíz si es binario

Si queremos implementar una cola dinámica utilizando un único puntero entonces alguna de las siguientes alternativas consigue complejidad de todas las operaciones de TAD Cola sean constantes
4
si, cuando el puntero indique el final de la cola
no, siempre habrá alguna opción con complejidad lineal
si, utilizando una lista circular donde el puntero indica el frente de la cola y el sucesor de este fuese el elemento del final
si, utilizando una lista circular donde el puntero indica el final de la cola y el sucesor de este fuese el elemento del frente

Supongamos que queremos hacer una copia de seguridad de nuestro ficheros mas importantes y para ello solo disponemos de un DVD+R grabable de 4.7Gb según esto tenemos n ficheros con distintos tamaños respectivamente y además nuestro DVD tiene capacidad máxima T se cumple que T< t1+t2+t3+...+tnCon respecto al problema anterior cual de las afirmaciones es cierta
2
para optimizar la utilización del espacio del DVD utilizaría un esquema de ramificación y poda
para optimizar la utilización del espacio del DVD utilizaría un esquema de backtracking
para optimizar la utilización del espacio del DVD utilizaría un esquema de divide y vencerás
para optimizar la utilización del espacio del DVD utilizaría un esquema de voraz

Dadas 2 soluciones recursivas A y B, para un problema de manera que las ecuaciones de recurrencia para el caso general (n > 1) son Ta(n)=Ta(n-1)+n y Tb(n-1)+1. (Los casos base de ambos problemas se resuelven con tiempo constante cuando n < =1). Desde el punto de vista asintotico ¿ cual de las dos soluciones es mejor?
2
La solución B
La solución A
Faltan datos para poder decirlo
Ambas por igual

Suponiendo la implementación mas eficiente para cada TAD establecer el coste de borrado de los elementos menor en una lista desordenada un árbol binario ordenado y un montículo de mínimos respectivamente
1
O(1),O(n),O(log n),O(1)
O(log n),O(n),O(n),O(1)
O(n),O(1),O(log n),O(log n)
O(1),O(n),O(n),O(log n)

Un grafo no dirigido tiene 200 arcos podemos entonces deducir que
4
Ninguna de las anteriores
posee menos de 20 vertices
posee mas de 20 vertices y siempre es conexo
posee mas de 20 vertices

Dado el algoritmo anterior y considerando como medida significativa el numero de comparaciones con respecto a la variable Min y Max. Entonces el numero de comparaciones medias viene determinado por la siguiente funcion
2
Tmed(n) = (log n)/2
Tmed(n) = (3/2)n
Tmed(n) = E^n (1/i -2(1+1i))
Tmed(n) = E^n (1/i+2(1-1/i))

Que algoritmo es menos costoso para obtener el camino mínimo entre todos los pares de vértices de un grafo
3
Floyd tiene menor cota superior de coste que Dijkstra en este caso
Dijkstra es mas eficiente, puesto que tiene menor coste
Aplicar sucesivamente Dijkstra en este caso tiene igual cota superior de coste que aplicar Floyd
Calcular la matriz de cierre transitivo
Kruskal es el mas adecuado para lograr este objetivo

Sea un grafo no dirigido con n vertices entonces
2
Si se hace un recorrido en anchura partiendo del nodo x el conjunto de vértices visitados es igual al conjunto total de vértices del grafo
Si se hace un recorrido en anchura que parte del nodo x el conjunto de visitados al final será igual que resultaría si el recorrido fuera en profundidad
Si se hace un recorrido en anchura partiendo del nodo x no puede asegurarse que el conjunto de visitados al final resulte ser el mismo que si el recorrido fueran en profundidad
Si se hace un recorrido en anchura que parte del nodo x y el grafo es cíclico se entra en un bucle infinito
Si se hace un recorrido en anchura partiendo del nodo x y el conjunto de visitados resultante n es igual al conjunto total de vértices es porque el grafo no es fuertemente conexo

Sea un grafo G no dirigido etiquetado con etiquetas positivas y conexo entonces es cierto que el algoritmo de Kruskal
1
Solo puede producir una única solución si todas las etiquetas tienen valores distintos
Kruskal puede producir una única solución si todas las etiquetas tienen valores distintos
Puede producir distintas soluciones si todas las etiquetas tienen valores distintos
Solo puede producir una única solución independientemente de los valores de las etiquetas
El numero de soluciones que puede generar Kruskal es imprevisible en cualquier caso

Cual de las siguientes características es fundamental en los algoritmos ávidos
3
Se generan todas las secuencias de decisiones de forma sistemática y organizada
Nos garantizan la obtención de la solución optima del problema
Nunca se vuelve a reconsiderar una decisión ya tomada
Se combinan las soluciones parciales para obtener la solución parcial

A partir de cual de los siguientes recorridos se puede reconstruir un árbol binario completo
3
InOrden
PostOrden
Las tres respuestas son correctas
PreOrden

Sea A un árbol binario de profundidad k con n nodos donde n = 2^k-1 este datos nos permite saber entre otras cosas que
3
III existen en el árbol todos lo nodos de nivel k
I el árbol es complejo
IV I, II y III conjuntamente
II el árbol es equilibrado

Utilizaremos una estructura de cola en aquellas aplicaciones que requieran un tratamiento en el que los datos
4
debamos procesarlos en orden inverso a como se obtienen y puedan repetirse
debamos procesarlos en el mismo orden en el que se obtienen y no puedan repetirse
se insertan y se extraigan por un único punto, y deban estar ordenados
debamos procesarlos en el mismo orden en el que se obtienen y puedan repetirse

Suponiendo la implementación mas eficiente para cada TAD establecer el coste en el borrado del elemento menor en una lista ordenada una lista desordenada y un montículo de mínimos respectivamente
3
O(1),O(n),O(1)
O(log n),O(n),O(1)
O(1),O(n),O(log n)
O(n),O(1),O(log n)

Suponiendo que T1 E O(f) y que T2 E O(f) indicar cual de las siguientes afirmaciones es cierta
1
I y II son ciertas
II T1 - T2 E O(f)
III Ninguna de las anteriores
I T1+T2 E O(f)

Sea un grafo dirigido con n vértices entonces
1
El grafo puede tener como máximo n^2-n arcos
El grafo debe tener con mínimo 1 arco ya que de lo contrario no se puede saber si es dirigido o no
Si tiene mas de n-1 arcos necesariamente tiene un ciclo
si tiene menos de n-1 arcos es imposible que tenga un ciclo
El grafo puede tener máximo n^2

Comparando los algoritmos de multiplicacion de matrices y warshall para un grafo no valuado G tenemos que 
4
Tienen complejidad diferente la multiplicación de matrices tiene O(n^4) y warshall O(n^3) la multiplicación de matrices se basa en aplicaciones de espacio de búsqueda y warshall se basa en ir obteniendo caminos de longitud mayor
Ambos tienen la misma complejidad, multiplicación de matrices se basa en ir obteniendo caminos de longitud mayor aplicaciones de espacio de búsqueda y warshall se basa en aplicaciones de espacio de búsqueda
Ambos tienen la misma complejidad, multiplicación de matrices se basa en aplicaciones de espacio de búsqueda y warshall se basa en ir obteniendo caminos de longitud mayor
Tienen complejidad diferente la multiplicación de matrices tiene O(n^4) y warshall O(n^3) la multiplicación de matrices se basa en ir obteniendo caminos de longitud mayor y warshall se basa en aplicaciones de espacio de búsqueda

Sea A un vector de n elementos y supongamos que todos los elementos de A son distintos. Considera el siguiente algoritmo:Nos interesa medir cuantas veces se ejecuta la instrucción nº 3 Entonces el caso mejor se obtiene cuando: ```módulo ordena ( var A es vector de n enteros);\nvariables i, j, x: es entero\nfor (i = 2; i<=N; i++) {\n\tX=A[i];\n\tA[0]=X;\n\tj=i-1;\n\twhile ( X<A[j] ) { # (2)\n\t\tA[j+1]=A[j]; # (3)\n\t\tj = j - 1\n\t}\n\tA[j+1]=X;\n}\nfinmódulo```
1
Los datos vienen ordenados ascendentemente, que se ejecuta exactamente 0 veces
Los datos vienen ordenados ascendentemente, que se ejecuta exactamente n^2 veces
Los datos vienen dispuestos en orden inverso, que se ejecuta exactamente n^2 veces
Los datos vienen dispuestos en orden inverso, que se ejecuta exactamente n-i veces

Dado el algoritmo el caso peor el numero de nodos procesados: ```Módulo Ejercicio (ent A es ArbolBinario) devuelve entero\nvariables\n\tIzq, Der es ArbolBinario\ninicio\n\tsi no A.Vacio entonces\n\t\tA.HijoIzq (Izq);\n\t\tA.HijoDer (Der);\n\t\tdevolver (ejercicio(izq) + ejercicio(der) + 1)\n\tsi no\n\t\tdevolver (0)\n\tfinsi\nfin```
3
es proporcional al logaritmo siempre
es proporcional a n*logn
sigue una función lineal siempre
depende del grado de equilibrio que tenga
ninguna respuesta es correcta

Sea A un árbol binario ordenado equilibrad de n elementos en el que todos sus elementos son distintos, entonces la operación de búsqueda de un elemento que no esta en el árbol tendrá un coste
2
Θ(n)
O(log n)
Ω(log n) y O(n)
Θ(log n)

Supongamos que obtenemos de teclado una secuencia ordenada de datos la cual vamos almacenando en una determinada estructura de datos entonces conociendo de antemano que sobre esta estructura vas a realizar muchas operaciones de búsqueda que estructura de almacenamiento erigirías
2
Una lista enlazada dinámicamente
Un vector
Una cola enlazada dinamicamente
Un árbol binario ordenado o árbol de búsqueda
Un grafo

Que estructura de datos es mas eficiente para almacenar los nodos vivos al implementar un algoritmo de ramificación y poda
4
Una lista
Un árbol binario ordenado
Un árbol balanceado
Una cola de prioridad

Cual es el objetivo de los rebalanceos en un árbol AVL
2
Que la búsqueda de los elementos en el árbol se mantenga constante
Que la diferencia máxima entre sus dos subárboles sea 1
Que todos los subarboles tengan la misma altura
Que si un nodo del ultimo nivel esta vacío los siguientes en ese nivel también lo estén

Sea G=(V,E) un grafo no dirigido donde Card(E) = Card()-1 cual de las siguientes afirmaciones es cierta
4
G es conexo, pero si se suprime una arista cualquiera deja de serl
G es un arbol
Dos vértices cualesquiera de G están conectados por un único camino simple
Si G es conexo entonces G es acíclico

Un grafo es una estructura formada por el par (V, E) donde
3
V es el conjunto de vértices y E es una matriz
V es el conjunto de vértices del grafo y E un conjunto de arcos
Todas las anteriores son correctas
V es el conjunto de vértices y E un conjunto de arcos
V es un vector y E es una lista de vértices adyacentes

Que algoritmo es menos costoso para obtener el camino minimo entre todos los pares de vertices de un grafo
1
Aplicar sucesivamente Dijkstra en este caso tiene igual cota superior de coste que aplicar Floyd
Calcularía la matriz de cierre transitivo
Dijkstra es mas eficiente puesto que tiene menor coste
Kruskal es mas adecuado para lograr este objetivo
Floyd tiene menor cota superior de coste que Dijkstra en este caso

El recorrido en profundidad de un grafo G no dirigido ha producido el arbol que se muestra en la figura, en el que cada nodo esta numerado siguiendo el orden de visita del recorrido en profundidad:```\n     1\n   / | \\n  2  5  7\n /|  |\n3 4  6```
1
Los nodos 1 y 2 pueden ser adyacentes al nodo 4
El nodo 2 es adyacente al nodo 3 y el nodo 3 puede ser adyacente al nodo 4
El nodo 1 puede ser adyacente al nodo 4 y al nodo 5 puede ser adyacente al nodo 7
Los nodos 1 y 3 pueden ser adyacentes al nodo 6

Podemos detectar todos los vertices involucrados en ciclos dentro de un grafo dirigido inspeccionando el resultad de
2
algoritmo Prim
algoritmo Warshall
algoritmo Floyd
algoritmo Dijkstra

El algoritmo que se describe a continuación calcula: ```Módulo Ejercicio (ent A es ArbolBinario) devuelve entero\nvariables\n\tIzq, Der es ArbolBinario\ninicio\n\tsi no A.Vacio entonces\n\t\tA.HijoIzq (Izq);\n\t\tA.HijoDer (Der);\n\t\tdevolver (ejercicio(izq) + ejercicio(der) + 1)\n\tsi no\n\t\tdevolver (0)\n\tfinsi\nfin```
3
Cuantos niveles distintos tiene el árbol A
El numero de veces que aparece el hijo izquierdo y el hijo derecho en el árbol A
Ninguna de las anteriores
El grado del árbol A
El nivel en el que se encuentra el (hijo izquierdo + hijo derecho + 1) del árbol A

¿Cuál de estas afirmaciones sobre el algoritmo para calcular x^n es falsa? ```Función potencia ( ent x: entero, ent n: entero): entero\nInicio\n\tsi n==1 entonces\n\t\tretorna (x);\n\tsi no\n\t\tretorna (x*potencia(x,n-1));\n\tfinsi\nfin```
4
Se utiliza un esquema de divide y venceras para su solucion
Su precondición es {Q} = {x entero, n natural, n>=1}
Su ecuación de recurrencia es T(n) = T(n-1)+1
Su coste temporal es O(x^n)

Los algoritmos de Warshall, Prim y floyd son ejemplos de los siguientes esquemas algoritmicos
4
Warshall programación dinámica, Prim algoritmo voraz , Floyd algoritmo voraz
Warshall programación dinámica, Prim programación dinámica, Floyd algoritmo voraz
Warshall Algoritmo voraz, Prim programación dinámica, Floyd algoritmo voraz
Warshall: programación dinámica, Prim algoritmo voraz, Floyd programación dinámica

Suponiendo la implementación mas eficiente para cada TAD, establecer el coste en el borrado del elemento menor en una lista ordenada, una lista desordenada un árbol binario ordenado y un montículo de mínimos respectivamente.
1
O(1),O(n),O(n),O(log n)
O(1),O(n),O(log n),O(1)
O(log n),O(n),O(n),O(1)
O(n),O(1),O(log n),O(log n)

Sea un árbol binario de profundidad k con nodos, donde n - 2^k este dato nos permite saber entre otras cosas
3
Existen en árbol todos los nodos de nivel k
El árbol es equilibrado
Las 3 respuestas conjuntamente
El árbol es completo

Utilizaremos una estructura de cola en aquellas aplicaciones que requieran un tratamiento en los que los datos
2
debamos procesarlos en el mismo orden en el que se obtienen y no puedan repetirse
debamos procesarlos en el mismo orden en el que se obtiene y puedan repetirse
debamos procesarlos en orden inverso a como se obtienen y no puedan repetirse
se inserten y extraigan por un único punto y deben ser ordenados
debamos procesarlos en orden inverso a como se obtienen y puedan repetirse

Sea v un vector de N elementos y supongamos que todos los elementos de v son distintos Considera el algoritmo siguiente Si tomamos como medida significativa el numero de comparaciones con elementos del vector(instrucción 2) entonces el algoritmo tiene un coste: ```for (i=1; i<N; i++) {\n\tX=V[i]; # (1)\n\tIzq=0;\n\tDer=i-1;\n\twhile (Izq <= Der) {\n\t\tMedio = (Izq+Der)/2;\n\t\tif (X<V[Medio]) # (2)\n\t\t\tDer=Medio-1;\n\t\telse\n\t\t\tIzq = Medio +1;\n\t}\n\tfor(j=i-1; j>=Izq; j--) {\n\t\tV[j+1] = V[j]; # (3)\n\t}\n\tV[Izq]=X;\n}```
1
Θ(n*log(n))
O(log(n))
Θ(n)
Ω(log(n)) y O(n)

La complejidad del siguiente bucle es: ```for (i=1; i<=N; i++) {\n\tif (T[i] == x)\n\t\tAux=i;\n}```
2
IV I y II son correctas
V ninguna de las anteriores
I Constante desde el punto de vista del numero de comparaciones
III Varia en función de la ordenación del vector
II Constante desde el punto de vista del numero de asignaciones

Cuando tenemos un algoritmo backtracking
4
Cuando en un problema tenemos una cantidad de datos demasiad grande asi podemos hacer llamadas recursivas con una cantidad de datos mas pequeña
Ninguna de las anteriores son correctas
Las dos anteriores son correctas
Cuando debamos probar todas las combinaciones posibles para encontrar la solucion de un problema

Resolviendo la ecuación de recurrencia del ejercicio siguiente se obtiene que su función de coste es: ```Función F (ent n: entero): entero\nvariables x, i: entero\nInicio\n\tsi (n>=1) entonces\n\t\tretorna 1\n\tsi no\n\t\tpara i de 1 a n hacer\n\t\t\tx← 1\n\t\t\tmientras x<n hacer\n\t\t\t\tx← x*2\n\t\t\tfinmientras\n\t\tfinpara\n\t\tretorna F(n/2)+F(n/2)\n\tfinsi\nfin```
1
O(n*log^2 n)
O(log n)
O(2^n)
O(n^2)
O(n)

Sea G un grado no dirigido de n vértices sabemos que G con n vértices en un árbol libre si es acíclico y conexo entonces
1
G tiene exactamente n-1 arcos
G tiene al menos n arcos
G tiene al menos n-1 arcos
Ninguna de las anteriores

Considera la función siguiente que es un algoritmo típico de búsquedaSupongamos que x esta en el vector y que todos los elementos son distintos. En este caso, el numero medio de comparaciones con la variable x es: ```Función pertenece (ent L: vector de enteros, ent x:entero):entero\nvariables: i, aux: entero\nInicio\n\taux← 0\n\tpara i de 0 a n-1 hacer\n\t\tsi L[i]==x entonces\n\t\t\taux← i\n\t\tfinsi\n\tfinpara\nretorna aux\nFin```
1
n
(n+1)/2
n/2
1

El recorrido en profundidad de un grafo G no dirigido ha producido el árbol que se muestra en el que cada nodo esta numerad siguiendo el orden de visita del recorrido en profundidad```\n     1\n    /|\\n   2 6 7\n  /   \n 3   \n/ \\n4 5```
4
El nodo 6 es adyacente al nodo 4
Se trata de un grafo fuertemente conexo
El nodo 1 solo puede ser adyacente a los nodos 2,6 y 7
El nodo 2 puede ser adyacente al nodo 5 y el nodo 4 puede ser adyacente al nodo 1
El nodo 6 y 7 no son adyacente y el nodo 5 y el nodo 7 si lo son

Los algoritmos warshall, floyd y kruskal son ejempls de los siguientes algoritmos
3
Warshall programación dinámica, floyd programación dinámica, kruskal programación dinámica
Warshall programación dinámica, floyd algoritmo voraz, kruskal backtracking
Warshall programación dinámica, floyd programación dinámica, kruskal algoritmo voraz
Warshall algoritmo voraz, floyd programación dinámica, kruskal algoritmo voraz

Dadas las siguientes ecuaciones de recurrencia. Determinar el orden al que pertenece cada una de ellasT1(n)=2T1(n-1)+c1; T2(n)=T2(n-1)+c2, T3(n)=T3(n/2)+c3 y T4(n)=T4(n+1)+n+c4
1
T1(n) E O(2^n), T2(n) E O(n), T3(n) E O(log n), T4(n) E O(n^2)
T1(n) E O(n), T2(n) E O(n), T3(n) E O(log n), T4(n) E O(n^2)
T1(n) E O(log n), T2(n) E O(n), T3(n) E O(log n), T4(n) E O(n^2)
T1(n) E O(2^n), T2(n) E O(n), T3(n) E O(log n), T4(n) E O(2n)

¿Cuál es el objetivo de la etapa de análisis en el Diseño y Análisis de un Algoritmo?: 
2
Determinar el lenguaje y herramientas disponibles para su desarrollo. 
Estimar los recursos que consumirá el algoritmo una vez implementado.
Estimar la potencia y características del equipo informático necesarios para el correcto funcionamiento del algoritmo. 

¿Cuál de las siguientes jerarquías de complejidades es la correcta? 
3
O(1)⊂O(lg n)⊂O(lg lg n) ⊂ ... 
... ⊂ (n!)⊂O(2^n) ⊂O(n^n) 
... ⊂ (2^n)⊂O(n!) ⊂O(n^n) 

¿Cuál de los siguientes algoritmos de ordenación tiene menor complejidad? 
3
Burbuja 
Inserción directa
Mergesort

¿El tiempo de ejecución de un algoritmo depende de la talla del problema? 
3
Sí, siempre 
No, nunca 
No necesariamente

Ordena de menor a mayor las siguientes complejidades \n\t1. O(1) \n\t2. O(n^2) \n\t3. O(nlgn) \n\t4. O(n!) 
2
3, 1, 2 y 4
1, 3, 2 y 4
1, 3, 4 y 2

El estudio de la complejidad resulta realmente interesante para tamaños grandes de problema por varios motivos: 
3
Las diferencias reales en tiempo de compilación de algoritmos con diferente coste para tamaños pequeños del problema no suelen ser muy significativas. 
Las diferencias reales en tiempo de ejecución de algoritmos con diferente coste para tamaños grandes del problema no suelen ser muy significativas. 
Ninguna de las anteriores. 

¿Por que se emplean funciones de coste para expresar el coste de una algoritmo? 
2
Para poder expresar el coste de los algoritmos con mayor exactitud 
Para que la expresión del coste del algoritmo sea válida para cualquier entrada al mismo
Para poder expresar el coste de un algoritmo mediante una expresión matemática

El caso base de una ecuación de recurrencia asociada a la complejidad temporal de un algoritmo expresa:
3
El coste de dicho algoritmo en el mejor de los casos. 
El coste de dicho algoritmo en el peor de los casos.
Ninguna de las anteriores.

La complejidad de la función TB es: ```función TB (A: vector[λ]; iz , de : N) : N \nvar n,i:N; \n\tn=iz-de+1 \n\topcion \n\t\t(n < 1) : devuelve ( 0 ) ; \n\t\t(n = 1) : devuelve ( 1 ) ; \n\t\t(n > 1) : si (A[iz] = A[de]) entonces \n\t\t\t\tdevuelve (TB( A, iz + 1, de - 1 ) + 1); \n\t\t\tsino \n\t\t\t\tdevuelve (TB( A, iz + 1, de - 1 )) ; \n\t\t\tfinsi ; \n\tfopcion \nfin ```
1
Θ (n)
Θ (n · lg n) 
Θ (n^2 · lg n)

Dado el polinomio $$f(n)= a_mn^m + a_{m-1}n^{m-1} + … + a_0,$$ con $$a_m \in{R^+}$$ entonces f pertenece al orden:
3
$$O(n^m)$$. 
$$Ω(n^m)$$.
Las dos respuestas anteriores son correctas.

Si $$f1(n) \in{ Ο(g1(n))}$$ y $$f2(n) \in{ Ο(g2(n))}$$ entonces:
2
$$f1(n)·f2(n) \in{ Ο(maximo(g1(n),g2(n)))}$$
$$f1(n)·f2(n) \in{ Ο (g1(n)· g2(n))}$$
Ambas son correctas 

Si $$f1(n) \in{ Ο(g1(n))}$$ y $$f2(n) \in{ Ο(g2(n))}$$ entonces:
3
$$f1(n)+f2(n) \in{ Ο(maximo(g1(n),g2(n)))}$$ 
$$f1(n)+f2(n) \in{ Ο (g1(n)+g2(n))}$$
Ambas son correctas 

Un algoritmo cuya talla es n y que tarda $$40^n$$ segundos en resolver cualquier instancia tiene una complejidad temporal:
2
$$\Theta{( n^n )}$$
$$\Theta{( 4^n )}$$
Ninguna de las anteriores

Si dos algoritmos tienen la misma complejidad asintótica:
1
No necesitan exactamente el mismo tiempo para su ejecución. 
Necesitan exactamente el mismo tiempo para su ejecución.
Ninguna de las anteriores 

Los algoritmos directos de ordenación, respecto de los indirectos:
1
Presentan una mayor complejidad temporal y sus tiempos de ejecución absolutos son mayores. 
Presentan una menor complejidad temporal y sus tiempos de ejecución absolutos son menores.
Presentan una mayor complejidad temporal si bien sus tiempos de ejecución absolutos son menores. 

La talla o tamaño de un problema depende de: 
3
Conjunto de valores asociados a la entrada y salida del problema.
Conjunto de valores asociados a la salida del problema.
Conjunto de valores asociados a la entrada del problema.

En un algoritmo recursivo, la forma de dividir el problema en subproblemas:
2
Influye en la complejidad espacial del mismo. 
Influye en su complejidad temporal.
No influye en ninguna de sus complejidades. 

$$f(n) = 5n+3m·n +11$$ entonces $$f(n)$$ pertenece a: 
3
$$O (n·m)$$. 
$$O (n^m)$$.
Las dos son correctas

El sumatorio, desde $$i=1$$ hasta n, de $$i^k$$ pertenece a:
1
$$Ο(n^{k+1})$$ 
$$Ο(n^k)$$
Ninguna de las anteriores 

La complejidad de la función A2 es: ```Funcion A2 (n, a: entero):entero; \nVar r: entero; fvar \n\tsi (a² > n) devuelve 0 \n\tsino \n\t\tr:= A2(n, 2a); \n\t\topción \n\t\t\tn < a²: devuelve r; \n\t\t\tn ≥ a² : devuelve r + a; \n\t\tfopción \n\tfsi \nfin```
2
$$O(\sqrt{n} · a)$$
$$O( \sqrt{n} / a)$$
$$O( n / \sqrt{a} )$$

Cual de las siguientes definiciones es cierta: 
1
Las cotas de complejidad se emplean cuando para una misma talla se obtienen diferentes complejidades dependiendo de la entrada al problema.
Las cotas de complejidad se emplean cuando para diferentes tallas se obtienen diferentes complejidades dependiendo de la entrada al problema.
Ninguna de las anteriores 

Cuando para distintas instancias de problema con el mismo tamaño no obtenemos el mismo resultado: 
3
No es posible calcular la complejidad a priori y debemos ejecutar el programa varias veces con la misma talla y obtener el tiempo medio para hallar la complejidad media. 
No se puede aplicar la técnica de paso de programa, ya que esta técnica es para calcular la complejidad a priori. 
Calculamos el máximo y mínimo coste que nos puede dar el algoritmo.

$$f(n) = 5n+5$$ ¿ $$f(n)$$ pertenece a $$O(n)$$? 
3
Si. El valor de c es 5 y el valor mínimo de n_0 es de 3 
Si. El valor de c es 9 y el valor mínimo de n_0 es de 1
Si. El valor de c es 6 y el valor mínimo de n_0 es de 5

$$f(n) = 10n+7$$ ¿ $$f(n)$$ pertenece a $$O(n 2)$$$? 
2
Si. Para c = 1 y a partir de un valor de n_0 =10. 
Sí Para cualquier valor de c positivo siempre existe un n_0 a partir del que se cumple. 
No. 

Si f(n) ∈ Ω (g(n)) entonces:
1
∃ c, n_0 ∈ R^+ : f(n) ≥ c· g(n) ∀ n ≥ n_0
∃ c, n_0 ∈ R^+ : f(n) ≥ c· g(n) ∀ n
∃ c, n_0 ∈ R^+ : f(n) ≤ c· g(n) ∀ n ≥ n_0

El coste asociado a la siguiente ecuación de recurrencia es: \n$$f(n) = \begin{cases} 1 & n \leq 1 \\ n + f(\frac{n}{2}) + f(\frac{n}{2}) & n > 1 \end{cases}$$
3
Θ(n lg n^2) 
Θ(n^2 lg n) 
Θ(n lg n)

Un algoritmo recursivo basado en el esquema divide y vencerás...
1
... será más eficiente cuanto más equitativa sea la división en subproblemas.
Las demás opciones son verdaderas.
... nunca tendrá una complejidad exponencial.

Indicad cuál de estas tres expresiones es falsa.
2
Θ(n / 2) = Θ(n)
Θ(n) ⊆ Θ(n^2)
Θ(n) ⊆ Θ(n)

¿Cuál de estas tres expresiones es falsa?
3
3n^2 + 1 ∈ O(n^3)
n + n log(n) ∈ Ω(n)
n + n log(n) ∈ Θ(n)

Indica cuál es la complejidad en el peor caso de la función replace:```unsigned bound( const vector<int>& v ) {\n\tfor( unsigned i = 0; i < v.size(); i++ )\n\t\tif( v[i] == '0')\n\t\t\treturn i;\n\treturn v.size();\n}\n\nvoid replace( vector<int>& v, int c ) {\n\tfor( unsigned i = 0; i < bound(v); i++)\n\t\tv[i] = c;\n}\n```
2
O(n log n)
O(n^2)
O(n)

¿Cuál es la complejidad temporal de la siguiente función recursiva?```unsigned desperdicio (unsigned n){ \n\tif (n<=1) \n\t\treturn 0; \n\tunsigned sum = desperdicio(n/2) + desperdicio(n/2); \n\tfor (unsigned i=1; i<=n-1; i++) \n\t\tfor (unsigned j=1; j<=i; j++) \n\t\t\tsum+=1; \n\treturn sum; \n} \n```
1
Θ(n^2)
Θ(2^n)
Θ(n^2 log n)

Sea f(n) la solución de la relación de recurrencia f(n) = 2f(n/2) + 1; f(1) = 1. Indica cual de estas tres expresiones es cierta.
1
f(n) ∈ Θ(n)
f(n) ∈ Θ(n^2)
f(n) ∈ Θ(n log n)

Considerad estos dos fragmentos:```s=0; for(i=0;i<n;i++) s+=i;``` y ```s=0; for(i=0;i<n;i++) if (a[i] != 0) s+=i;``` y un array a[i] de números enteros. Indicad cuál de estas tres afirmaciones es cierta:
2
El coste temporal asintótico del primer programa en el caso peor es más alto que en el segundo.
El coste temporal asintótico, tanto en el caso mejor como en el caso peor, de los dos programas es el mismo.
El coste temporal asintótico del segundo programa en el caso peor es más alto que en el primero.

Indica cual es la complejidad, en función de n, del fragmento siguiente:```int a = 0; \nfor( int i = 0; i < n; i++ ) \n\tfor( int j = i; j > 0; j /= 2 ) \n\t\ta += a[i][j];```
1
O(n log n)
O(n)
O(n^2)

Indica cuál es la complejidad en función de n, donde K es una constante (no depende de n ), del fragmento siguiente:```for( int i = K; i < n - K; i++ ){ \n\tA[i] = 0; \n\tfor( int j = i - K; j < i + K; j++ ) \n\t\tA[i] += B[j]; \n}```
1
O(n)
O(n log n)
O(n^2)

Pertenece $$3n^2 + 3$$ a $$O(n^3)$$?
3
Solo para c = 1 y n_0 = 5.
No.
Sí.

La complejidad temporal en el mejor de los casos...
3
Las demás opciones son verdaderas.
... es el tiempo que tarda el algoritmo en resolver la talla más pequeña que se le puede presentar.
... es una función de la talla que tiene que estar definida para todos los posibles valores de esta.

La versión de Quicksort que utiliza como pivote la mediana del vector...
3
... se comporta mejor cuando el vector ya está ordenado.
... se comporta peor cuando el vector ya está ordenado.
... El hecho de que el vector estuviera previamente ordenado o no, no influye en la complejidad temporal de este algoritmo.

Dada la siguiente relación de recurrencia, ¿Qué cota es verdadera? \n\n$$f(n) = \begin{cases} 1 & n = 1 \\ \sqrt{n} + 3f(\frac{n}{3}) & n > 1 \end{cases}$$
1
f(n) ∈ Θ(n)
f(n) ∈ Θ(n^3)
f(n) ∈ Θ(√n log n)

Un problema de tamaño $$n$$ puede transformarse en tiempo $$O(n^2)$$ en nueve de tamaño $$n/3$$. Por otro lado, la solución al problema cuando la talla es $$1$$ requiere un tiempo constante. \n¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
2
O(n^2)
O(n^2 log n)
O(n log n)

Indica cuál es la complejidad, en función de $$n$$, del siguiente fragmento de código: ```s=0; for(i=0;i<n;i++) for(j=i;j<n;j++) s+=i*j;```
1
$$\Theta(n^2)$$
$$O(n^2)$$ pero no $$\Omega(n^2)$$
$$\Theta(n)$$

Sea ƒ(n) la solución de la relación de recurrencia ƒ (n) = 2ƒ(n-1)+1 ƒ(1) = 1. Indicad cuál de estas tres expresiones es cierta:
2
ƒ(n) ∈ Θ(n)
ƒ(n) ∈ Θ(2^n)
ƒ(n) ∈ Θ(n^2)

Un programa con dos bucles anidados uno dentro del otro, El primero hace $$n$$ iteraciones aproximadamente y el segundo la mitad, tarda un tiempo
2
$$O(n \log{n})$$
$$O(n^2)$$
$$O(n \sqrt{n})$$

Un problema de tamaño $$n$$ puede transformarse en tiempo $$O(\frac{n}{2})$$ en nueve de tamaño $$\frac{n}{3}$$; por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante. ¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
2
$$O(n \log n)$$
$$O(n^2 \log n)$$
$$O(n^2)$$

¿Cuál es la complejidad temporal de la siguiente función recursiva?```unsigned desperdicio (unsigned n){ \nif (n<=1) \n\treturn 0; \nunsigned sum = desperdicio (n/2) + desperdicio (n/2); \nfor (unsigned i=1; i<n-1; i++) \n\tfor (unsigned j=1; j<=i; j++) \n\t\tfor (unsigned k=1; k<=j; k++) \n\t\t\tsum+=i*j*k; \nreturn sum; \n}```
3
$$O(2^n)$$
$$O(n^3 \log n)$$
$$O(n^3)$$

Los algoritmos de ordenación Quicksort y Mergesort tienen en común ...
3
... que se ejecutan en tiempo O(n).
... que ordenan el vector sin usar espacio adicional.
... que aplican la estrategia de divide y vencerás.

Indica cuál es la complejidad de la función siguiente:```unsigned sum( const mat &A ) {    # A es una matriz cuadrada \n\tunsigned d = A.n_rows(); \n\tunsigned a = 0; \n\tfor( unsigned i = 0; i < d; i++ ) \n\t\tfor( unsigned j = 0; j < d; j++ ) \n\t\t\ta += A(i,j); \n\treturn a; \n}```
2
$$O(n^2)$$
$$O(n)$$
$$O(n \log n)$$

Indicad cuál de estas tres expresiones es falsa.
3
$$\Theta(n/2) = \space\space\space\space\space\space\space \Theta(n)$$
$$\Theta(n) \subseteq \space \Theta(n)$$
$$\Theta(n) \subseteq \space \Theta(n^2)$$

¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, una solución voraz óptima?
2
El árbol de cobertura de coste mínimo de un grafo conexo.
El problema de la mochila discreta o sin fraccionamiento.
El problema de la mochila continua o con fraccionamiento.

Los algoritmos de programación dinámica hacen uso ...
2
... de que la solución óptima se puede construir añadiendo a la solución el elemento óptimo de los elementos restantes, uno a uno.
... de que se puede ahorrar cálculos guardando resultados anteriores en un almacén. 
... de una estrategia trivial consistente en examinar todas las soluciones posibles.

Cuando se calculan los coeficientes binomiales usando la recursión $$\binom{n}{r} = \binom{n-1}{r} + \binom{n-1}{r-1} $$, con $$ \binom{n}{0} = \binom{n}{n} = 1 $$, qué problema se da y cómo se puede resolver?
3
La recursión puede ser infinita y por tanto es necesario organizarla según el esquema iterativo de programación dinámica.
Se repiten muchos cálculos y ello se puede evitar haciendo uso de una estrategia voraz.
Se repiten muchos cálculos y ello se puede evitar usando programación dinámica.

Sea $$f(n)$$ la solución de la relación de recurrencia $$f(n) = 2f(n/2) + n $$; $$ f(1) = 1 $$. Indicad cuál de estas tres expresiones es cierta.
3
$$ f(n) \in \Theta(n^2) $$
$$ f(n) \in \Theta(n) $$
$$ f(n) \in \Theta(n \log n) $$

Para que la complejidad de un algoritmo presente caso mejor y peor distintos ...
2
... es condición necesaria y suficiente que existan instancias distintas del problema con el mismo tamaño.
... es condición necesaria que existan instancias distintas del problema con el mismo tamaño.
... es condición suficiente que existan instancias distintas del problema con el mismo tamaño.

Indicad cuál de estas tres expresiones es cierta:
3
$$ O(n^2) \subseteq O(2^{\log(n)}) \subset   O(2^n) $$
$$ O(n^2) \subseteq O(2^{\log(n)}) \subseteq O(2^n) $$
$$ O(2^{\log(n)}) \subseteq O(n^2) \subseteq O(2^n) $$

La complejidad temporal en el mejor de los casos de un algoritmo recursivo...
2
... coincide con el valor del caso base de la ecuación de recurrencia que expresa la complejidad temporal del algoritmo.
Las demás opciones son falsas. 
... siempre coincidirá con la complejidad temporal de las instancias que están en el caso base del algoritmo recursivo.

Considerad la función siguiente:```int M( int i, int f ) { \n\tif ( i == f ) \n\t\treturn i; \n\telse { \n\t\te = v[ M( i, (i+f)/2 ) ]; \n\t\tf = v[ M( (i+f)/2+1, f ) ]; \n\t\tif (e<f) \n\t\t\treturn e; \n\t\telse \n\t\t\treturn f; \n\t} \n}```Si la talla del problema viene dada por $$ n = f - i + 1 $$, ¿cuál es el coste temporal asintótico en el supuesto de que $$ n $$ sea una potencia de 2?
1
$$ O(n) $$. 
$$ O(n^2) $$.
$$ O(n \log(n)) $$.

El coste temporal asintótico del fragmento ```s=0; for(i=0;i<n;i++) for(j=i;j<n;j++) s+=i*j;``` y el del fragmento ```s=0; for(i=0;i<n;i++) for(j=0;j<n;j++) s+=i*i*j;```son ...
1
a. ... iguales.
b. ... el del segundo, menor que el del primero.
c. ... el del primero, menor que el del segundo.

La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la primera posición ...
2
... se comporta mejor cuando el vector ya está ordenado.
... se comporta peor cuando el vector ya está ordenado.
... El hecho de que el vector estuviera previamente ordenado o no, no influye en la complejidad temporal de este algoritmo.

La versión de Quicksort que utiliza como pivote el elemento del vector que ocupa la posición central ...
1
... se comporta mejor cuando el vector ya está ordenado.
... se comporta peor cuando el vector ya está ordenado.
... no presenta casos mejor y peor distintos para instancias del mismo tamaño.

Dada la siguiente relación de recurrencia, ¿Qué cota es verdadera? \n\n $$ f(n) = \begin{cases} 1 & n = 1 \\ n + 3f(n/3) & n > 1 \end{cases} $$
1
$$ f(n) \in \Theta(n \log n) $$
$$ f(n) \in \Theta(n^3) $$
$$ f(n) \in \Theta(n) $$

Sobre la complejidad temporal de la siguiente función: ```unsigned desperdicio (unsigned n){ \n\tif (n<=1) \n\t\treturn 0; \n\tunsigned sum = desperdicio (n/2) + desperdicio (n/2) + desperdicio (n/2); \n\tfor (unsigned i=1; i<n-1; i++) \n\t\tfor (unsigned j=1; j<=i; j++) \n\t\t\tfor (unsigned k=1; k<=j; k++) \n\t\t\t\tsum+=i*j*k; \n\treturn sum; \n}```
1
Ninguna de las otras dos alternativas es cierta.
Las complejidades en los casos mejor y peor son distintas.
El mejor de los casos se da cuando n ≤ 1 y en tal caso la complejidad es constante.

Con respecto al esquema Divide y vencerás, ¿es cierta la siguiente afirmación? \nSi la talla se reparte equitativamente entre los subproblemas, entonces la complejidad temporal resultante es una función logarítmica. \n
2
No, nunca, puesto que también hay que añadir el coste de la división en subproblemas y la posterior combinación.
No tiene porqué, la complejidad temporal no depende únicamente del tamaño resultante de los subproblemas.
Sí, siempre, en Divide y Vencerás la complejidad temporal depende únicamente del tamaño de los subproblemas.

¿Qué cota se deduce de la siguiente relación de recurrencia? \n\n $$ f(n) = \begin{cases} 1 & n = 1 \\ n + 4f(\frac{n}{2}) & n > 1 \end{cases} $$
1
f(n) ∈ Θ(n^2)
f(n) ∈ Θ(n)
f(n) ∈ Θ(n log n)

¿Cuál de estas tres expresiones es falsa?
3
$$ 2n^3 - 10n^2 + 1 \in O(n^3) $$
$$ n + n \sqrt{n} \in \Omega(n) $$
$$ n + n \sqrt{n} \in \Theta(n) $$

Sea $$ f(n) = n \log(n) + n $$.
3
... $$ f(n) \in \Omega(n \log(n)) $$
... $$ f(n) \in O(n \log(n)) $$
Las otras dos opciones son ciertas

¿Cuál es la complejidad temporal de la siguiente función?```int ejemplo (vector < int > & v){ \n\tint n=v.size(); \n\tint j,i=2; \n\tint sum=0; \n\twhile (n>0 && i<n){ \n\t\tj=i; \n\t\twhile (v[j] != v[1]){ \n\t\t\tsum+=v[j]; \n\t\t\tj=j/2; \n\t\t} \n\t\ti++; \n\t} \n\treturn sum; \n}```
1
$$ \Theta(n \log n) $$
$$ \Theta(n^2) $$
$$ \Omega(n) $$

En cuanto a la complejidad temporal de la siguiente función:```int ejemplo (vector < int > & v){ \n\tint n=v.size(); \n\tint j,i=2; \n\tint sum=0; \n\twhile (n>0 && i<n){ \n\t\tj=i; \n\t\twhile (v[j] != v[1]){ \n\t\t\tsum+=v[j]; \n\t\t\tj=j/2; \n\t\t} \n\t\ti++; \n\t} \n\treturn sum; \n}```
1
Las complejidades en el mejor y en el peor de los casos no coinciden.
El mejor de los casos se da cuando \( n = 0 \), su complejidad es constante.
Esta función no presenta casos mejor y peor puesto que solo puede haber una instancia para cada una de las posibles talla

Indica cuál es la complejidad, en función de \( n \), del fragmento siguiente:```for( int i = n; i > 0; i /= 2 ) \n\tfor( int j = n; j > 0; j /= 2 ) \n\t\ta += A[i][j]; \n```
1
$$ O(\log^2(n)) $$
$$ O(n \log(n)) $$
$$ O(n^2) $$

Indica cuál es la complejidad, en función de \( n \), del fragmento siguiente:```a = 0; \nfor( int i = 0; i < n*n; i++ ) \n\ta += A[(i + j) % n];```
1
$$ O(n^2) $$
$$ O(n \log(n)) $$
$$ O(n) $$

La versión deQuicksort que utiliza como pivote la mediana del vector...
1
... no presenta caso mejor y peor distintos para instancias del mismo tamaño.
... es más eficiente si el vector ya está ordenado.
... es la versión con mejor complejidad en el mejor de los casos.

El siguiente fragmento del algoritmo de ordenación Quicksort reorganiza los elementos del vector para obtener una subsecuencia de elementos menores que el pivote y otra de mayores. Su complejidad temporal, con respecto al tamaño del vector v, que está delimitado por los valores pi y pf, es...```x = v[pi]; \ni = pi+1; \nj = pf; \ndo { \n\twhile (i<=pf && v[i] < x) i++; \n\twhile (v[j] > x ) j--; \n\tif (i <= j ) { \n\t\tswap( v[i],v[j] ); \n\t\ti++; \n\t\tj--; \n\t} \n} while (i < j); \nswap(v[pi],v[j]);``` \nNota: La función swap se realiza en tiempo constante.
1
... lineal en cualquier caso.
... cuadrática en el peor de los casos.
... lineal en el caso peor y constante en el caso mejor.

Dada la siguiente relación de recurrencia, ¿Qué cota es verdadera?  \n\n$$ f(n) = \begin{cases} 1 & n = 1 \\ n + 2f(n-1) & n \geq 1 \end{cases} $$
1
$$ f(n) \in \Omega(2^n) $$
$$ f(n) \in \Theta(n^2) $$
$$ f(n) \in \Theta(2^n) $$

¿Cuál es la solución a la siguiente relación de recurrencia? \n\n$$ f(n) = \begin{cases} \Theta(1) & n = 0 \\ \Theta(1) + f(n/3) & n > 0 \end{cases} $$
1
$$ f(n) \in \Theta(\log(n)) $$.
$$ f(n) \in \Theta(n/3) $$.
Ninguna de las otras dos es cierta.

De las siguientes expresiones, o bien dos son verdaderas y una es falsa o bien al contrario: dos son falsas y una es verdadera. Marca la que en este sentido es distinta a las otras dos.
3
$$ 2n^3 - 10n^2 + 1 \in O(n^3) $$
$$ n + n\sqrt{n} \in \Omega(n) $$
$$ n + n\sqrt{n} \in \Theta(n) $$

Si $$ f \in \Omega(g_1) $$ y $$ f \in \Omega(g_2) $$ entonces
3
$$ f \not\in \Omega(\min(g_1, g_2)) $$
$$ f \in \Omega(g_1 \cdot g_2) $$
$$ f \in \Omega(g_1 + g_2) $$

¿Cuál de las siguientes relaciones de recurrencia expresa mejor la complejidad espacial es la del algoritmo Mergesort?
3
$$ T(n) = n + T(n - 1) \space\space$$ para $$\space\space n > 1 \space\space$$ y $$\space\space T(n) \space = \space\space\space\space\space\space\space 1 \space\space$$ para $$\space\space n \leq \space\space 1 $$
$$ T(n) = n + T(n/2) \space\space$$ para $$\space\space n > 1 \space\space$$ y $$\space\space T(n) \space = \space\space\space\space\space\space\space 1 \space\space$$ para $$\space\space n \leq \space\space 1 $$
$$ T(n) = n + 2T(n/2) \space\space$$ para $$\space\space n > 1 \space\space$$ y $$\space\space T(n) \space\ = \space\space\space\space\space\space\space 1 \space\space$$ para $$\space\space n \leq \space\space 1 $$

De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es distinta a las otras dos.
3
$$ \log(n^3) \not\in \Theta(\log_3(n)) $$
$$ \Theta(\log^2(n)) = \Theta(\log^3(n)) $$
$$ \Theta(\log_2(n)) = \Theta(\log_3(n)) $$

Un problema de tamaño $$ n $$ puede transformarse en tiempo $$ O(1) $$ en siete de tamaño $$ \frac{n}{7} $$; por otro lado, la solución al problema cuando la talla es 1 requiere un tiempo constante. \n¿Cuál de estas clases de coste temporal asintótico es la más ajustada?
3
$$ O(n^2) $$
$$ O(n) $$
$$ O(n \log n) $$

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){\n\tif(n<2)return;\n\tfor(int i=0;i<pow(n,2);i++)\n\t\tcout<< "*";\n\tfor(int i=0;i<5;i++)\n\t\tf(n/2);\n}```
1
$$O(5^{log\,n})$$
$$O(n^2\,log\,n)$$
$$O(n^2)$$

Se pretende obtener la complejidad temporal en el caso más desfavorable de la siguiente función. \n```int exa(vector<int> &v){ \n\tint i, sum = 0, n = v.size(); \n\tif(n>0){ \n\t\tint j=n; \n\t\twhile(sum<100 and j!=0({ \n\t\t\tj = j /2; \n\t\t\tsum = 0; \n\t\t\tfor(i = j;i<n;i++) \n\t\t\t\tsum += v[i]; \n\t\t} \n\t\treturn j; \n\t} \n\telse return -1; \n}```
1
$$ C_s(n)=\sum^{log(n+1)}_{k=1}(n-n/2^k)\in O(n\log n) $$
$$ C_s(n)=\sum^{log\,n}_{j=1}\sum^{j}_{i=1}(1/2)^i \in O(n\log n) $$
$$ C_s(n)=\sum^{n/2}_{j=0}(1/2\sum^{n}_{i=j}1) \in O(n\log n) $$

Las siguientes funciones calculan el valor de potencia n-+esima de dos. ¿Cuál es el más eficiente en cuanto a coste temporal?\n```unsigned long pot2_1 (unsigned n){ \n\tif(n==0) return 1; \n\tif(n%2==0) return pot2_1(n/2) * pot2_1(n/2); \n\telse return 2 * pot2_1(n/2) * pot2_1(n/2); \n} \n\nunsigned long pot2_2(unsigned n){ \n\tif(n==0) return 1; \nm\t unsigned long aux= pot2_2(n/2); \n\tif(n%2==0) return aux * aux; \n\telse return 2 * aux * aux; \n}``` \n Seleccione una:
3
La primera, pot2_1(n), es más eficiente que la otra.
Las dos funciones son equivalentes en cuanto a coste temporal.
La segunda, pot2_2(n), es más eficiente que la otra.

Tenemos un vector desordenado y queremos obtener los tres elementos más pequeños. ¿Cuál seria la complejidad emporal más ajustada para hacerlo? (sin pérdida de generalidad puedes suponer que en el vector todos los elementos son distintos) \nSeleccione una:
2
El logaritmo de la longitud del vector
Lineal con la longitud del vector
Cuadrática con la longitud del vector

Supongamos que una solución recursiva a un problema de optimización muestra estas dos características: por un lado, se basa en obtener soluciones óptimas a problemas parciales más pequeños, y por otro, estos subproblemas se resuelven más de una vez durante el proceso recursivo. Este problema es candidato a tener una solución alternativa basada en \nSeleccione una:
1
un algoritmo de programación dinámica.
un algoritmo voraz.
un algoritmo del estilo de divide y vencerás.

Si $$ f ∉ O(g_1) $$ y $$ f \in O(g_2) $$ entonces siempre se cumplirá: \nSeleccione una:
1
$$ f \in \Omega(min(g_1,g_2)) $$
$$ f \in \Omega(g_1 + g_2) $$
$$ f ∉ O(max(g_1, g_2)) $$

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){ \n\t if(n < 1) return; \n\tfor(int i = 0; i < n; i++) \n\t\tfor(int j = 0; j < n;j++) \n\t\t\tfor(int k = 0; k < n;k++) \n\t\t\t\tcout << "*"; \n\tfor(int i = 0;i < 8;i++) \n\t\tf(n / 2); \n}``` \nSeleccione una:
1
$$ \Theta(n^3 \log n) $$
$$ \Theta(n^3) $$
$$ \Theta(n^2 \log n) $$

¿En qué caso la complejidad temporal del algoritmo de ordenación Quicksort es igual a la complejidad temporal del algoritmo Mergesort? \nSeleccione una:
1
En el caso mejor de ambos.
En el caso peor de ambos.
Tanto en el caso peor como en el caso mejor de ambo

Di cuál de estos resultados de coste temporal asintótico es falsa: \nSeleccione una:
2
La ordenación de un vector usando el algoritmo Quicksort requiere en el peor caso un tiempo en $$ O(n^2) $$
La ordenación de un vector usando el algoritmo Mergesort requiere en el peor caso un tiempo en $$ O(n^2) $$
La búsqueda binaria en un vector ordenado requiere en el peor caso un tiempo en $$ O(\log n) $$

De las siguientes expresiones, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es  distinta a las otras dos. \nSeleccione una:
2
$$ O(n^2) \subset O(2^{\log_2(n)}) \subset O(2^n) $$
$$ O(2^{\log_2(n)}) \subset O(n^2) \subset O(n!) $$
$$ O(4^{\log_2(n)}) \subset O(n) \subset O(2^n) $$

Tenemos un vector ordenado de tamano $$n_0$$ y un vector desordenado de tamano $$n_d$$ y queremos obtener un vector ordenado con todos los elementos. ¿Qué serå más rápido? \nSeleccione una:
3
Depende de si $$ n_o > n_d $$ o no.
Insertar los elementos del vector desordenado (uno a uno) en el vector ordenado.
Ordenar el desordenado y luego mezclar las listas.

La complejidad temporal (o coste temporal asintötico) en el mejor de los casos... \nSeleccione una:
2
Las otras dos opciones son ambas verdaderas.
... es una función de la talla, o tamano del problema, que tiene que estar definida para todos los posibles valores de ésta
... es el tiempo que tarda el algoritmo en resolver la talla más pequena que se le puede presentar.

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){ \n\tif(n < 1) return; \n\tfor( int i = 0;i < n; i++) \n\t\tfor(int j = 0; j < n; j++) \n\t\t\tfor(int k = 0; k < n; k++) \n\t\t\t\tcout << "*"; \n\tfor(int i = 0; i < 8; i++) \n\t\tif(n / 2); \n}``` \nSeleccione una:
3
$$ \Theta(n^3) $$
$$ \Theta(n^2 \log n) $$
$$ \Theta(n^3 \log n) $$

Sea la siguiente relacion de recurrencia: \n$$ T(n) = \begin{cases} 1 & si\,n \le 1 \\ 8T(\frac{n}{8}) + g(n) & en\,otro\, caso\end{cases} $$ \nSi $$ T(n) \in \Theta(n^2) $$, ¿en cuál de estos tres casos nos podemos encontrar? \nSeleccione una:
2
$$ g(n) = \space\space\space\space\space\space\space n^3  $$
$$ g(n) = \space\space\space\space\space\space\space n^2 $$
$$ g(n) = \space\space\space\space\space\space\space n $$

¿Cuál de los siguientes algoritmos de ordenación necesita un espacio de almacenamiento adicional al vector que se ordena con complejidad O(n)? \nSeleccione una:
1
Mergesort.
Quicksort.
Bubblesort.

Si $$ f ∉ O(g_1) $$ y $$ f \in O(g_2) $$ entonces siempre se cumplirá: \nSeleccione una:
3
$$ f \in \Omega(g_1 + g_2) $$
$$ f ∉ O(max(g_1, g_2)) $$
$$ f \in \Omega(min(g_1, g_2)) $$

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){ \n\tif(n < 2) return; \n\tfor(int i = 0; i < pow(n,2); i++) \n\t\tcout << "*"; \n\tf(n - 2); \n}``` \nSeleccione una:
3
$$ \Theta(n^2 \log n) $$
$$ \Theta(n^2) $$
$$ \Theta(n^3) $$

Si $$ f ∉ O(g_1) $$ y $$ f \in O(g_2) $$ enbtonces siempre se cumplirá: \nSeleccione una:
1
$$ f \in \Omega(min(g_1, g_2)) $$
$$ f \in \Omega(g_1 + g_2) $$
$$ f ∉ \Omega(max(g_1, g_2)) $$

¿Qué nos proporciona la media entre el coste temporal asintótico (o complejidad temporal) en el peor caso y el coste temporal asintótico en el mejor caso? \nSeleccione una:
3
El coste temporal promedio.
El coste temporal asintótico en eI caso medio.
En general, nada de interés.

Las siguientes funciones calculan el valor de la potencia n-ésima de dos. ¿Cuál es más eficiente en cuanto a coste temporal? \n```unsigned long pot2_1(unsigned n){ \n\tif(n==0) return 1; \n\tif(n%2==0)return pot2_1(n/2) * pot2_1(n/2); \n\telse return 2 * pot2_1(n/2) * pot2_1(n/2); \n} \n\nunsigned long pot2_2(unsigned n){ \n\t if(n==0) return 1; \n\treturn 2 * pot2_2(n-1); \n}``` \nSeleccione una:
2
La segunda, pot2_2(n), es más eficiente que la otra.
Las dos funciones son equivalentes en cuanto a coste temporal. 
La primera, pot2_1(n), es más eficiente que la otra.

Con respecto al parámetro n, ¿Cuál es la complejidad temporal de la siguiente función? \n```void f(unsigned n){ \n\tif(n < 2) return; \n\tfor(int i = 0; i < pow(n,2); i++) \n\t\tcout << "*"; \n\tfor(int i = 0; i < 5; i++) \n\t\tf(n/2); \n}``` \nSeleccione una:
3
$$ \Theta(n^2) $$
$$ \Theta(n^2 \log n) $$
$$ \Theta(5^{\log n}) $$

¿Qué algoritmo es asintóticamente más rápido, el Quicksort o el Mergesort? \nSeleccione una:
3
Los dos son igual de rápidos ya que el coste temporal asintótico de ambos es O(n log(n)).
como su nombre indica, el Quicksort.
el Mergesort es siempre más rápido o igual (salvo una constante) que el Quicksort.

La solucion Optima al problema de encontrar el arbol de recubrimiento de coste minimo para un grafo no dirigido, conexo y ponderado \nSeleccione una:
2
... se construye haciendo crecer varios arboles que al final acaban injertados en un unico arbol.
... puede construir un unico arbol que va creciendo o bien construir un bosque de arboles que al final se injenan en un unico arbol
... se construye haciendo crecer un unico arbol.

Se pretende implementar mediante programación dinámica iterativa la función recursiva: \n```int f(int x, int y){ \n\tif(x <= y) return 1; \n\treturn x + f(x-1,y); \n}``` \n¿Cuál es la mejor complejidad espacial que se puede conseguir? \nSeleccione una:
2
$$ O(x) $$
$$ O(1) $$
$$ O(x^2) $$

iCual de los siguientes pares de problemas son equivalentes en cuanto al tipo de solucian (Optima, factible, etc.) aportada por el método voraz? \nSeleccione una:
3
La mochila continua y la asignación de tareas.
El fontanero diligente y el problema del cambio.
La mochila discreta y la asignación de tareas.

De los problemas siguientes, indicad cual no se puede tratar eficientemente como los otros dos: \nSeleccione una:
2
El problema de cortar un tubo de forma que se obtenga el maximo beneficio posible.
El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores.
El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el minimo de monedas posibles.

La eficiencia de los algoritmos voraces se basa en el hecho de que ... \nSeleccione una:
2
... antes de tomar una decisiön se comprueba si satisface las retricciones del problema.
... las decisiones tomadas nunca se reconsideran.
... con antelaciön, Ias posibles decisiones se ordenan de mejor a peor.

Se pretende implementar mediante programación dinamica iterativa la función recursiva:```unsigned f(unsigned x, unsigned v[]) { \n\tif (x==0) \n\t\treturn 0; \n\tunsigned m = 0; \n\tfor (unsigned k = 0; k < x; k++) \n\t\tm = max(m, v[k] + f(x-k, v)); \n\treturn m; \n}```¿Cuál es la mejor estructura para el almacén?
2
int A
int A[]
int A[][]

La solución óptima al problema de encontrar el árbol de recubrimiento de coste mínimo para un grafo no dirigido, conexo y ponderado ... CONFIRMADA
2
... se construye haciendo crecer un único árbol.
... puede construir un único árbol que va creciendo o bien construir un bosque de árboles que al final se injertan en un único árbol
... se construye haciendo crecer varios árboles que al final acaban injertados en un único árbol.

En el método voraz ... CONFIRMADA
1
... es habitual preparar los datos para disminuir el coste temporal de la función que determina cuál es la siguiente decisión a tomar.
... siempre se encuentra solución pero puede que no sea la óptima.
... el dominio de las decisiones sólo pueden ser conjuntos discretos o discretizables.

Se pretende implementar mediante programación dinámica iterativa la función recursiva:```unsigned f( unsigned x, unsigned v[] ) { \nif (x==0) \n\treturn 0; \nunsigned m = 0; \nfor ( unsigned k = 0; k < x; k++ ) \n\tm = max( m, v[k] + f( x-k, v ) ); \n\treturn m; \n}``` ¿Cuál es la mejor complejidad espacial que se puede conseguir? CONFIRMADA
3
O(1)
O(x^2)
O(x)

La eficiencia de los algoritmos voraces se basa en el hecho de que... CONFIRMADA
3
... con antelación, las posibles decisiones se ordenan de mejor a peor
... antes de tomar una decisión de comprueba si satisface las restricciones del problema
... las decisiones tomadas nunca se reconsideran

En la solución al problema de la mochila continua, ¿por qué es conveniente la ordenación previa de los objetos? CONFIRMADA
2
Porque si no se hace no es posible garantizar que la toma de decisiones siga un criterio voraz
Para reducir la complejidad temporal en la toma de cada decisión de O(n) a O(1), donde n es el numero de objetos a considerar
Para reducir la complejidad temporal en la toma de cada decisión de O(n^2) a O(nlogn), donde n es el numero de objetos a considerar

Si ante un problema de decisión existe un criterio de selección voraz entonces... CONFIRMADA
2
la solución óptima está garantizada
Ninguna de las otras dos es cierta
al menos una solución factible está garantizada

¿Cuál de estos tres problemas de optimización no tiene, o no se le conoce, un solución voraz óptima? CONFIRMADA
3
El árbol de cobertura de coste mínimo de un grafo conexo
El problema de la mochila continua o con fraccionamiento
El problema de la mochila discreta o sin fraccionamiento

¿Cual de los siguientes pares de problemas son equivalente en cuanto al tipo de solución(óptima, factible, etc) aportada por el método voraz? CONFIRMADA
1
La mochila discreta y la asignación de tareas
El fontanero diligente y el problema del cambio
La mochila continua y la asignación de tareas

De los problemas siguientes, indicad cuál no se puede tratar eficientemente como los otros dos: CONFIRMADA
1
El problema de la mochila sin fraccionamiento y sin restricciones en cuanto al dominio de los pesos de los objetos y de sus valores
El problema de cortar un tubo de forma que se obtenga el máximo beneficio posible
El problema del cambio, o sea, el de encontrar la manera de entregar una cantidad de dinero usando el mínimo de monedas posibles

Supongamos que una solución recursiva a un problema de optimización muestra estas dos características: por un lado, se basa en obtener soluciones óptimas a problemas parciales más pequeños, y por otro, estos subproblemas se resuelven más de una vez durante el proceso recursivo. Este problema es candidato a tener una solución alternativa basada en ... CONFIRMADA
2
... un algoritmo del estilo de divide y vencerás.
... un algoritmo de programación dinámica.
... un algoritmo voraz.

La mejora que en general aporta la programación dinámica frente a la solución ingenua se consigue gracias al hecho de que ... CONFIRMADA
3
El número de veces que se resuelven los subproblemas no tiene nada que ver con la eficiencia de los problemas resueltos mediante programación dinámica
... en la solución ingenua se resuelve pocas veces un número relativamente grande de subproblemas distintos.
... en la solución ingenua se resuelve muchas veces un número relativamente pequeño de subproblemas distintos.

¿Cómo se vería afectada la solución voraz al problema de la asignación de tareas en el caso de que se incorporaran restricciones que contemplen que ciertas tareas no pueden ser adjudicadas a ciertos trabajadores ? CONFIRMADA
1
La solución factible ya no estaría garantizada, es decir, pudiera ser que el algoritmo no llegue a solución alguna.
Ya no se garantizaría la solución óptima pero sí una factible.
Habría que replantearse el criterio de selección para comenzar por aquellos trabajadores con más restricciones en cuanto a las tareas que no pueden realizar para asegurar, al menos, una solución factible.

```unsigned f( unsigned y, unsigned x){  # suponemos y >= x \n\tif (x==0 || y==x) return 1;\n\treturn f(y-1, x-1) + f(y-1, x);\n}```
1
O(x-y)
O(y)
O(x)

¿Cual de estas tres estrategias voraces obtiene un mejor valor para la mochila discreta?
1
Meter primero los elementos de mayor valor específico o valor por unidad de peso
Meter primero los elementos de menor peso
Meter primero los elementos de mayor valor

El problema de encontrar el árbol de recubrimiento de coste mínimo para un grafo dirigido y ponderado...
2
sólo se puede resolver con una estrategia voraz si existe una arista para cualquier par de vértices del grafo
... se puede resolver siempre con una estrategia voraz
... no se puede resolver en general con una estrategia voraz

Un algoritm recursivo basado en el esquema divide y vencerás...
2
Las demás opciones son verdaderas
... será más eficiente cuanto más equitativa sea la división en subproblemas
... nunca tendrá una complejidad exponencial

Los algoritmos de programación dinámica hacen uso... CONFIRMADA
3
... de que la solución óptima se puede construir añadiendo a la solución el elemento óptimo de los elementos restantes, uno a uno.
... de una estrategia trivial consistente en examinar todas las soluciones posibles
... de que se puede ahorrar cálculos guardando resultados anteriores en un almacén

Se pretende aplicar la técnica memoización a la siguiente función recursiva: ```int f( int x, int y ) {  \n\tif( x <= y ) return 1;  \n\treturn x + f(x-1,y); \n}```En el caso más desfavorable, ¿qué complejidades temporal y espacial cabe esperar de la función resultante?
1
O(x-y), tanto temporal como espacial.
Ninguna de las otras dos opciones es correcta
Temporal O(x-y) y espacial O(1)

Se pretende implementar mediante programación dinámica iterativa la función recursiva:```unsigned f(unsigned y, unsigned x) { # suponemos y >= x \n\tif (x==0 || y==x) return 1; \n\treturn f(y-1, x-1) + f(y-1, x); \n}```¿Cuál es la mejor estructura para el almacén? \nSeleccione una:
2
int A[]
int A
int A[] []

Dado un problema de optimización, el método voraz... CONFIRMADA
3
Siempre obtiene una solución óptima
Siempre obtiene una solución factible
garantiza la solución óptima sólo para determinados problemas

Un informático quiere subir a una montaña y para ello decide que tras cada paso, el siguiente debe tomarlo en la dirección de máxima pendiente hacia arriba. Además, entenderá que ha alcanzado la cima cuando llegue a un punto en el que no haya ninguna dirección que sea cuesta arriba. ¿qué tipo de algoritmo está usando nuestro informático? CONFIRMADA
2
un algoritmo divide y vencerás.
un algoritmo voraz.
un algoritmo de programación dinámica

```int f(int x, int y){  \n\tif (x<=y) return 1;  \n\treturn x + f(x-1,y);\n}```Seleccione una:
2
O(x^2)
O(1)
O(x)

¿Qué mecanismo se usa para acelerar el algoritmo de Prim? CONFIRMADA
3
El TAD "Union-find"
Mantener una lista de los arcos ordenados según su peso.
Mantener para cada vértice el vértice origen de la arista más corta hasta él.

Cuando la descomposición de los problemas da lugar a subproblemas de tamaño similar, ¿qué esquema promete ser más apropiado? CONFIRMADA
1
Programación dinámica
Divide y vencerás, siempre que se garantice que los problema no son del mismo tamaño
El metodo voraz

Se pretende implementar mediante programación dinámica iterativa la función recursiva:```unsigned f(unsigned y, unsigned x) { # suponemos y >= x \n\tif (x==0 || y==x) return 1; \n\treturn f(y-1, x-1) + f(y-1, x); \n} ```¿Cuál es la mejor complejidad espacial que se puede conseguir? \nSeleccione una: CONFIRMADA
3
O(y^2)
O(1)
O(y)

La solución de programación dinámica iterativa del problema de la mochila discreta... CONFIRMADA
3
... tiene un coste temporal asintótico exponencial con respecto al número de objetos
... calcula menos veces el valor de la mochila que la correspondiente solución de programación dinámica recursiva
... tiene la restricción de que los valores tienen que ser enteros positivos

¿Cual de los siguientes pares de problemas son equivalentes en cuanto al tipo de solución(óptima, factible, etc) aportada por el método voraz? CONFIRMADA
1
El fontanero diligente y mochila continua
El fontanero diligente y el problema del cambio
El fontanero diligente y asignación de tareas

Un tubo de n centímetros de largo se puede cortar en segmentos de 1 centímetro, 2 centímetros, etc... Existe una lista de los precios a los que se venden los segmentos de cada longitud. Una de las maneras de cortar el tubo es la que más ingresos nos producirá. Di cuál de estas tres afirmaciones es FALSA. CONFIRMADA
1
Hacer una evaluación exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo Θ(n!)
Es posible evitar hacer la evaluación exhaustiva "de fuerza bruta" guardando, para cada posible longitud j < n el precio más elevado posible que se puede obtener dividiendo el tubo correspondiente
Hace una evaluación exhaustiva "de fuerza bruta" de todas las posibles maneras de cortar el tubo consume un tiempo Θ(2^n)

¿Cuál de estas estrategias para calcular el $$n$$-ésimo elemento de la serie de Fibonacci \n $$f(n) = f(n - 1) + f(n - 2),\ f(1) = f(2) = 1$$ \nes más eficiente? CONFIRMADA
1
Programación dinámica
La estrategia voraz
Las dos estrategias citadas serían similares en cuanto a la eficiencia

Dada la suma de la recurrencia: \n $$ T(n) = \begin{cases} 1 & n = 0 \\ \sum_{k=0}^{n-1} T(k) & n > 0 \end{cases} $$ \n ¿cuál de las siguientes afirmaciones es cierta?
2
T(n) ∈ Θ(n^2)
T(n) ∈ Θ(2^n)
T(n) ∈ Θ(n!)

Se pretende implementar mediante programación dinámica iterativa la función recursiva: ¿Cuál es la mejor complejidad espacial que se puede conseguir?```float f(unsigned x, int y){ \n\tif( y < 0 ) return 0; \n\tfloat A = 0.0; \n\tif ( v1[y] <= x ) \n\t\tA = v2[y] + f( x-v1[y], y-1 ); \n\tfloat B = f( x, y-1 ); \n\treturn min(A, 2+B); \n}``` CONFIRMADA
3
O(1)
O(y^2)
O(y)

La programación dinámica... CONFIRMADA
3
En algunos casos se puede utilizar para resolver problemas de optimización con dominios continuos pero probablemente pierda su eficacia ya que puede disminuir drásticamente el número de subproblemas repetidos
Normalmente se usa para resolver problemas de optimización con dominios discretizables puesto que las tablas se han de indexar con este tipo de valores
Las otras dos opciones son ciertas

Se pretende implementar mediante programación dinámica iterativa la función recursiva: ¿Cuál es la mejor complejidad espacial que se puede conseguir?```int f( int x, int y ) { \n\tif( x <= y ) return 1; \n\treturn x + f(x-1,y); \n}```
3
O(x^2)
O(x)
O(1)

Cuando se calculan los coeficientes binomiales usando la recursión $$ {n \choose r} = {n-1 \choose r} + {n-1 \choose r-1} $$, con $$ {n \choose 0} = {n \choose n} = 1 $$, qué problemas se da y cómo se puede resolver? CONFIRMADA
2
Se repiten muchos cálculos y ello se puede evitar haciendo uso de una estrategia voraz.
Se repiten muchos cálculos y ello se puede evitar usando programación dinámica.
La recursión puede ser infinita y por tanto es necesario organizarla según el esquema iterativo de programación dinámica.

Si un problema de optimización lo es para una función que toma valores continuos...
2
La programación dinámica iterativa siempre es mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
La programación dinámica recursiva puede resultar mucho más eficiente que la programación dinámica iterativa en cuanto al uso de memoria.
El uso de memoria de la programación dinámica iterativa y de la programación dinámica recursiva es el mismo independientemente de si el dominio es discreto o continuo.

La mejor solución que se conoce para el problema de la mochila continua sigue el esquema ...
3
...divide y vencerás.
...ramificación y poda.
...voraz.

Uno de estos tres problemas no tiene una solución eficiente que siga el esquema de programación dinámica
2
El problema de la mochila discreta.
El problema de las torres de Hanoi.
El problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud.

¿Cuál de estos problemas tiene una solución eficiente utilizando programación dinámica?
2
El problema de la asignación de tareas.
El problema del cambio.
La mochila discreta sin restricciones adicionales.

El siguiente programa resuelve el problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud, pero falta un trozo. ¿Qué debería ir en lugar de XXXXXXX?```void fill(price r[]) { \n\tfor (index i=0;i<=n;i++) \n\t\tr[i]=-1; \n} \n \nprice cutrod(price p[], r[], length n) { \n\tprice q; \n\tif (r[n]>=0)  \n\t\treturn r[n]; \n\tif (n==0)  \n\t\tq=0; \n\telse { \n\t\tq=-1; \n\t\tfor (index i=1;i<=n;i++) \n\t\t\tq=max(q,p[i]+cutrod(XXXXXXXX)); \n\t} \n\tr[n]=q; \n\treturn q; \n}```
3
p, r-1, n
p, r, n-r[n]
p, r, n-i

Dadas las siguientes funciones:```# Precondición: { 0 <= i < v.size(); i < j <= v.size() } \nunsigned f( const vector<unsigned>&v, unsigned i, unsigned j ) { \n\tif ( i == j+1 ) \n\t\treturn v[i]; \n\tunsigned sum = 0; \n\tfor ( unsigned k = 0; k < j - i; k++ ) \n\t\tsum += f( v, i, i+k+1 ) + f( v, i+k+1, j ); \n\treturn sum; \n} \n \nunsigned g( const vector<unsigned>& v ) { \n\treturn f( v, v.begin(), v.end() ); \n}```Se quiere reducir la complejidad temporal de la función g usando programación dinámica iterativa. ¿cuál sería la complejidad espacial?
2
cúbica
cuadrática
exponencial

Uno de estos tres problemas no tiene una solución trivial y eficiente que siga el esquema voraz.
1
El problema del cambio.
El problema de la mochila discreta sin limitación en la carga máxima de la mochila.
El problema de la mochila continua.

El siguiente programa resuelve el problema de cortar un tubo de longitud n en segmentos de longitud entera entre 1 y n de manera que se maximice el precio de acuerdo con una tabla que da el precio para cada longitud, pero falta un trozo. ¿Qué debería ir en lugar de XXXXXXX?```void fill(price m[]) { \n\tfor (index i=0;i<=n;i++)  \n\t\tm[i]=-1; \n} \n \nprice cutrod(length n, price m[], price p[]) { \n\tprice q; \n\tif (m[n]>=0) \n\t\treturn m[n]; \n\tif (n==0) \n\t\tq=0; \n\telse { \n\t\tq=-1; \n\t\tfor (index i=1;i<=n;i++) \n\t\t\tq=max(q,p[i]+cutrod(XXXXXXXX)); \n\t} \n\tm[n]=q; \n\treturn q; \n}```
2
n-m[n],m,p
n-i,m,p
n,m[n]-1,p

Decid cuál de estas tres es la cota pesimista más ajustada al valor óptimo de la mochila discreta:
3
El valor de una mochila que contiene todos los objetos restantes aunque se pase del peso máximo permitido.
El valor de la mochila continua correspondiente.
El valor de la mochila discreta que se obtiene usando un algoritmo voraz basado en el valor específico de los objetos.

¿Qué esquema algorítmico utiliza el algoritmos de ordenación Quicksort?
1
Divide y Vencerás 
Programación Dinámica 
Backtracking 

Ante un problema que presenta una solución recursiva siempre podemos aplicar: (NO SEGURO)
1
Divide y vencerás 
Programación dinámica 
Cualquiera de las dos anteriores 

En cual de los siguientes casos no se puede aplicar el esquema Divide y Vencerás: 
3
Cuando los subproblemas son de tamaños muy diferentes 
Cuando el problema no cumple el principio de optimalidad
Se puede aplicar en ambos casos

Dado el algoritmo de búsqueda binaria, supongamos que, en vez de dividir la lista de elementos en dos mitades del mismo tamaño, la dividamos en dos partes de tamaños 1/3 y 2/3. El coste de este algoritmo: 
2
Es el mismo que el del original 
Es mayor que el del original 
Es menor que el del original 

Si n es el número de elementos del vector, el coste del algoritmo Mergesort es: 
2
O(n^2) y Ω(n logn) 
Θ (n logn) 
Θ (n^2) 

La serie de números de Fibonacci se define de la siguiente forma: \n\n $$fib(n) = \begin{cases} 1 & n \leq 1 \\ fib(n-1) + fib(n-2) & n > 1 \end{cases}$$ \n\nPara implementar esta función podemos emplear:
3
Divide y vencerás 
Programación dinámica 
Cualquiera de las dos anteriores

La serie de números de Fibonacci se define de la siguiente forma: \n\n $$fib(n) = \begin{cases} 1 & n \leq 1 \\ fib(n-1) + fib(n-2) & n > 1 \end{cases}$$ \n\n¿Qué implementación de entre las siguientes supone el menor coste? 
2
Divide y vencerás 
Programación dinámica 
Cualquiera de las dos anteriores

El problema de la mochila, ¿puede solucionarse de forma óptima empleando la estrategia de divide y vencerás?: 
2
Sólo para el caso de la mochila con fraccionamiento 
Sólo para el caso de la mochila sin fraccionamiento 
Si, se puede aplicar para ambos casos. 

Para que un problema de optimización se pueda resolver mediante PD es necesario que: 
1
Cumpla el principio de optimalidad 
Cumpla el teorema de reducción 
Cumpla los dos anteriores 

Dada una solución recursiva a un problema ¿Cómo podemos evitar la resolución de los mismos subproblemas muchas veces? 
2
Resolver los subproblemas de mayor a menor y guardar su resultado en una tabla, inicializándola con los problemas pequeños. 
Resolver los subproblemas de menor a mayor y guardar su resultado en una tabla, inicializándola con los problemas pequeños. 
Resolver los subproblemas de mayor a menor y guardar su resultado en una tabla, inicializándola con los problemas más grandes. 

Si aplicamos Programación Dinámica a un problema que también tiene solución por divide y vencerás podemos asegurar que... 
3
El coste temporal se reduce y el espacial aumenta con respecto a la solución por DyV 
El coste temporal aumenta y el espacial se reduce con respecto a la solución por DyV 
Ninguna de las anteriores.

¿Cuándo utilizaremos Programación Dinámica en lugar de Divide y Vencerás? (NO SEGURO)
2
Cuando se incrementa la eficacia 
Cuando se incrementa la eficiencia 
Cuando se reduce el coste espacial. 

En programación dinámica, dónde almacenamos los valores de los problemas resueltos? 
3
En un vector unidimensional 
En un vector bidimensional 
Depende del problema

Supongamos el problema de la mochila resuelto mediante Programación Dinámica y particularizado para n elementos y un peso máximo trasportable de P. ¿Es necesario calcular valores para toda la matriz auxiliar para obtener el resultado? 
2
Si 
No 
Depende de los valores de n y P. 

Un problema de optimización cuya solución se puede expresar mediante una secuencia de decisiones cumple el principio de optimalidad si, dada una secuencia óptima: (NO SEGURO)
3
Existe una subsecuencia de esa solución que corresponde a la solución óptima de su subproblema asociado
Existe al menos una subsecuencia de esa solución que corresponde a la solución óptima de su subproblema asociado 
Cualquier subsecuencia de esa solución corresponde a la solución óptima de su subproblema asociado 

La programación dinámica, para resolver un problema, aplica la estrategia... 
1
Se resuelven los problemas más pequeños y, combinando las soluciones, se obtienen las soluciones de problemas sucesivamente más grandes hasta llegar al problema original. 
Se descompone el problema a resolver en subproblemas más pequeños, que se resuelven independientemente para finalmente combinar las soluciones de los subproblemas para obtener la solución del problema original. 
Ninguna de las anteriores 

¿Qué esquema de programación es el adecuado para resolver el problema del k-ésimo mínimo en un vector? 
2
Programación Dinámica 
Divide y Vencerás 
Ninguno de los dos 

Si n es el número de elementos de un vector. La solución de menor coste al problema de encontrar su k-ésimo mínimo tiene la siguiente complejidad: 
2
Ω (n) y O(n logn) 
Ω (n) y O(n^2) 
Ninguna de las dos 

Si n es el número de elementos de un vector. Podemos encontrar una solución al problema de encontrar su k-ésimo que esté acotada superiormente por : 
1
O(n^3) 
O (n) 
Ninguna de las dos 

Dada la solución recursiva al problema de encontrar el k-ésimo mínimo de un vector. Cada llamada recursiva, ¿cuántas nuevas llamadas recursivas genera? 
1
una o ninguna 
dos o ninguna 
una o dos 

La solución al problema de encontrar el k-ésimo mínimo de un vector pone en práctica la siguiente estrategia: 
2
Ordena totalmente el vector 
Ordena parcialmente el vector 
No ordena ningún elemento del vector 

¿Qué esquema de programación es el adecuado para resolver el problema de la búsqueda binaria? 
2
Programación Dinámica 
Divide y Vencerás 
Ninguno de los dos 

Si n es el número de elementos de un vector. La solución de menor coste al problema de la búsqueda binaria tiene la siguiente complejidad: 
3
Ω (logn) y O(n logn) 
Θ(n logn) 
Ω (1) y O(logn) 

¿Con qué esquema de programación obtenemos algoritmos que calculan la distancia de edición entre dos cadenas? 
1
Programación Dinámica 
Divide y vencerás 
Ambos 

Disponemos de dos cadenas de longitudes m y n. Si resolvemos el problema de la distancia de edición mediante programación dinámica, ¿De qué tamaño debemos definir la matriz que necesitaremos? 
3
(m-1) x (n-1) 
m x n 
(m+1) x (n+1)

Se pretende implementar mediante programación dinámica iterativa la función recursiva:```float f(unsigned x, int y){ \n\tif( y < 0 ) return 0; \n\tfloat A = 0.0; \n\tif ( v1[y] <= x )  \n\t\tA = v2[y] + f( x-v1[y], y-1 ); \n\tfloat B = f( x, y-1 ); \n\treturn min(A,2+B); \n}```¿Cuál es la mejor complejidad temporal que se puede conseguir? CONFIRMADA
3
O(y)
O(x)
O(x ⋅ y)

Se pretende implementar mediante programación dinámica iterativa la función recursiva:```int f(int x, int y){\n\tif( x <= y ) return 1;\n\treturn x + f(x-1,y);\n}```¿Cuál es la mejor complejidad temporal que se puede conseguir? CONFIRMADA
2
O(y)
O(x)
O(x ⋅ y)

La solución de programación dinámica iterativa del problema de la mochila discreta ... CONFIRMADA
2
... calcula menos veces el valor de la mochila que la correspondiente solución de programación dinámica recursiva.
... tiene la restricción de que los pesos de los objetos tienen que ser números discretos o discretizables.
... tiene la restricción de que los valores de los objetos tienen que ser números discretos o discretizables.

Se pretende aplicar la técnica memoización a la siguiente función recursiva: ```int f( int x, int y ) {  \n\tif( x > y ) return 1;  \n\treturn x + f(x,y-2); \n}```En el caso más desfavorable, ¿qué complejidades temporal y espacial cabe esperar de la función resultante? CONFIRMADA
1
O(x-y), tanto temporal como espacial.
Ninguna de las otras dos opciones es correcta
Temporal O(x-y) y espacial O(1)

El problema de encontrar el árbol de recubrimiento de coste mínimo para un grafo no dirigido, conexo y ponderado ... CONFIRMADA
1
... se puede resolver siempre con una estrategia voraz
sólo se puede resolver con una estrategia voraz si existe una arista para cualquier par de vértices del grafo
... no se puede resolver en general con una estrategia voraz

¿Para qué se utiliza el TAD "Union-find" en el algoritmo de Kruskal? CONFIRMADA
1
Para comprobar si un arco forma ciclos
Para comprobar si un vétice ya ha sido visitado
Para comprobar si dos vértices son equivalentes

La solución óptima al problema de encontrar el árbol de recubrimiento de coste mínimo par un grafo no dirigido, conexo y ponderado ... CONFIRMADA
1
...puede construirlo tanto vértice a vértice como arista a arista
...debe construirlo vértice a vértice: arista a arista no puede ser
...debe construirlo arista a arista: vértice a vértice no puede ser

¿Cuál de los siguientes pares de problemas son equivalentes en cuanto al tipo de solución (óptima, factible, etc.) aportada por el método voraz? CONFIRMADA
2
El fontanero diligente y la asignación de tareas.
El fontanero diligente y la mochila continua.
El fontanero diligente y el problema del cambio.

Un algoritmo recursivo basado en el esquema de divide y vencerás ... CONFIRMADA
3
Las demás opciones son verdaderas
... nunca tendrá una complejidad exponencial
... será más eficiente cuanto más equitativa sea la división en subproblemas

Sea el vector $$ v = {1, 3, 2, 7, 4, 6, 8} $$ cuyos elementos están dispuestos formando un montículo de mínimos. Posteriormente añadimos en la última posición del vector un elemento nuevo con valor 5. ¿Qué operación hay que hacer para que el vector siga representando un montículo de mínimos?
1
Intercambiar el 7 con el 5.
Intercambiar el 8 con el 5.
No hay que hacer nada pues el vector $$ \space\space v = {1, 3, 2, 7, 4, 6, 8,5} \space\space$$ también es un montículo de mínimos.

Se dispone de un conjunto de n valores numéricos dispuestos en forma de montículo y se desea obtener el valor de la suma de todos los que al menos tienen un hijo (es decir, no son nodos hoja). ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
1
O(n)
O(log n)
O(n log n)

¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? ```f (n) = n(n - 1) + \n\t\t\t\t f (n - 1) si n > 0 \n\t\t\t\t f (0) = 1 si n = 0```
2
f (n) ∈ Θ(n^2)
f (n) ∈ Θ(n^3)
Ninguna de las otras dos opciones es cierta.

Indica cuál es la complejidad temporal en función de $$n$$, donde $$A$$ es un vector de enteros y $$k$$ es una constante que no depende de $$n$$, del fragmento siguiente:```for (int i = k; i < n - k; i++){ \n\tA[i] = 0; \n\tfor (int j = i - k; j < i + k; j++){ \n\t\tA[i] += B[j]; \n\t} \n}```
3
Θ(k)
Θ(n^2)
Θ(n)

Con los valores numéricos almacenados en un fichero, queremos construir un heap (montículo). ¿cuál es la forma más eficiente de proceder?
1
Almacenar esos valores en un vector y después, reorganizar sus elementos para que estén dispuestos en forma de heap.
Almacenar esos valores directamente en un heap que inicialmente está vacío y va creciendo por cada uno de los valores insertados.
Ambas formas de proceder son equivalentes en cuanto a eficiencia.

Se dispone de un conjunto de n valores numéricos dispuestos en un vector sin orden pre-establecido. Se desea escribir una función que reciba ese vector y un valor k (n/2 ≤ k ≤ n) y que devuelva los k valores más pequeños dispuestos en otro vector de manera ordenada. ¿Cuál es la complejidad temporal del mejor algoritmo que se puede escribir?
3
O(kn)
Ninguna de las otras dos opciones es cierta.
O(k log n)

Con respecto a los algoritmos estudiados durante el curso que encuentran el árbol de recubrimiento de mínimo coste, de las afirmaciones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos.
1
El algoritmo de Kruskal va construyendo un bosque de árboles que va uniendo hasta que acaba con un árbol de recubrimiento de coste mínimo.
El algoritmo de Prim se puede acelerar notablemente si los vértices se organizan en una estructura union-find.
La complejidad temporal del algoritmo de Prim es cúbica con respecto al número de vértices del grafo.

¿Cuál es la complejidad, en función de n, del siguiente fragmento: (suponed que A está definido como vector<int>A(n) y sort() es la función de ordenación de la librería estándar de C++, que tiene la mejor complejidad, temporal y espacial, posible para un algoritmo de ordenación de propósito general.)```std::sort(begin(A), end(A)); \nint acc = 0; \nfor ( auto i : A ) \n\tacc += i;```
1
Θ(n log n)
Θ(n^2)
Θ(n)

Una empresa de transportes dispone de M vehículos para repartir N paquetes, todos al mismo destino. Cada paquete i tiene un peso Pi y se tiene que entregar antes de que transcurra un tiempo Tpi. Por otro lado, cada vehículo j puede transportar una carga máxima Cj, tarda un tiempo Tvj para llegar al destino y consume una cantidad Lj de litros de combustible, independientemente de la carga que transporta. Imaginad un algoritmo de vuelta atrás que obtenga la manera en que se tienen que transportar los objetos (en qué vehículo j tiene que ir cada objeto i) para que el consumo sea el mínimo. ¿Cuál sería una buena cota optimista?
3
La solución voraz del problema de cargar cada paquete en el camión de menor consumo donde cada paquete llega a tiempo, sin tener en cuenta si el camión se sobrecarga o no.
La solución voraz del problema de cargar cada paquete en el camión de menor consumo, sin sobrecargarlo, sin tener en cuenta si el paquete llega a tiempo o no.
Ambas son cotas optimistas válidas.

Queremos aplicar la técnica de memoización a la siguiente función recursiva:```double f(double x) { \n\tif (x <= 2) \n\t\treturn x; \n\treturn f(sqrt(x-1)) + f(sqrt(x-2)); \n}```¿Cuál sería un buen candidato para el almacén? (La función sqrt() obtiene la raíz cuadrada; xMax es el valor de x en la primera llamada.)
3
vector < vector < double > > M(xMax+1, vector < double > (xMax+1))
vector < double > M(xMax+1)
Ninguna de las otras dos opciones es válida.

¿Qué obtenemos con la siguiente declaración de C++: priority_queue<nodo> pq; ?
1
Un heap o montículo de máximos.
Un heap o montículo de mínimos.
Un heap o montículo sin orden establecido ya que no se ha definido la función de comparación.

Un fontanero tiene una jornada de Q cuartos de hora (es así como se organiza la agenda) y tiene C clientes. El trabajo del cliente i tarda qi cuartos de hora y el fontanero le cobra un precio pi. Es posible que no pueda atender a todos los clientes en la jornada, que nunca puede de alargar. Este problema tiene una solución bien conocida que permite elegir qué clientes visitar para que la suma cobrada al final de la jornada sea la máxima. ¿Qué podemos decir de esta solución?
2
Que se ha de implementar forzosamente con un algoritmo de búsqueda y enumeración como el de vuelta atrás.
Que la organización de la agenda en cuartos de hora permite obtener una solución de complejidad temporal Θ(QC) y complejidad espacial Θ(Q).
Que no se puede implementar con una solución de “divide y vencerás” con memoización.

De las siguientes expresiones, o bien dos son ciertas y una es falsa, o bien al contrario, una es cierta y dos son falsas. Marca la que en este sentido es diferente a las otras dos.
2
$$\sum_{i=1}^{n/2} \sum_{j=1}^{i} 2^j = \space\space\space\space\space\space\space\space\space\space\space\space O(n \log n)$$
$$\sum_{i=1}^{n} \sum_{j=1}^{\log i} 2^j = \space\space\space\space\space\space\space\space\space\space\space\space O(n^2)$$
$$\sum_{i=1}^{\log n} \sum_{j=1}^{n} 2^j = \space\space\space\space\space\space\space\space\space\space\space\space O(n \log n)$$

En cuanto a la posibilidad de aplicar la técnica de programación dinámica iterativa para resolver un problema:
1
Se debe conocer de antemano todos los posibles subproblemas y además, se debe disponer de una ordenación entre todos ellos según tamaño.
No necesariamente ha de conocerse de antemano todos los posibles subproblemas pero sí debe saberse, dados dos de ellos cualesquiera, cuál es más pequeño.
Se debe conocer de antemano todos los posibles subproblemas pero no necesariamente se debe disponer de una ordenación entre todos ellos según tamaño.

¿Cuál es el coste de monticulizar (heapify) un vector de tamaño N?
2
O(N log N) y Ω(N)
Θ(N)
O(N) y Ω(1)

Para resolver la versión general del problema de la mochila con n objetos y carga máxima W, hemos escrito un algoritmo de divide y vencerás que, sucesivamente, divide el problema en dos subproblemas; cada uno de ellos toma la mitad de los objetos y la mitad de la carga máxima de la mochila. El caso base ocurre cuando solo hay un objeto que se añade a la solución si cabe en la fracción de carga máxima que corresponde a ese subproblema, y si no cabe se descarta. Asumiendo que n y W son potencias exactas de 2, ¿qué podemos decir de esta solución?
1
Que con los resultados de los subproblemas no siempre se puede componer la solución del problema original.
Que no cumple el teorema de reducción.
Que, aunque con los resultados de los subproblemas se puede componer la solución del problema original, esta formulación no mejora la solución estudiada en clase.

En un algoritmo de búsqueda y enumeración, ¿qué podemos decir acerca de la heurística que se utiliza para determinar si un nodo debe expandirse o no?
2
Que puede equivocarse, por eso se le llama heurística.
Que también puede usarse como estrategia de búsqueda.
Las otras dos opciones son ambas ciertas.

Dados dos nodos cualesquiera del árbol de búsqueda de ramificación y poda, en general, ¿se puede saber con certeza cuál está más cerca de la solución óptima del problema a resolver?
3
Sí, el que tiene mejor cota optimista.
Sí, el que tiene mejor cota pesimista.
Sí, pero solo si ambos nodos son hoja.

El problema de la moneda consiste a formar una suma M con el número mínimo de monedas tomadas (con repetición) de un conjunto C donde hay una cantidad suficientemente grande de monedas con cada posible valor facial C' = {c1, c2, ..., c|C|}, con c1 = 1. ¿Cuál de estas afirmaciones sobre un algoritmo recursivo de la forma\n\n$$ n_opt(M) = 1 + min_{1≤i≤|C|} n_opt(M - ci); $$\n\n$$n_opt(0) = 0;$$\n\n$$n_opt(x) = ∞$$ para $$x < 0$$ \n\nes falsa?
1
Dependiendo de cuáles sean los valores faciales y la suma, puede ser que el algoritmo recursivo no encuentre solución.
Tiene un coste temporal prohibitivo, ya que puede calcular n_opt(x) para el mismo valor de x más de una vez.
Encuentra siempre la solución óptima.

Se pretende resolver el problema del viajante de comercio (travelling salesman problem) mediante el esquema de vuelta atrás. ¿Cuál de los siguientes valores se espera que se comporte mejor como cota optimista para un nodo?
1
La suma de los pesos de las k aristas restantes más cortas, donde k es el número de ciudades que quedan por visitar.
El valor que se obtiene de multiplicar k por el peso de la arista más corta de entre las restantes, donde k es el número de ciudades que quedan por visitar.
La suma de los pesos de las aristas que completan la solución paso a paso visitando el vértice más cercano al último visitado.

¿Cuál es la complejidad temporal en función de n, del siguiente fragmento:```for (int i = 0; i < n; i++) { \n\tA[i] = 0; \n\tfor (int j = 0; j < 20; j++) { \n\t\tA[i] += B[j]; \n\t} \n}```
3
Θ(n log n)
Θ(n^2)
Θ(n)

Sea f(n) = 3n + 4. Dos de las tres afirmaciones siguientes prueban que f(n) ∈ O(n). ¿Cuál es la que no?
3
Para todo n > 4 se cumple que 3n + 4 < 4n
Para todo n > 4/(c-3), con c > 3, se cumple que 3n + 4 < cn.
Para todo n < 4/(c-3), con c > 4, se cumple que 3n + 4 < cn.

¿Cuál es la complejidad temporal en el caso mejor del algoritmo que, dado un vector, nos dice cuál de sus elementos quedaría en la posición k si lo ordenáramos por orden descendente de valor?
2
O(log n)
O(n)
O(n log n)

Tengo que sumar una larga lista de n cantidades diferentes y se me ha ocurrido que una manera de ganar tiempo es la siguiente estrategia recursiva: parto la lista en dos sublistas iguales, calculo su suma por separado usando la misma técnica y luego sumo las dos cantidades. Cuando al partir una lista me quedo con una cantidad sólo, la suma es esa cantidad, y si me quedan cero cantidades, la suma es cero. ¿Gano tiempo, es decir, hago menos sumas?
3
No, en este caso el coste temporal es Θ(n log n).
Sí, ya que en este caso el coste temporal se reduce a Θ(log n).
No, ya que la complejidad temporal del método propuesto es la misma que la de sumar una a una las cantidades

Uno de estos tres algoritmos de ordenación no opera directamente sobre el vector, y necesita almacenamiento adicional para los elementos del mismo. ¿Cuál es?
1
Mergesort
Heapsort
Quicksort

Si $$ \lim_{n → \infty} \left(\frac{f(n)}{n^2}\right) = 3 $$, ¿cuál de estas afirmaciones es cierta?
3
$$ f(n) \in \Omega(n^3) $$
$$ f(n) \in \Theta(n^3) $$
Las otras dos opciones son ambas falsas.

Indica cuál de los siguientes conjuntos es el conjunto O(f):
1
{g : N → R+ | ∃c > 0, ∃n0 ∈ N, ∀n > n0, g(n) < c f(n)}
{g : N → R+ | ∃c > 0, ∃n0 ∈ N : ∀n > n0, g(n) > c f(n)}
{g : N → R+ | ∃c, d > 0, ∃n0 ∈ N : ∀n > n0, c f(n) ≤ g(n) ≤ d f(n)}

El elemento n-ésimo de la serie tribonacci, T(n), se define como sigue: T(n) = T(n - 3) + T(n - 2) + T(n - 1) para n > 3; T(0) = 0; T(1) = 1 y T(2) = 1. ¿Cuál de estas afirmaciones es falsa?
3
Una implementación ingenua de la función T(n), la cual llamaría a T(n - 1), T(n - 2) y T(n - 3) tendría una complejidad prohibitiva por la repetición de cálculos que se produciría.
Es posible una implementación de programación dinámica iterativa con complejidad Θ(n).
El problema no tiene una solución de programación dinámica iterativa pero se puede resolver añadiendo memoización al cálculo recursivo ingenuo en el que el cálculo de T(n) comporta realizar las llamadas a T(n - 1), T(n - 2) y T(n - 3).

Sobre el teorema de reducción:
2
Que se cumpla es condición necesaria para poder aplicar divide y vencerás.
Las otras dos opciones son ambas falsas.
Que se cumpla es condición necesaria para poder aplicar programación dinámica.

De las siguientes situaciones, o bien dos son posibles y una no lo es, o bien al contrario, solo una es posible y las otras dos no lo son. Marca la que, en este sentido, es diferente a las demás.
2
f(n) ∈ O(n) y f(n) ∈ Ω(1).
f(n) ∈ O(n) y f(n) ∈ Ω(n^2).
f(n) ∈ O(n) y f(n) ∈ O(n^2).

¿Puede ocurrir que la solución recursiva de estilo "divide y vencerás" pero con memoización de un problema resuelva menos subproblemas que la mejor solución iterativa posible de programación dinámica?
2
No, nunca.
Sí, porque la mejor solución iterativa posible de programación dinámica puede resolver subproblemas que no sean necesarios al resolver subproblemas posteriores.
Sí, porque no existe garantía de que la mejor solución iterativa posible no resuelva problemas repetidos, mientras que la técnica de memoización lo garantiza directamente mediante el uso de un almacén.

En la estrategia de ramificación y poda se usa una cola de prioridad para decidir en qué orden se expanden los nodos. Imaginemos un problema de optimización. ¿Puede ser que el valor por el cual se ordenan los nodos sea una cota pesimista del nodo?
1
Sí.
No, porque para podar necesitamos una cota optimista.
No, porque una cota pesimista es típicamente el valor que se encuentra en una de las hojas que cuelga del nodo.

Sobre la propiedad de subestructura óptima de un problema de optimización (por selección discreta):
3
Es condición necesaria para poder aplicar divide y vencerás.
Es condición necesaria para poder aplicar programación dinámica.
Las otras dos opciones son ambas ciertas.

En cuanto a la complejidad temporal de la siguiente función, ¿cuál de las siguientes formulaciones expresa mejor su complejidad en el peor de los casos?```int f(vector <int> &v) { \n\tint n=v.size(), i=2, k=0; \n\twhile (i<n){ \n\t\tint j=i; \n\t\twhile (v[j] != v[1]){ \n\t\t\tk++; \n\t\t\tj=j/2; \n\t\t} \n\t\ti=i+2; \n\t} \n\treturn k; \n}```
1
$$ c_s(n) = \sum_{k=1}^{\lfloor \frac{n-1}{2} \rfloor} \log_2 2k \in O(n \log n) $$
$$ c_s(n) = \sum_{k=1}^{\lfloor \frac{n-1}{2} \rfloor} \log_2 2k^2 \in O(\log^2 n) $$
Las otras dos opciones son ambas falsas.

La costa de un país tiene n núcleos de población, todos unidos por una línea costera de tren. La industria de cada núcleo de población $$j$$ produce $$T_j$$ toneladas de productos para la exportación y se encuentra en el kilómetro $$k_j$$ de la línea de tren. Las exportaciones son básicas para su economía y debe realizarse por mar ya que ha roto relaciones con los países con los que linda por tierra. El gobierno ha decidido promover el transporte marítimo y ha presupuestado la cantidad necesaria para construir p puertos de manera que se minimice el tráfico por la línea de tren. El tráfico es $$\sum_{j=1}^{n} T_j |k_j - k_{s(j)}|$$ donde $$s(j)$$ es el puerto de salida más cercano al núcleo $$j$$ ¿Es posible resolver el problema mediante una técnica de programación dinámica?
2
No. Debe resolverse usando una técnica de búsqueda y enumeración (vuelta atrás, ramificación y poda) ya que el problema no tiene subestructura óptima.
Sí. El problema goza de subestructura óptima: podemos resolver el problema asumiendo que conocemos la solución para las m primeras ciudades y para p - 1 puertos, determinar la posición óptima para que el puerto p sirva a las n - m ciudades restantes, y buscar la valor óptimo de m.
No, pero el problema tiene una solución voraz exacta que consiste en empezar por asignar puerto a todos los núcleos de población e ir quitando uno a uno los puertos de manera que el tráfico que resulte de quitarlos aumente lo mínimo posible.

¿Cuál de las siguientes formulaciones expresa mejor la complejidad temporal, en función del parámetro n, de la siguiente función? (asumimos que n es potencia exacta de 2)```int f(int n) { \n\tint k=0; \n\tfor (int i = 2; i <= n; i *= 2) \n\t\tfor (int j = i; j > 0; j -= 2) \n\t\t\tk++; \n\treturn k; \n}```
2
$$ \sum_{p=2}^{n/2} \space\space\space\space$$ (p-1)/2 
$$ \sum_{p=1}^{\log n} \space\space\space\space$$ 2^{p-1} 
$$ \sum_{p=1}^{\log n} \space\space\space\space$$ 2 * (p-1) 

¿Cuál es el coste temporal de crear un montículo a partir de un vector no ordenado?
1
Θ(n)
Θ(n log n)
Ω(n log n) y O(n^2).

Existen dos algoritmos que para ordenar un vector de n elementos, buscan el máximo de esos n elementos, lo intercambian con el n-ésimo elemento para ponerlo al final, y luego ordenan, usando el mismo algoritmo, el vector de las primeras n − 1 componentes. ¿Cuál de las afirmaciones siguientes es cierta?
1
Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por selección; el primero tiene un coste temporal O(n log n) y el segundo, O(n^2).
Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por burbuja o bubblesort; el primero tiene un coste temporal O(n log n) y el segundo, O(n^2).
Uno de los algoritmos es heapsort y el otro es una de las posibles maneras de realizar la ordenación por selección; el primero tiene un coste temporal O(n) y el segundo, O(n^2).

Se pretende resolver la versión general del problema del encaminamiento óptimo mediante la técnica "divide y vencerás", ¿se podría obtener la mejor disposición de las puertas?
1
No, ya que no se cumple la propiedad "subestructura óptima".
No, ya que no cumple el teorema de reducción.
Sí, pero a costa de una complejidad temporal prohibitiva.

Cuál es la complejidad temporal en función del tamaño del problema (n) de multiplicar dos matrices cuadradas?
2
O(n^2)
O(n^3/2)
O(n^3)

Una de las tres afirmaciones siguientes sobre los algoritmos que obtienen el árbol de recubrimiento mínimo de un grafo ponderado no dirigido es cierta. ¿Cuál es?
2
El algoritmo de Kruskal va ampliando un único árbol de recubrimiento mínimo.
El algoritmo de Prim va ampliando un único árbol de recubrimiento mínimo.
El algoritmo de Prim se puede acelerar usando una estructura de datos de conjuntos disjuntos con las operaciones union y find.

Un ladrón entra por la noche en la quesería más prestigiosa del mercado central con una larga mochila cilíndrica que tiene exactamente el diámetro de los quesos (todos los quesos son cilindros del mismo diámetro y altura, siguiendo un nuevo estándar de la UE) en la que puede cargar exactamente un metro de quesos y con una sofisticada sierra radial quesera (con baterías) que le permite cortar un queso horizontalmente en lugar de hacer cuñas, de manera que se lleve un cilindro. Cada queso tiene un precio único, que no se repite en la tienda. Se quiere llevar queso por el máximo importe posible. Indica cuál de las siguientes afirmaciones sobre la carga óptima es falsa.
3
Lleva la mochila llena hasta arriba y como mucho ha usado la sierra radial para cortar un queso.
Los primeros quesos que ha cargado son, enteros, los quesos más caros de toda la quesería.
Lleva la mochila llena hasta arriba y ha usado la sierra radial más de una vez para llevarse porciones bien calculadas de los quesos más caros.

El problema del cambio es el de formar una suma M con el número mínimo de monedas tomadas (con repetición) de un conjunto C en el que el valor facial de la moneda de tipo i es $$c_i$$. ¿Cuál de las siguientes afirmaciones es falsa?
3
Una versión (memoizada) de la siguiente recursión da la solución óptima en caso de que exista: n(M) = 1 + min_{1≤i≤|C|} n(M - c_i); n(0) = 0; n(x) = ∞ para x < 0
La solución voraz consistente en coger siempre la moneda de valor facial más grande de cuyo valor es menor que la cantidad M así: n(M) = 1 + n(M - c*) donde c* = max{c ∈ C |c ≤ M} puede no encontrar solución para cualquier M y C.
La solución voraz consistente en coger siempre la moneda de valor facial más grande de cuyo valor es menor que la cantidad M así: n(M) = 1 + n(M - c*) donde c* = max{c ∈ C |c ≤ M} encuentra siempre la solución óptima para cualquier M y C si existe dicha solución.

Sea un problema de optimización por selección discreta, con restricciones, en el que se deben tomar n decisiones booleanas para optimizar un indicador, y se abordará mediante un método de búsqueda y enumeración (vuelta atrás, ramificación y poda). ¿Cuál de las siguientes afirmaciones es correcta?
2
La complejidad temporal será como mucho O(n log n) porque en general basta con ordenar adecuadamente las decisiones para convertir cualquier problema de este tipo en un problema de complejidad temporal lineal.
Puede haber problemas para los que la complejidad será exponencial o peor; ninguna estrategia de poda puede garantizar que esto no va a ocurrir.
La complejidad temporal en el peor caso será O(n^2) ya que se toman n decisiones binarias.

Tenemos un “superprocesador” que tiene una instrucción que permite la ordenación de 100 elementos en un tiempo constante. Para este superprocesador, adaptamos el algoritmo Mergesort de forma que cada vez que queremos ordenar menos de 100 elementos, en lugar de hacer las llamadas recursivas, llama a esta instrucción. ¿cuál sería la complejidad de este algoritmo?
1
O(n log n)
O(n)
O(1)

En cuanto a la complejidad temporal de la siguiente función, ¿qué podemos decir acerca del mejor de los casos?```int f(vector <int> & v) { \n\tint n=v.size(), i=2, k=0; \n\twhile (i<n){ \n\t\tint j=i; \n\t\twhile (v[j] != v[1]){ \n\t\t\tk++; \n\t\t\tj=j/2; \n\t\t} \n\t\ti=i+2; \n\t} \n\treturn k; \n}```
2
Que el mejor de los casos ocurre cuando el vector tiene 2 elementos o menos y la complejidad es Ω(1).
Que uno de los mejores casos ocurre cuando v[j] = v[1] ∀ j ∈ ℕ y la complejidad es Ω(n).
Las otras dos opciones son ambas falsas.

Se pretende calcular el valor 2^n, n ∈ ℕ, haciendo una transcripción literal de la expresión $$2^n = 1 + \sum_{i=0}^{n-1} \prod_{j=1}^i 2$$. ¿Cuál sería la complejidad temporal asintótica, en función de n, del algoritmo resultante?
2
O(2^n)
O(n^2)
O(n)

¿Qué diferencia (entre otras) hay entre el algoritmo de Prim y el de Kruskal? Seleccione una: CONFIRMADA
1
El subgrafo que paso a paso va generando el algoritmo de Prim siempre contiene una única componente conexa mientras que el de Kruskal no tiene por qué.
Aún siendo el grafo de partida totalmente conexo, el algoritmo de Kruskal garantiza la solución óptima mientras que el de Prim sólo garantiza un subóptimo.
El algoritmo de Prim es voraz y el de Kruskal no.

Una de las afirmaciones siguientes es cierta y las otras dos falsas. Indicad cuál es la cierta. Seleccione una: CONFIRMADA
1
O(2^n) ∈ O(n!)
O(3^n) ∈ O(2^n)
O(n^n) ∈ O(n!)

Un problema tiene subestructura óptima cuando.... CONFIRMADA
3
...se trata de un problema con complejidad inherentemente prohibitiva.
...es posible escribir una solución voraz para el problema
...su solución se puede construir eficientemente a partir de soluciones de subproblemas suyos.

El valor que se obtiene con el método voraz para el problema de la mochila discreta es ... CONFIRMADA
1
... un valor inferior al valor óptimo que a veces puede ser igual a este.
... un valor inferior al valor óptimo, pero que nunca coincide con este.
... un valor superior al valor óptimo.

Indica cuál es la complejidad, en función de n, del fragmento siguiente: CONFIRMADA ```for( int i = 0; i < n; i++ ) { \n\tA[i] = 0; \n\tfor( int j = 0; j < 2*n; j++ ) \n\t\nA[i] += B[j]; \n}```
1
Θ(n^2)
Θ(n log n)
Θ(n)

¿De qué clase de complejidad es la solución de la siguiente relación de recurrencia? CONFIRMADA ```f(n) = 1 + f(n/b) si n > 1 \nf(1) = 1 \n\n, con b ∈ N, b > 1```
1
f(n) ∈ Θ(log n)
f(n) ∈ Θ(n)
Depende del valor de b.

¿Cuál sería la complejidad temporal de la siguiente función tras aplicar programación dinámica? CONFIRMADA ```double f(int n, int m){ \n\tif(n <= 1) return 1; \n\treturn m * f(n-1,m) * f(n-2,m); \n}```
3
Θ(n^2)
Θ(n * m)
Θ(n)

Con respecto al tamaño del problema, ¿Cuál es el orden de complejidad temporal asintótica de la siguiente función? (asumimos que A es una matriz cuadrada)  CONFIRMADA ```void traspuesta( vector < vector < int >> A){ \n\tfor( int i = 1; i < A.size(); i++ ) \n\t\tfor( int j = 0; j < i ; j++ ) \n\t\t\tswap( A[i][j], A[j][i] ); \n}```
3
constante
cuadrático
lineal

Si f(n) ∈ O(g(n)) ¿cuál de estas situaciones no es posible?
2
f(n) ∈ Ω(g(n))
limₙ → ∞ g(n) / f(n) = 0
g(n) ∈ O(f(n))

En los algoritmos de ramificación y poda, ¿el valor de una cota pesimista es menor que el valor de una cota optimista? (se entiende que ambas cotas se aplican sobre el mismo nodo) CONFIRMADA
3
Sí, siempre es así.
En general sí, si se trata de un problema de minimización, aunque en ocasiones ambos valores pueden coincidir.
En general sí, si se trata de un problema de maximización, aunque en ocasiones ambos valores pueden coincidir.

Con respecto a la complejidad espacial de los algoritmos de ordenación Quicksort, Heapsort y Mergesort: CONFIRMADA
1
Mergesort tiene complejidad espacial lineal con el tamaño del vector a ordenar, la de los otros dos es constante.
Mergesort y Heapsort tienen complejidad espacial lineal con el tamaño del vector a ordenar, la de Quicksort es constante.
Las complejidad espacial de todos ellos es lineal con el tamaño del vector a ordenar.

Indica cuál es la complejidad en función de \(n\), donde \(k\) es una constante (no depende de \(n\)), del fragmento siguiente: CONFIRMADA ```for( int i = k; i < n - k; i++){ \n\tA[i] = 0; \n\tfor( int j = i - k; j < i + k; j++ ) \n\t\tA[i] += B[j]; \n}```
2
O(n*log(n))
O(n)
O(n^2)

De las expresiones siguientes, o bien dos son verdaderas y una es falsa, o bien dos son falsas y una es verdadera. Marca la que (en este sentido) es diferente de las otras dos. CONFIRMADA
2
Si f no está en Omega(g) entonces O(f) es igual a Omega(g)
Si f está en Theta(g) entonces O(f) es igual a O(g)
Si f está en O(g) entonces g no está en O(f)

En un algoritmo de optimización resuelto mediante ramificación y poda ¿Podría encontrarse la solución óptima sin haber alcanzado nunca un nodo hoja? CONFIRMADA
2
Sí, esto puede ocurrir incluso si no se hace uso de cotas pesimistas.
Sí, pero esto solo podría ocurrir si se hace uso de cotas pesimistas.
No, los nodos hojas son los nodos completados y por lo tanto hay que visitar al menos uno de ellos para almacenarlo como la mejor solución hasta el momento.

El problema del alfarero (solución discreta con tiempos continuos): Se dispone de $$n$$ clases de objetos. De cada una de ellas se conoce el número máximo de piezas que se puede fabricar, $$m_i \in N$$; El valor de cada pieza terminada, $$v_i \in N$$ y el tiempo necesario para su fabricación $$t_i \in R$$, $$i \in [0..n-1]$$. El tiempo disponible para la fabricación de objetos está limitado por $$T \in R$$. \n\nSe pretende resolver mediante ramificación y poda y para ello se hace uso de una cota que consiste en asumir que de las restantes clases de objetos aún no tratadas se va a fabricar exactamente una pieza. ¿Qué podemos decir de esta cota? CONFIRMADA
1
Que no es cota, ni optimista ni pesimista
Que es una cota pesimista.
Que es una cota optimista.

Dado un vector de tamaño n de números enteros. ¿Con qué complejidad temporal se puede determinar si sus elementos están dispuestos formando un montículo de mínimos?
1
O(n)
O(log n)
O(1)

Haciendo uso de la función Merge del algoritmo Mergesort se quiere mezclar k vectores ordenados de n elementos cada uno y obtener un único vector de kn elementos. Para ello primero se mezclan los dos primeros vectores, luego el resultado se mezcla con el tercero y a su vez, este resultado se mezcla con el cuarto y así hasta llegar al k-ésimo. ¿Cuál sería la complejidad del algoritmo?
2
Θ(n · k^2)
Θ(n · k)
Θ(n^2 · k)

Una de estas tres afirmaciones es falsa. ¿Cuál?
3
Un algoritmo voraz puede no encontrar la solución óptima de un problema de selección discreta.
El esquema de ramificación y poda no garantiza que la complejidad temporal de resolución de un problema de selección discreta no sea exponencial.
Los algoritmos voraces no sirven para resolver problemas de selección discreta.

Una de estas tres situaciones no es posible. ¿Cuál es?
2
f(n) ∈ O(n) y f(n) ∈ Ω(1)
f(n) ∈ Ω(n^2) y f(n) ∈ O(n)
f(n) ∈ O(n) y f(n) ∈ O(n^2)

Una empresa de mensajería tiene n repartidores con distintos tiempos de entrega según el tipo de envío. Se trata de asignar los próximos n envíos, uno a cada repartidor, minimizando el tiempo total de todos los envíos. Para ello se conoce de antemano una tabla de tiempos en la que el valor t_ij corresponde al tiempo que emplea el repartidor i en realizar el envío j. De entre las estrategias que se citan, ¿cuál sería la eficiente para resolver el problema?
2
Algoritmo voraz.
Vuelta atrás.
Ramificación y poda.

De las siguientes tres afirmaciones, una es cierta y dos falsas, o bien una es falsa y dos son ciertas. Marca la que en ese sentido es diferente a las otras dos.
3
Para que un problema tenga solución mediante programación dinámica es condición necesaria que pueda resolverse mediante divide y vencerás.
Todo problema que tiene solución mediante divide y vencerás también la tendrá mediante programación dinámica.
Todo problema que tiene solución mediante ramificación y poda también la tendrá mediante programación dinámica.

¿En qué caso la complejidad temporal de quicksort es la misma que la del algoritmo de ordenación por inserción?
3
En el caso mejor.
En el caso peor.
En ningún caso.

¿Cuál es la complejidad temporal de la siguiente función?```int f(int n){ \n\tint k = 0; \n\tfor (int i = 1; i < n; i *= 2) \n\t\tfor (int j = i; j > 0; j -= 2) \n\t\t\tk++; \n\treturn k; \n}```
2
Θ(n^2)
Θ(n log n)
Θ(n)

De las siguientes tres afirmaciones, una es cierta y dos falsas, o bien una es falsa y dos son ciertas. Marca la que en ese sentido es diferente a las otras dos.
1
Ramificación y poda sirve para resolver problemas que vuelta atrás no puede.
Ramificación y poda siempre es más eficiente que vuelta atrás.
Ramificación y poda resuelve el mismo tipo de problemas que vuelta atrás.

Cuando un algoritmo recursivo que sigue el esquema divide y vencerás incurre en complejidades temporales prohibitivas porque se resuelven repetidamente los mismos subproblemas...
2
...debemos convertirlo obligatoriamente a iterativo para evitarlo.
...podemos guardar soluciones parciales en un almacén para evitar esa repetición, pero resolveremos indefectiblemente más problemas que si lo convertimos en iterativo.
...podemos guardar soluciones parciales en un almacén para evitar esa repetición y puede ser que resolvamos menos problemas que si lo convertimos en iterativo.

Indica cuál de las siguientes afirmaciones sobre el problema de la mochila continua es cierta:
3
El esquema voraz podría no encontrar ninguna solución.
Un esquema voraz siempre encuentra alguna solución, aunque no sea óptima.
Se puede demostrar que un esquema voraz encuentra siempre la solución óptima.

En una carrera de coches por el desierto uno de los principales problemas es el abastecimiento de gasolina. Un participante dispone de un mapa que le indica las distancias entre las gasolineras que hay en la ruta y cree que, parándose a repostar el menor número de veces posible, podrá ganar. Para ayudarle hay que diseñar un algoritmo que le sugiera en qué gasolineras debe hacerlo. Hay que tener en cuenta que hay una única ruta posible. De entre las estrategias que se citan, ¿cuál sería la eficiente para resolver el problema?
2
Programación dinámica.
Algoritmo voraz.
Ramificación y poda.

Sea el problema de la función compuesta mínima. Si no acotamos el número máximo de operaciones posibles, un esquema de ramificación y poda:
1
Podría no acabar, al tener que expandir indefinidamente nuevos nodos.
Si incluimos memorización, podría no encontrar la solución óptima pero siempre acabaría.
Si incluimos memorización, siempre encuentra la solución óptima.

Solo una de estas tres relaciones de recurrencia es tal que T(n) ∈ Θ(n). ¿Cuál?
1
T(n) = 1 + 2T(n/2) si n > 1; T(1) = 1
T(n) = 1 + T(n/2) si n > 1; T(1) = 1
T(n) = n + T(n - 1) si n > 1; T(1) = 1

Qué complejidad temporal asintótica cabe esperar de un algoritmo divide y vencerás cuya función descomponer produce, en tiempo constante, dos subproblemas iguales de tamaño n - 2 cada uno y cuya función combinar es lineal con n, donde n es el tamaño del problema.
1
O(n log n)
O(2^n)
O(n^2)

Dado el siguiente programa recursivo:```int f(int n) { # Se asume que n >= 0 \n\tif(n == 0) \n\t\treturn 1; \n\treturn f(n - 1) + f(n - 2); \n}``` si quisiéramos mejorarlo haciendo uso de la técnica de programación dinámica, ¿cuáles serían las complejidades temporal y espacial más ajustadas del algoritmo resultante?
1
Respectivamente, O(n) y O(1)
Ambas complejidades serían O(1)
Ambas complejidades serían O(n)

Se quiere desarrollar un programa que compruebe si es posible que un caballo de ajedrez, mediante una secuencia de sus movimientos permitidos, recorra todas las casillas de un tablero N x N a partir de una determinada casilla dada como entrada y sin repetir ninguna casilla. De entre las estrategias que se citan, ¿cuál sería la eficiente para resolver el problema?
2
Programación dinámica.
Vuelta atrás.
Algoritmo voraz.

Un vector de enteros de tamaño n tiene sus elementos estructurados en forma de montículo (heap). ¿Cuál es la complejidad temporal en el peor de los casos de borrar el primer elemento del vector y reconstruirlo posteriormente para que siga manteniendo la estructura de montículo?
2
O(n).
O(log n).
O(n log n).

El problema del cambio consiste en formar una cantidad dineraria M utilizando el menor número posible de monedas a escoger de entre las disponibles. ¿Qué estrategia resulta ser la más eficiente para garantizar la solución óptima?
2
Un algoritmo Voraz.
Programación Dinámica.
Divide y vencerás.

En un algoritmo de ramificación y poda, ¿Qué ocurre si coinciden los valores obtenidos por las cotas pesimista y optimista del mismo nodo?
2
Esta situación no puede ocurrir en ningún caso; por lo tanto, una de las cotas está mal calculada (o ambas).
Que ese valor es a su vez el mejor valor que se puede obtener con ese nodo.
Que es un nodo hoja, esta situación sólo es posible en los nodos hoja.

Di cuál de estos tres problemas de optimización no comporta, en el peor caso, tener que considerar O(n!) posibles soluciones.
3
El problema de la asignación de n tareas a n trabajadores de forma que cada trabajador hace exactamente una tarea y cada tarea es asignada a un trabajador exactamente, de forma que la suma de los costes de las tareas es mínimo.
El problema del viajante de comercio (travelling salesman problem, o sea, el de encontrar un ciclo hamiltoniano de coste mínimo en un grafo conexo de n vértices donde cada arista tiene un coste asignado.
El problema de buscar un árbol que cubre todos los vértices de un grafo de n vértices de forma que el coste es mínimo (minimum spanning tree).

Sea T(n) = n + T(n - 1) para n > 1 y T(1) = 1. Una de las afirmaciones siguientes es cierta. ¿Cuál?
1
T(n) ∈ O(n^3)
T(n) ∈ O(n log n)
T(n) ∈ O(n)

Una de las siguientes afirmaciones es falsa. ¿Cuál?
1
O(2^n) = O(3^n)
O(n log n) ⊆ O(n^2)
O(n^2 + 2n + 1) = O(n^2)

Se pretende resolver el problema del viajante de comercio (travelling salesman problem) mediante Ramificación y poda. ¿Cuál de las siguientes acciones resulta ser mejor cota optimista para aplicarla a los nodos intermedios?
1
Obtener el árbol de recubrimiento de mínimo coste a los vértices aún no visitados.
Completar el recorrido pendiente mediante un algoritmo voraz.
Asumir que ya no quedan más vértices por visitar y cerrar el camino desde el último vértice visitado.

Se pretende implementar mediante programación dinámica iterativa la siguiente función recursiva:```int f(int m, int n, int p, int *v){ \n\tif(n < 0) return 0; \n\tint aux = 0; \n\tif (v[n] <= m) \n\t\taux = p + f(m - v[n], n - 1, p, v); \n\treturn aux + f(m, n - 1, p, v); \n}```¿Cuál sería la complejidad temporal del algoritmo iterativo?
2
Θ(m)
Θ(m · n)
Ninguna de las otras dos opciones es la correcta.

Puede ser que una solución recursiva con memoización a un problema de optimización realice menos evaluaciones de la función que computa el valor de una solución parcial que una basada en programación dinámica iterativa y por lo tanto acabo siendo más rápida?
1
Sí; de hecho, esto pasa con el problema de la mochila discreta con pesos enteros.
No; las dos soluciones tienen que realizar el mismo número de evaluaciones de la función que computa el valor de una solución parcial, y la solución recursiva es más lenta porque tiene que gestionar las llamadas recursivas (argumentos, reserva de espacio temporal, etc).
No; las soluciones recursivas realizan más evaluaciones de la función que computa el valor de una solución parcial que las iterativas correspondientes.

En los algoritmos de Ramificación y poda ...
2
una cota pesimista es necesariamente un valor insuperable, de no ser así se podría podar el nodo que conduce a la solución óptima.
una cota pesimista es necesariamente un valor alcanzable, de no ser así no está garantizado que se encuentre la solución óptima.
una cota optimista es el valor que a lo sumo alcanza cualquier nodo factible que no es el óptimo.

¿Cuál es el coste temporal asintótico de la siguiente función?```int f(int n) { \n\tint count = 0; \n\tfor (int i = n; i > 0; i /= 2) \n\t\tfor (int j = 0; j < 2 * i; j++) \n\t\t\tcount += 1; \n\treturn count; \n}```
1
O(n)
O(n log n)
O(n^2)

¿Cuál de estos conceptos pertenece a la misma categoría que divide y vencerás, vuelta atrás o ramificación y poda?
1
programación dinámica.
memoización.
cota optimista.

¿Cuál es la complejidad espacial del algoritmo Quicksort?
3
O(n).
O(n log n).
O(1).

¿Qué aporta la técnica de ramificación y poda frente a la de vuelta atrás?
3
Eficiencia. Los algoritmos de ramificación y poda son más eficientes que los de vuelta atrás.
La posibilidad de combinar el uso de cotas pesimistas y optimistas para cualquier nodo ya sea completado o sin completar. En vuelta atrás esto no se puede hacer.
La posibilidad de analizar diferentes estrategias para seleccionar el siguiente nodo a expandir.

Se pretende ordenar un vector cuyos n elementos están organizados formando un montículo (Heap). Sin tener en cuenta el tiempo empleado para este preproceso, ¿Con qué coste temporal asintótico se podría realizar la ordenación?
3
O(n).
Ninguna de las otras dos opciones es la correcta.
O(n log n).

Se pretende ordenar un vector cuyos n elementos están organizados formando un montículo (Heap). Sin tener en cuenta el tiempo empleado para este preproceso, ¿Con qué coste temporal asintótico se podría realizar la ordenación?
3
O(n).
Ninguna de las otras dos opciones es la correcta.
O(n log n).

Cuando se usan cotas pesimistas para hacer podas en algoritmos de optimización basados en búsqueda y enumeración (por ejemplo, vuelta atrás o ramificación y poda)...
2
...siempre se obtienen cuando se visitan las hojas del árbol de búsqueda.
...se pueden obtener sin visitar necesariamente las hojas del árbol de búsqueda.
...es posible que no encontremos la solución óptima.

¿Cuál es el coste temporal asintótico de la siguiente función?```void f(int n, int arr[]) { \n\tint i = 0, j = 0; \n\tfor(; i < n; ++i) \n\t\twhile(j < n && arr[i] < arr[j]) \n\t\t\tj++; \n}```
1
O(n)
O(n log n)
O(n^2)

Uno de estos tres algoritmos no resuelve el mismo problema que los otros dos. ¿Cuál?
1
El algoritmo de Floyd y Warshall.
El algoritmo de Prim.
El algoritmo de Kruskal.

Una de las siguientes afirmaciones es falsa. ¿Cuál?
1
Si f ∈ O(g) y g ∈ O(f), entonces f = g
Si f ∈ O(g) y g ∈ O(f), entonces O(f) = O(g)
Si f ∈ O(g) y g ∈ O(h), entonces f ∈ O(h)

¿Por qué muchos algoritmos voraces presentan complejidades temporales en O(n log n)?
1
Porque primero ordenan de alguna manera los elementos y porque una vez ordenados la complejidad temporal del proceso de selección de los elementos que se incorporarán a la solución está en O(n log n).
Porque primero ordenan de alguna manera los elementos y porque una vez ordenados la complejidad temporal del proceso de selección de los elementos que se incorporarán a la solución es estrictamente inferior a O(n log n).
Porque el proceso de selección de los elementos que se incorporarán a la solución es siempre O(n log n).

Se pretende borrar todos los elementos de un vector cuyo valor es un número par. Si el tamaño del vector es n, ¿con qué coste temporal asintótico se podría realizar esa operación?
1
O(n)
O(n^2)
Ninguna de las otras dos opciones es la correcta.
